
<!DOCTYPE HTML>
<html lang="zh" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>集成学习 · TensorFlow 教程（Hvass）</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="wizardforcel">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-comment/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html" />
    
    
    <link rel="prev" href="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="輸入並搜尋" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://www.gitbook.com/book/wizardforcel/tf-tut-hvass" target="_blank" class="custom-link">TensorFlow 教程（Hvass）</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    TensorFlow 教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                <a href="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                    
                    简单线性模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                <a href="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                    
                    卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                <a href="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                    
                    PrettyTensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                <a href="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                    
                    保存 & 恢复
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.6" data-path="05_Ensemble_Learning_zh_CN.html">
            
                <a href="05_Ensemble_Learning_zh_CN.html">
            
                    
                    集成学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                <a href="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                    
                    CIFAR-10
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                <a href="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                    
                    Inception 模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                <a href="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                    
                    迁移学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                <a href="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                    
                    视频数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../11_Adversarial_Examples_zh_CN/11_Adversarial_Examples_zh_CN.html">
            
                <a href="../11_Adversarial_Examples_zh_CN/11_Adversarial_Examples_zh_CN.html">
            
                    
                    对抗样本
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                <a href="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                    
                    MNIST的对抗噪声
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                <a href="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                    
                    可视化分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                <a href="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                    
                    DeepDream
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../15_Style_Transfer_zh_CN/15_Style_Transfer_zh_CN.html">
            
                <a href="../15_Style_Transfer_zh_CN/15_Style_Transfer_zh_CN.html">
            
                    
                    风格迁移
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本書使用 GitBook 釋出
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >集成学习</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="tensorflow-&#x6559;&#x7A0B;-05">TensorFlow &#x6559;&#x7A0B; #05</h1>
<h1 id="&#x96C6;&#x6210;&#x5B66;&#x4E60;">&#x96C6;&#x6210;&#x5B66;&#x4E60;</h1>
<p>by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a>
/ <a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials" target="_blank">GitHub</a> / <a href="https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ" target="_blank">Videos on YouTube</a><br>&#x4E2D;&#x6587;&#x7FFB;&#x8BD1; <a href="https://zhuanlan.zhihu.com/insight-pixel" target="_blank">thrillerist</a>/<a href="https://github.com/thrillerist/TensorFlow-Tutorials" target="_blank">Github</a>  </p>
<h2 id="&#x7B80;&#x4ECB;">&#x7B80;&#x4ECB;</h2>
<p>&#x8FD9;&#x7BC7;&#x6559;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#xFF08;ensemble&#xFF09;&#x3002;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x591A;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x7136;&#x540E;&#x53D6;&#x5B83;&#x4EEC;&#x8F93;&#x51FA;&#x7684;&#x5E73;&#x5747;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x53EA;&#x7528;&#x4E00;&#x4E2A;&#x3002;</p>
<p>&#x6700;&#x7EC8;&#x4E5F;&#x662F;&#x5728;MINIST&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x8BC6;&#x522B;&#x624B;&#x5199;&#x6570;&#x5B57;&#x3002;ensemble&#x7A0D;&#x5FAE;&#x5730;&#x63D0;&#x5347;&#x4E86;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#xFF0C;&#x4F46;&#x5DEE;&#x5F02;&#x5F88;&#x5C0F;&#xFF0C;&#x4E5F;&#x53EF;&#x80FD;&#x662F;&#x968F;&#x673A;&#x51FA;&#x73B0;&#x7684;&#x3002;&#x6B64;&#x5916;&#xFF0C;ensemble&#x8BEF;&#x5206;&#x7C7B;&#x7684;&#x4E00;&#x4E9B;&#x56FE;&#x50CF;&#x5728;&#x5355;&#x72EC;&#x7F51;&#x7EDC;&#x4E0A;&#x5374;&#x662F;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x7684;&#x3002;</p>
<p>&#x672C;&#x6587;&#x57FA;&#x4E8E;&#x4E0A;&#x4E00;&#x7BC7;&#x6559;&#x7A0B;&#xFF0C;&#x4F60;&#x9700;&#x8981;&#x4E86;&#x89E3;&#x57FA;&#x672C;&#x7684;TensorFlow&#x548C;&#x9644;&#x52A0;&#x5305;Pretty Tensor&#x3002;&#x5176;&#x4E2D;&#x5927;&#x91CF;&#x4EE3;&#x7801;&#x548C;&#x6587;&#x5B57;&#x4E0E;&#x4E4B;&#x524D;&#x6559;&#x7A0B;&#x76F8;&#x4F3C;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x5DF2;&#x7ECF;&#x770B;&#x8FC7;&#x5C31;&#x53EF;&#x4EE5;&#x5FEB;&#x901F;&#x5730;&#x6D4F;&#x89C8;&#x672C;&#x6587;&#x3002;</p>
<h2 id="&#x6D41;&#x7A0B;&#x56FE;">&#x6D41;&#x7A0B;&#x56FE;</h2>
<p>&#x4E0B;&#x9762;&#x7684;&#x56FE;&#x8868;&#x76F4;&#x63A5;&#x663E;&#x793A;&#x4E86;&#x4E4B;&#x540E;&#x5B9E;&#x73B0;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x6570;&#x636E;&#x7684;&#x4F20;&#x9012;&#x3002;&#x7F51;&#x7EDC;&#x6709;&#x4E24;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x548C;&#x4E24;&#x4E2A;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#xFF0C;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x662F;&#x7528;&#x6765;&#x7ED9;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x7684;&#x3002;&#x5173;&#x4E8E;&#x7F51;&#x7EDC;&#x548C;&#x5377;&#x79EF;&#x7684;&#x66F4;&#x591A;&#x7EC6;&#x8282;&#x63CF;&#x8FF0;&#x89C1;&#x6559;&#x7A0B; #02 &#x3002;</p>
<p>&#x672C;&#x6559;&#x7A0B;&#x5B9E;&#x73B0;&#x4E86;5&#x4E2A;&#x8FD9;&#x6837;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#xFF0C;&#x6BCF;&#x4E2A;&#x7F51;&#x7EDC;&#x7684;&#x7ED3;&#x6784;&#x76F8;&#x540C;&#x4F46;&#x6743;&#x91CD;&#x4EE5;&#x53CA;&#x5176;&#x4ED6;&#x53D8;&#x91CF;&#x4E0D;&#x540C;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image
Image(<span class="hljs-string">&apos;images/02_network_flowchart.png&apos;</span>)
</code></pre>
<p><img src="output_4_0.png" alt="png"></p>
<h2 id="&#x5BFC;&#x5165;">&#x5BFC;&#x5165;</h2>
<pre><code class="lang-python">%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> timedelta
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> os

<span class="hljs-comment"># Use PrettyTensor to simplify Neural Network construction.</span>
<span class="hljs-keyword">import</span> prettytensor <span class="hljs-keyword">as</span> pt
</code></pre>
<p>&#x4F7F;&#x7528;Python3.5.2&#xFF08;Anaconda&#xFF09;&#x5F00;&#x53D1;&#xFF0C;TensorFlow&#x7248;&#x672C;&#x662F;&#xFF1A;</p>
<pre><code class="lang-python">tf.__version__
</code></pre>
<pre><code>&apos;0.12.0-rc0&apos;
</code></pre><p>PrettyTensor &#x7248;&#x672C;:</p>
<pre><code class="lang-python">pt.__version__
</code></pre>
<pre><code>&apos;0.7.1&apos;
</code></pre><h2 id="&#x8F7D;&#x5165;&#x6570;&#x636E;">&#x8F7D;&#x5165;&#x6570;&#x636E;</h2>
<p>MNIST&#x6570;&#x636E;&#x96C6;&#x5927;&#x7EA6;12MB&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x5728;&#x7ED9;&#x5B9A;&#x8DEF;&#x5F84;&#x4E2D;&#x627E;&#x5230;&#x5C31;&#x4F1A;&#x81EA;&#x52A8;&#x4E0B;&#x8F7D;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data
data = input_data.read_data_sets(<span class="hljs-string">&apos;data/MNIST/&apos;</span>, one_hot=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code>Extracting data/MNIST/train-images-idx3-ubyte.gz
Extracting data/MNIST/train-labels-idx1-ubyte.gz
Extracting data/MNIST/t10k-images-idx3-ubyte.gz
Extracting data/MNIST/t10k-labels-idx1-ubyte.gz
</code></pre><p>&#x73B0;&#x5728;&#x5DF2;&#x7ECF;&#x8F7D;&#x5165;&#x4E86;MNIST&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x5B83;&#x7531;70,000&#x5F20;&#x56FE;&#x50CF;&#x548C;&#x5BF9;&#x5E94;&#x7684;&#x6807;&#x7B7E;&#xFF08;&#x6BD4;&#x5982;&#x56FE;&#x50CF;&#x7684;&#x7C7B;&#x522B;&#xFF09;&#x7EC4;&#x6210;&#x3002;&#x6570;&#x636E;&#x96C6;&#x5206;&#x6210;&#x4E09;&#x4EFD;&#x4E92;&#x76F8;&#x72EC;&#x7ACB;&#x7684;&#x5B50;&#x96C6;&#xFF0C;&#x4F46;&#x540E;&#x9762;&#x6211;&#x4EEC;&#x4F1A;&#x751F;&#x6210;&#x968F;&#x673A;&#x7684;&#x8BAD;&#x7EC3;&#x96C6;&#x3002;</p>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;Size of:&quot;</span>)
print(<span class="hljs-string">&quot;- Training-set:\t\t{}&quot;</span>.format(len(data.train.labels)))
print(<span class="hljs-string">&quot;- Test-set:\t\t{}&quot;</span>.format(len(data.test.labels)))
print(<span class="hljs-string">&quot;- Validation-set:\t{}&quot;</span>.format(len(data.validation.labels)))
</code></pre>
<pre><code>Size of:
- Training-set:        55000
- Test-set:        10000
- Validation-set:    5000
</code></pre><h3 id="&#x7C7B;&#x522B;&#x6570;&#x5B57;">&#x7C7B;&#x522B;&#x6570;&#x5B57;</h3>
<p>&#x7C7B;&#x578B;&#x6807;&#x7B7E;&#x4F7F;&#x7528;One-Hot&#x7F16;&#x7801;&#xFF0C;&#x8FD9;&#x610F;&#x5916;&#x6BCF;&#x4E2A;&#x6807;&#x7B7E;&#x662F;&#x957F;&#x4E3A;10&#x7684;&#x5411;&#x91CF;&#xFF0C;&#x9664;&#x4E86;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x4E4B;&#x5916;&#xFF0C;&#x5176;&#x4ED6;&#x7684;&#x90FD;&#x4E3A;&#x96F6;&#x3002;&#x8FD9;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x7D22;&#x5F15;&#x5C31;&#x662F;&#x7C7B;&#x522B;&#x7684;&#x6570;&#x5B57;&#xFF0C;&#x5373;&#x76F8;&#x5E94;&#x56FE;&#x7247;&#x4E2D;&#x753B;&#x7684;&#x6570;&#x5B57;&#x3002;&#x6211;&#x4EEC;&#x4E5F;&#x9700;&#x8981;&#x6D4B;&#x8BD5;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x7684;&#x6574;&#x5F62;&#x7C7B;&#x522B;&#x6570;&#x5B57;&#xFF0C;&#x5728;&#x8FD9;&#x91CC;&#x8BA1;&#x7B97;&#x3002;</p>
<pre><code class="lang-python">data.test.cls = np.argmax(data.test.labels, axis=<span class="hljs-number">1</span>)
data.validation.cls = np.argmax(data.validation.labels, axis=<span class="hljs-number">1</span>)
</code></pre>
<h3 id="&#x521B;&#x5EFA;&#x968F;&#x673A;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x521B;&#x5EFA;&#x968F;&#x673A;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x6211;&#x4EEC;&#x5C06;&#x4F1A;&#x5728;&#x968F;&#x673A;&#x9009;&#x62E9;&#x7684;&#x8BAD;&#x7EC3;&#x96C6;&#x4E0A;&#x8BAD;&#x7EC3;5&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x5C06;&#x539F;&#x59CB;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x5408;&#x5E76;&#x5230;&#x5927;&#x7684;&#x4E00;&#x4E2A;&#x6570;&#x7EC4;&#x4E2D;&#x3002;&#x56FE;&#x50CF;&#x548C;&#x6807;&#x7B7E;&#x90FD;&#x8981;&#x8FDB;&#x884C;&#x6B64;&#x64CD;&#x4F5C;&#x3002;</p>
<pre><code class="lang-python">combined_images = np.concatenate([data.train.images, data.validation.images], axis=<span class="hljs-number">0</span>)
combined_labels = np.concatenate([data.train.labels, data.validation.labels], axis=<span class="hljs-number">0</span>)
</code></pre>
<p>&#x68C0;&#x67E5;&#x5408;&#x5E76;&#x540E;&#x7684;&#x6570;&#x7EC4;&#x5927;&#x5C0F;&#x662F;&#x5426;&#x6B63;&#x786E;&#x3002;</p>
<pre><code class="lang-python">print(combined_images.shape)
print(combined_labels.shape)
</code></pre>
<pre><code>(60000, 784)
(60000, 10)
</code></pre><p>&#x5408;&#x5E76;&#x6570;&#x636E;&#x96C6;&#x7684;&#x5927;&#x5C0F;&#x3002;</p>
<pre><code class="lang-python">combined_size = len(combined_images)
combined_size
</code></pre>
<pre><code>60000
</code></pre><p>&#x5B9A;&#x4E49;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4F7F;&#x7528;&#x7684;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x5927;&#x5C0F;&#x3002;&#x4F60;&#x53EF;&#x4EE5;&#x8BD5;&#x7740;&#x6539;&#x53D8;&#x5927;&#x5C0F;&#x3002;</p>
<pre><code class="lang-python">train_size = int(<span class="hljs-number">0.8</span> * combined_size)
train_size
</code></pre>
<pre><code>48000
</code></pre><p>&#x5728;&#x8BAD;&#x7EC3;&#x65F6;&#x5E76;&#x6CA1;&#x6709;&#x4F7F;&#x7528;&#x9A8C;&#x8BC1;&#x96C6;&#xFF0C;&#x4F46;&#x5B83;&#x7684;&#x5927;&#x5C0F;&#x5982;&#x4E0B;&#x3002;</p>
<pre><code class="lang-python">validation_size = combined_size - train_size
validation_size
</code></pre>
<pre><code>12000
</code></pre><p>&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#x5C06;&#x5408;&#x5E76;&#x6570;&#x7EC4;&#x96C6;&#x5212;&#x5206;&#x6210;&#x968F;&#x673A;&#x7684;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">random_training_set</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># Create a randomized index into the full / combined training-set.</span>
    idx = np.random.permutation(combined_size)

    <span class="hljs-comment"># Split the random index into training- and validation-sets.</span>
    idx_train = idx[<span class="hljs-number">0</span>:train_size]
    idx_validation = idx[train_size:]

    <span class="hljs-comment"># Select the images and labels for the new training-set.</span>
    x_train = combined_images[idx_train, :]
    y_train = combined_labels[idx_train, :]

    <span class="hljs-comment"># Select the images and labels for the new validation-set.</span>
    x_validation = combined_images[idx_validation, :]
    y_validation = combined_labels[idx_validation, :]

    <span class="hljs-comment"># Return the new training- and validation-sets.</span>
    <span class="hljs-keyword">return</span> x_train, y_train, x_validation, y_validation
</code></pre>
<h2 id="&#x6570;&#x636E;&#x7EF4;&#x5EA6;">&#x6570;&#x636E;&#x7EF4;&#x5EA6;</h2>
<p>&#x5728;&#x4E0B;&#x9762;&#x7684;&#x6E90;&#x7801;&#x4E2D;&#xFF0C;&#x6709;&#x5F88;&#x591A;&#x5730;&#x65B9;&#x7528;&#x5230;&#x4E86;&#x6570;&#x636E;&#x7EF4;&#x5EA6;&#x3002;&#x5B83;&#x4EEC;&#x53EA;&#x5728;&#x4E00;&#x4E2A;&#x5730;&#x65B9;&#x5B9A;&#x4E49;&#xFF0C;&#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5728;&#x4EE3;&#x7801;&#x4E2D;&#x4F7F;&#x7528;&#x8FD9;&#x4E9B;&#x53D8;&#x91CF;&#x800C;&#x4E0D;&#x662F;&#x76F4;&#x63A5;&#x5199;&#x6570;&#x5B57;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># We know that MNIST images are 28 pixels in each dimension.</span>
img_size = <span class="hljs-number">28</span>

<span class="hljs-comment"># Images are stored in one-dimensional arrays of this length.</span>
img_size_flat = img_size * img_size

<span class="hljs-comment"># Tuple with height and width of images used to reshape arrays.</span>
img_shape = (img_size, img_size)

<span class="hljs-comment"># Number of colour channels for the images: 1 channel for gray-scale.</span>
num_channels = <span class="hljs-number">1</span>

<span class="hljs-comment"># Number of classes, one class for each of 10 digits.</span>
num_classes = <span class="hljs-number">10</span>
</code></pre>
<h3 id="&#x7528;&#x6765;&#x7ED8;&#x5236;&#x56FE;&#x7247;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x7528;&#x6765;&#x7ED8;&#x5236;&#x56FE;&#x7247;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7528;&#x6765;&#x5728;3x3&#x7684;&#x6805;&#x683C;&#x4E2D;&#x753B;9&#x5F20;&#x56FE;&#x50CF;&#xFF0C;&#x7136;&#x540E;&#x5728;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x4E0B;&#x9762;&#x5199;&#x51FA;&#x771F;&#x5B9E;&#x7C7B;&#x522B;&#x548C;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_images</span><span class="hljs-params">(images,                  # Images to plot, <span class="hljs-number">2</span>-d array.
                cls_true,                # True class-no for images.
                ensemble_cls_pred=None,  # Ensemble predicted class-no.
                best_cls_pred=None)</span>:</span>     <span class="hljs-comment"># Best-net predicted class-no.</span>

    <span class="hljs-keyword">assert</span> len(images) == len(cls_true)

    <span class="hljs-comment"># Create figure with 3x3 sub-plots.</span>
    fig, axes = plt.subplots(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)

    <span class="hljs-comment"># Adjust vertical spacing if we need to print ensemble and best-net.</span>
    <span class="hljs-keyword">if</span> ensemble_cls_pred <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
        hspace = <span class="hljs-number">0.3</span>
    <span class="hljs-keyword">else</span>:
        hspace = <span class="hljs-number">1.0</span>
    fig.subplots_adjust(hspace=hspace, wspace=<span class="hljs-number">0.3</span>)

    <span class="hljs-comment"># For each of the sub-plots.</span>
    <span class="hljs-keyword">for</span> i, ax <span class="hljs-keyword">in</span> enumerate(axes.flat):

        <span class="hljs-comment"># There may not be enough images for all sub-plots.</span>
        <span class="hljs-keyword">if</span> i &lt; len(images):
            <span class="hljs-comment"># Plot image.</span>
            ax.imshow(images[i].reshape(img_shape), cmap=<span class="hljs-string">&apos;binary&apos;</span>)

            <span class="hljs-comment"># Show true and predicted classes.</span>
            <span class="hljs-keyword">if</span> ensemble_cls_pred <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
                xlabel = <span class="hljs-string">&quot;True: {0}&quot;</span>.format(cls_true[i])
            <span class="hljs-keyword">else</span>:
                msg = <span class="hljs-string">&quot;True: {0}\nEnsemble: {1}\nBest Net: {2}&quot;</span>
                xlabel = msg.format(cls_true[i],
                                    ensemble_cls_pred[i],
                                    best_cls_pred[i])

            <span class="hljs-comment"># Show the classes as the label on the x-axis.</span>
            ax.set_xlabel(xlabel)

        <span class="hljs-comment"># Remove ticks from the plot.</span>
        ax.set_xticks([])
        ax.set_yticks([])

    <span class="hljs-comment"># Ensure the plot is shown correctly with multiple plots</span>
    <span class="hljs-comment"># in a single Notebook cell.</span>
    plt.show()
</code></pre>
<h3 id="&#x7ED8;&#x5236;&#x51E0;&#x5F20;&#x56FE;&#x50CF;&#x6765;&#x770B;&#x770B;&#x6570;&#x636E;&#x662F;&#x5426;&#x6B63;&#x786E;">&#x7ED8;&#x5236;&#x51E0;&#x5F20;&#x56FE;&#x50CF;&#x6765;&#x770B;&#x770B;&#x6570;&#x636E;&#x662F;&#x5426;&#x6B63;&#x786E;</h3>
<pre><code class="lang-python"><span class="hljs-comment"># Get the first images from the test-set.</span>
images = data.test.images[<span class="hljs-number">0</span>:<span class="hljs-number">9</span>]

<span class="hljs-comment"># Get the true classes for those images.</span>
cls_true = data.test.cls[<span class="hljs-number">0</span>:<span class="hljs-number">9</span>]

<span class="hljs-comment"># Plot the images and labels using our helper-function above.</span>
plot_images(images=images, cls_true=cls_true)
</code></pre>
<p><img src="output_37_0.png" alt="png"></p>
<h2 id="tensorflow&#x56FE;">TensorFlow&#x56FE;</h2>
<p>TensorFlow&#x7684;&#x5168;&#x90E8;&#x76EE;&#x7684;&#x5C31;&#x662F;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x79F0;&#x4E4B;&#x4E3A;&#x8BA1;&#x7B97;&#x56FE;&#xFF08;computational graph&#xFF09;&#x7684;&#x4E1C;&#x897F;&#xFF0C;&#x5B83;&#x4F1A;&#x6BD4;&#x76F4;&#x63A5;&#x5728;Python&#x4E2D;&#x8FDB;&#x884C;&#x76F8;&#x540C;&#x8BA1;&#x7B97;&#x91CF;&#x8981;&#x9AD8;&#x6548;&#x5F97;&#x591A;&#x3002;TensorFlow&#x6BD4;Numpy&#x66F4;&#x9AD8;&#x6548;&#xFF0C;&#x56E0;&#x4E3A;TensorFlow&#x4E86;&#x89E3;&#x6574;&#x4E2A;&#x9700;&#x8981;&#x8FD0;&#x884C;&#x7684;&#x8BA1;&#x7B97;&#x56FE;&#xFF0C;&#x7136;&#x800C;Numpy&#x53EA;&#x77E5;&#x9053;&#x67D0;&#x4E2A;&#x65F6;&#x95F4;&#x70B9;&#x4E0A;&#x552F;&#x4E00;&#x7684;&#x6570;&#x5B66;&#x8FD0;&#x7B97;&#x3002;</p>
<p>TensorFlow&#x4E5F;&#x80FD;&#x591F;&#x81EA;&#x52A8;&#x5730;&#x8BA1;&#x7B97;&#x9700;&#x8981;&#x4F18;&#x5316;&#x7684;&#x53D8;&#x91CF;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x4F7F;&#x5F97;&#x6A21;&#x578B;&#x6709;&#x66F4;&#x597D;&#x7684;&#x8868;&#x73B0;&#x3002;&#x8FD9;&#x662F;&#x7531;&#x4E8E;&#x56FE;&#x662F;&#x7B80;&#x5355;&#x6570;&#x5B66;&#x8868;&#x8FBE;&#x5F0F;&#x7684;&#x7ED3;&#x5408;&#xFF0C;&#x56E0;&#x6B64;&#x6574;&#x4E2A;&#x56FE;&#x7684;&#x68AF;&#x5EA6;&#x53EF;&#x4EE5;&#x7528;&#x94FE;&#x5F0F;&#x6CD5;&#x5219;&#x63A8;&#x5BFC;&#x51FA;&#x6765;&#x3002;</p>
<p>TensorFlow&#x8FD8;&#x80FD;&#x5229;&#x7528;&#x591A;&#x6838;CPU&#x548C;GPU&#xFF0C;Google&#x4E5F;&#x4E3A;TensorFlow&#x5236;&#x9020;&#x4E86;&#x79F0;&#x4E3A;TPUs&#xFF08;Tensor Processing Units&#xFF09;&#x7684;&#x7279;&#x6B8A;&#x82AF;&#x7247;&#xFF0C;&#x5B83;&#x6BD4;GPU&#x66F4;&#x5FEB;&#x3002;</p>
<p>&#x4E00;&#x4E2A;TensorFlow&#x56FE;&#x7531;&#x4E0B;&#x9762;&#x51E0;&#x4E2A;&#x90E8;&#x5206;&#x7EC4;&#x6210;&#xFF0C;&#x540E;&#x9762;&#x4F1A;&#x8BE6;&#x7EC6;&#x63CF;&#x8FF0;&#xFF1A;</p>
<ul>
<li>&#x5360;&#x4F4D;&#x7B26;&#x53D8;&#x91CF;&#xFF08;Placeholder&#xFF09;&#x7528;&#x6765;&#x6539;&#x53D8;&#x56FE;&#x7684;&#x8F93;&#x5165;&#x3002;</li>
<li>&#x6A21;&#x578B;&#x53D8;&#x91CF;&#xFF08;Model&#xFF09;&#x5C06;&#x4F1A;&#x88AB;&#x4F18;&#x5316;&#xFF0C;&#x4F7F;&#x5F97;&#x6A21;&#x578B;&#x8868;&#x73B0;&#x5F97;&#x66F4;&#x597D;&#x3002;</li>
<li>&#x6A21;&#x578B;&#x672C;&#x8D28;&#x4E0A;&#x5C31;&#x662F;&#x4E00;&#x4E9B;&#x6570;&#x5B66;&#x51FD;&#x6570;&#xFF0C;&#x5B83;&#x6839;&#x636E;Placeholder&#x548C;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x5165;&#x53D8;&#x91CF;&#x6765;&#x8BA1;&#x7B97;&#x4E00;&#x4E9B;&#x8F93;&#x51FA;&#x3002;</li>
<li>&#x4E00;&#x4E2A;cost&#x5EA6;&#x91CF;&#x7528;&#x6765;&#x6307;&#x5BFC;&#x53D8;&#x91CF;&#x7684;&#x4F18;&#x5316;&#x3002;</li>
<li>&#x4E00;&#x4E2A;&#x4F18;&#x5316;&#x7B56;&#x7565;&#x4F1A;&#x66F4;&#x65B0;&#x6A21;&#x578B;&#x7684;&#x53D8;&#x91CF;&#x3002;</li>
</ul>
<p>&#x53E6;&#x5916;&#xFF0C;TensorFlow&#x56FE;&#x4E5F;&#x5305;&#x542B;&#x4E86;&#x4E00;&#x4E9B;&#x8C03;&#x8BD5;&#x72B6;&#x6001;&#xFF0C;&#x6BD4;&#x5982;&#x7528;TensorBoard&#x6253;&#x5370;log&#x6570;&#x636E;&#xFF0C;&#x672C;&#x6559;&#x7A0B;&#x4E0D;&#x6D89;&#x53CA;&#x8FD9;&#x4E9B;&#x3002;</p>
<h3 id="&#x5360;&#x4F4D;&#x7B26;-&#xFF08;placeholder&#xFF09;&#x53D8;&#x91CF;">&#x5360;&#x4F4D;&#x7B26; &#xFF08;Placeholder&#xFF09;&#x53D8;&#x91CF;</h3>
<p>Placeholder&#x662F;&#x4F5C;&#x4E3A;&#x56FE;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x6211;&#x4EEC;&#x6BCF;&#x6B21;&#x8FD0;&#x884C;&#x56FE;&#x7684;&#x65F6;&#x5019;&#x90FD;&#x53EF;&#x80FD;&#x6539;&#x53D8;&#x5B83;&#x4EEC;&#x3002;&#x5C06;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x79F0;&#x4E3A;feeding placeholder&#x53D8;&#x91CF;&#xFF0C;&#x540E;&#x9762;&#x5C06;&#x4F1A;&#x63CF;&#x8FF0;&#x8FD9;&#x4E2A;&#x3002;</p>
<p>&#x9996;&#x5148;&#x6211;&#x4EEC;&#x4E3A;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x5B9A;&#x4E49;placeholder&#x53D8;&#x91CF;&#x3002;&#x8FD9;&#x8BA9;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6539;&#x53D8;&#x8F93;&#x5165;&#x5230;TensorFlow&#x56FE;&#x4E2D;&#x7684;&#x56FE;&#x50CF;&#x3002;&#x8FD9;&#x4E5F;&#x662F;&#x4E00;&#x4E2A;&#x5F20;&#x91CF;&#xFF08;tensor&#xFF09;&#xFF0C;&#x4EE3;&#x8868;&#x4E00;&#x4E2A;&#x591A;&#x7EF4;&#x5411;&#x91CF;&#x6216;&#x77E9;&#x9635;&#x3002;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x8BBE;&#x7F6E;&#x4E3A;float32&#xFF0C;&#x5F62;&#x72B6;&#x8BBE;&#x4E3A;<code>[None, img_size_flat]</code>&#xFF0C;<code>None</code>&#x4EE3;&#x8868;tensor&#x53EF;&#x80FD;&#x4FDD;&#x5B58;&#x7740;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x56FE;&#x50CF;&#xFF0C;&#x6BCF;&#x5F20;&#x56FE;&#x8C61;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A;<code>img_size_flat</code>&#x7684;&#x5411;&#x91CF;&#x3002;</p>
<pre><code class="lang-python">x = tf.placeholder(tf.float32, shape=[<span class="hljs-keyword">None</span>, img_size_flat], name=<span class="hljs-string">&apos;x&apos;</span>)
</code></pre>
<p>&#x5377;&#x79EF;&#x5C42;&#x5E0C;&#x671B;<code>x</code>&#x88AB;&#x7F16;&#x7801;&#x4E3A;4&#x7EF4;&#x5F20;&#x91CF;&#xFF0C;&#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5C06;&#x5B83;&#x7684;&#x5F62;&#x72B6;&#x8F6C;&#x6362;&#x81F3;<code>[num_images, img_height, img_width, num_channels]</code>&#x3002;&#x6CE8;&#x610F;<code>img_height == img_width == img_size</code>&#xFF0C;&#x5982;&#x679C;&#x7B2C;&#x4E00;&#x7EF4;&#x7684;&#x5927;&#x5C0F;&#x8BBE;&#x4E3A;-1&#xFF0C; <code>num_images</code>&#x7684;&#x5927;&#x5C0F;&#x4E5F;&#x4F1A;&#x88AB;&#x81EA;&#x52A8;&#x63A8;&#x5BFC;&#x51FA;&#x6765;&#x3002;&#x8F6C;&#x6362;&#x8FD0;&#x7B97;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code class="lang-python">x_image = tf.reshape(x, [<span class="hljs-number">-1</span>, img_size, img_size, num_channels])
</code></pre>
<p>&#x63A5;&#x4E0B;&#x6765;&#x6211;&#x4EEC;&#x4E3A;&#x8F93;&#x5165;&#x53D8;&#x91CF;<code>x</code>&#x4E2D;&#x7684;&#x56FE;&#x50CF;&#x6240;&#x5BF9;&#x5E94;&#x7684;&#x771F;&#x5B9E;&#x6807;&#x7B7E;&#x5B9A;&#x4E49;placeholder&#x53D8;&#x91CF;&#x3002;&#x53D8;&#x91CF;&#x7684;&#x5F62;&#x72B6;&#x662F;<code>[None, num_classes]</code>&#xFF0C;&#x8FD9;&#x4EE3;&#x8868;&#x7740;&#x5B83;&#x4FDD;&#x5B58;&#x4E86;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x6807;&#x7B7E;&#xFF0C;&#x6BCF;&#x4E2A;&#x6807;&#x7B7E;&#x662F;&#x957F;&#x5EA6;&#x4E3A;<code>num_classes</code>&#x7684;&#x5411;&#x91CF;&#xFF0C;&#x672C;&#x4F8B;&#x4E2D;&#x957F;&#x5EA6;&#x4E3A;10&#x3002;</p>
<pre><code class="lang-python">y_true = tf.placeholder(tf.float32, shape=[<span class="hljs-keyword">None</span>, <span class="hljs-number">10</span>], name=<span class="hljs-string">&apos;y_true&apos;</span>)
</code></pre>
<p>&#x6211;&#x4EEC;&#x4E5F;&#x53EF;&#x4EE5;&#x4E3A;class-number&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;placeholder&#xFF0C;&#x4F46;&#x8FD9;&#x91CC;&#x7528;argmax&#x6765;&#x8BA1;&#x7B97;&#x5B83;&#x3002;&#x8FD9;&#x91CC;&#x53EA;&#x662F;TensorFlow&#x4E2D;&#x7684;&#x4E00;&#x4E9B;&#x64CD;&#x4F5C;&#xFF0C;&#x6CA1;&#x6709;&#x6267;&#x884C;&#x4EC0;&#x4E48;&#x8FD0;&#x7B97;&#x3002;</p>
<pre><code class="lang-python">y_true_cls = tf.argmax(y_true, dimension=<span class="hljs-number">1</span>)
</code></pre>
<h3 id="&#x795E;&#x7ECF;&#x7F51;&#x7EDC;">&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h3>
<p>&#x8FD9;&#x4E00;&#x8282;&#x7528;PrettyTensor&#x5B9E;&#x73B0;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x8FD9;&#x8981;&#x6BD4;&#x76F4;&#x63A5;&#x5728;TensorFlow&#x4E2D;&#x5B9E;&#x73B0;&#x6765;&#x5F97;&#x7B80;&#x5355;&#xFF0C;&#x8BE6;&#x89C1;&#x6559;&#x7A0B; #03&#x3002;</p>
<p>&#x57FA;&#x672C;&#x601D;&#x60F3;&#x5C31;&#x662F;&#x7528;&#x4E00;&#x4E2A;Pretty Tensor object&#x5C01;&#x88C5;&#x8F93;&#x5165;&#x5F20;&#x91CF;<code>x_image</code>&#xFF0C;&#x5B83;&#x6709;&#x4E00;&#x4E2A;&#x6DFB;&#x52A0;&#x65B0;&#x5377;&#x79EF;&#x5C42;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x521B;&#x5EFA;&#x6574;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;Pretty Tensor&#x8D1F;&#x8D23;&#x53D8;&#x91CF;&#x5206;&#x914D;&#x7B49;&#x7B49;&#x3002;</p>
<pre><code class="lang-python">x_pretty = pt.wrap(x_image)
</code></pre>
<p>&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x5C06;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x88C5;&#x5230;&#x4E00;&#x4E2A;PrettyTensor&#x7684;object&#x4E2D;&#xFF0C;&#x518D;&#x7528;&#x51E0;&#x884C;&#x4EE3;&#x7801;&#x5C31;&#x53EF;&#x4EE5;&#x6DFB;&#x52A0;&#x5377;&#x79EF;&#x5C42;&#x548C;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#x3002;</p>
<p>&#x6CE8;&#x610F;&#xFF0C;&#x5728;<code>with</code>&#x4EE3;&#x7801;&#x5757;&#x4E2D;&#xFF0C;<code>pt.defaults_scope(activation_fn=tf.nn.relu)</code> &#x628A; <code>activation_fn=tf.nn.relu</code>&#x5F53;&#x4F5C;&#x6BCF;&#x4E2A;&#x7684;&#x5C42;&#x53C2;&#x6570;&#xFF0C;&#x56E0;&#x6B64;&#x8FD9;&#x4E9B;&#x5C42;&#x90FD;&#x7528;&#x5230;&#x4E86; Rectified Linear Units (ReLU) &#x3002;<code>defaults_scope</code>&#x4F7F;&#x6211;&#x4EEC;&#x80FD;&#x66F4;&#x65B9;&#x4FBF;&#x5730;&#x4FEE;&#x6539;&#x6240;&#x6709;&#x5C42;&#x7684;&#x53C2;&#x6570;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">with</span> pt.defaults_scope(activation_fn=tf.nn.relu):
    y_pred, loss = x_pretty.\
        conv2d(kernel=<span class="hljs-number">5</span>, depth=<span class="hljs-number">16</span>, name=<span class="hljs-string">&apos;layer_conv1&apos;</span>).\
        max_pool(kernel=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>).\
        conv2d(kernel=<span class="hljs-number">5</span>, depth=<span class="hljs-number">36</span>, name=<span class="hljs-string">&apos;layer_conv2&apos;</span>).\
        max_pool(kernel=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>).\
        flatten().\
        fully_connected(size=<span class="hljs-number">128</span>, name=<span class="hljs-string">&apos;layer_fc1&apos;</span>).\
        softmax_classifier(num_classes=num_classes, labels=y_true)
</code></pre>
<h3 id="&#x4F18;&#x5316;&#x65B9;&#x6CD5;">&#x4F18;&#x5316;&#x65B9;&#x6CD5;</h3>
<p>PrettyTensor&#x7ED9;&#x6211;&#x4EEC;&#x63D0;&#x4F9B;&#x4E86;&#x9884;&#x6D4B;&#x7C7B;&#x578B;&#x6807;&#x7B7E;(<code>y_pred</code>)&#x4EE5;&#x53CA;&#x4E00;&#x4E2A;&#x9700;&#x8981;&#x6700;&#x5C0F;&#x5316;&#x7684;&#x635F;&#x5931;&#x5EA6;&#x91CF;&#xFF0C;&#x7528;&#x6765;&#x63D0;&#x5347;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5206;&#x7C7B;&#x56FE;&#x7247;&#x7684;&#x80FD;&#x529B;&#x3002;</p>
<p>PrettyTensor&#x7684;&#x6587;&#x6863;&#x5E76;&#x6CA1;&#x6709;&#x8BF4;&#x660E;&#x5B83;&#x7684;&#x635F;&#x5931;&#x5EA6;&#x91CF;&#x662F;&#x7528;cross-entropy&#x8FD8;&#x662F;&#x5176;&#x4ED6;&#x7684;&#x3002;&#x4F46;&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x7528;<code>AdamOptimizer</code>&#x6765;&#x6700;&#x5C0F;&#x5316;&#x635F;&#x5931;&#x3002;</p>
<p>&#x4F18;&#x5316;&#x8FC7;&#x7A0B;&#x5E76;&#x4E0D;&#x662F;&#x5728;&#x8FD9;&#x91CC;&#x6267;&#x884C;&#x3002;&#x5B9E;&#x9645;&#x4E0A;&#xFF0C;&#x8FD8;&#x6CA1;&#x8BA1;&#x7B97;&#x4EFB;&#x4F55;&#x4E1C;&#x897F;&#xFF0C;&#x6211;&#x4EEC;&#x53EA;&#x662F;&#x5F80;TensorFlow&#x56FE;&#x4E2D;&#x6DFB;&#x52A0;&#x4E86;&#x4F18;&#x5316;&#x5668;&#xFF0C;&#x4EE5;&#x4FBF;&#x540E;&#x7EED;&#x64CD;&#x4F5C;&#x3002;</p>
<pre><code class="lang-python">optimizer = tf.train.AdamOptimizer(learning_rate=<span class="hljs-number">1e-4</span>).minimize(loss)
</code></pre>
<h3 id="&#x6027;&#x80FD;&#x5EA6;&#x91CF;">&#x6027;&#x80FD;&#x5EA6;&#x91CF;</h3>
<p>&#x6211;&#x4EEC;&#x9700;&#x8981;&#x53E6;&#x5916;&#x4E00;&#x4E9B;&#x6027;&#x80FD;&#x5EA6;&#x91CF;&#xFF0C;&#x6765;&#x5411;&#x7528;&#x6237;&#x5C55;&#x793A;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x3002;</p>
<p>&#x9996;&#x5148;&#x6211;&#x4EEC;&#x4ECE;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8F93;&#x51FA;&#x7684;<code>y_pred</code>&#x4E2D;&#x8BA1;&#x7B97;&#x51FA;&#x9884;&#x6D4B;&#x7684;&#x7C7B;&#x522B;&#xFF0C;&#x5B83;&#x662F;&#x4E00;&#x4E2A;&#x5305;&#x542B;10&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x5411;&#x91CF;&#x3002;&#x7C7B;&#x522B;&#x6570;&#x5B57;&#x662F;&#x6700;&#x5927;&#x5143;&#x7D20;&#x7684;&#x7D22;&#x5F15;&#x3002;</p>
<pre><code class="lang-python">y_pred_cls = tf.argmax(y_pred, dimension=<span class="hljs-number">1</span>)
</code></pre>
<p>&#x7136;&#x540E;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;&#x5411;&#x91CF;&#xFF0C;&#x7528;&#x6765;&#x544A;&#x8BC9;&#x6211;&#x4EEC;&#x6BCF;&#x5F20;&#x56FE;&#x7247;&#x7684;&#x771F;&#x5B9E;&#x7C7B;&#x522B;&#x662F;&#x5426;&#x4E0E;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#x76F8;&#x540C;&#x3002;</p>
<pre><code class="lang-python">correct_prediction = tf.equal(y_pred_cls, y_true_cls)
</code></pre>
<p>&#x4E0A;&#x9762;&#x7684;&#x8BA1;&#x7B97;&#x5148;&#x5C06;&#x5E03;&#x5C14;&#x503C;&#x5411;&#x91CF;&#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x6210;&#x6D6E;&#x70B9;&#x578B;&#x5411;&#x91CF;&#xFF0C;&#x8FD9;&#x6837;&#x5B50;False&#x5C31;&#x53D8;&#x6210;0&#xFF0C;True&#x53D8;&#x6210;1&#xFF0C;&#x7136;&#x540E;&#x8BA1;&#x7B97;&#x8FD9;&#x4E9B;&#x503C;&#x7684;&#x5E73;&#x5747;&#x6570;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x8BA1;&#x7B97;&#x5206;&#x7C7B;&#x7684;&#x51C6;&#x786E;&#x5EA6;&#x3002;</p>
<pre><code class="lang-python">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</code></pre>
<h3 id="saver">Saver</h3>
<p>&#x4E3A;&#x4E86;&#x4FDD;&#x5B58;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x53D8;&#x91CF;&#xFF0C;&#x6211;&#x4EEC;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x79F0;&#x4E3A;Saver-object&#x7684;&#x5BF9;&#x8C61;&#xFF0C;&#x5B83;&#x7528;&#x6765;&#x4FDD;&#x5B58;&#x53CA;&#x6062;&#x590D;TensorFlow&#x56FE;&#x7684;&#x6240;&#x6709;&#x53D8;&#x91CF;&#x3002;&#x5728;&#x8FD9;&#x91CC;&#x5E76;&#x672A;&#x4FDD;&#x5B58;&#x4EC0;&#x4E48;&#x4E1C;&#x897F;&#xFF0C;&#xFF08;&#x4FDD;&#x5B58;&#x64CD;&#x4F5C;&#xFF09;&#x5728;&#x540E;&#x9762;&#x7684;<code>optimize()</code>&#x51FD;&#x6570;&#x4E2D;&#x5B8C;&#x6210;&#x3002;</p>
<p>&#x6CE8;&#x610F;&#xFF0C;&#x5982;&#x679C;&#x5728;ensemble&#x4E2D;&#x6709;&#x8D85;&#x8FC7;100&#x4E2A;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x4F60;&#x9700;&#x8981;&#x6839;&#x636E;&#x60C5;&#x51B5;&#x6765;&#x589E;&#x52A0;<code>max_to_keep</code>&#x3002;</p>
<pre><code class="lang-python">saver = tf.train.Saver(max_to_keep=<span class="hljs-number">100</span>)
</code></pre>
<p>&#x8FD9;&#x662F;&#x7528;&#x6765;&#x4FDD;&#x5B58;&#x6216;&#x6062;&#x590D;&#x6570;&#x636E;&#x7684;&#x6587;&#x4EF6;&#x5939;&#x3002;</p>
<pre><code class="lang-python">save_dir = <span class="hljs-string">&apos;checkpoints/&apos;</span>
</code></pre>
<p>&#x5982;&#x679C;&#x6587;&#x4EF6;&#x5939;&#x4E0D;&#x5B58;&#x5728;&#x5219;&#x521B;&#x5EFA;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(save_dir):
    os.makedirs(save_dir)
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x6839;&#x636E;&#x8F93;&#x5165;&#x7684;&#x7F51;&#x7EDC;&#x7F16;&#x53F7;&#x8FD4;&#x56DE;&#x6570;&#x636E;&#x6587;&#x4EF6;&#x7684;&#x4FDD;&#x5B58;&#x8DEF;&#x5F84;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_save_path</span><span class="hljs-params">(net_number)</span>:</span>
    <span class="hljs-keyword">return</span> save_dir + <span class="hljs-string">&apos;network&apos;</span> + str(net_number)
</code></pre>
<h2 id="&#x8FD0;&#x884C;tensorflow">&#x8FD0;&#x884C;TensorFlow</h2>
<h3 id="&#x521B;&#x5EFA;tensorflow&#x4F1A;&#x8BDD;&#xFF08;session&#xFF09;">&#x521B;&#x5EFA;TensorFlow&#x4F1A;&#x8BDD;&#xFF08;session&#xFF09;</h3>
<p>&#x4E00;&#x65E6;&#x521B;&#x5EFA;&#x4E86;TensorFlow&#x56FE;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;TensorFlow&#x4F1A;&#x8BDD;&#xFF0C;&#x7528;&#x6765;&#x8FD0;&#x884C;&#x56FE;&#x3002;</p>
<pre><code class="lang-python">session = tf.Session()
</code></pre>
<h3 id="&#x521D;&#x59CB;&#x5316;&#x53D8;&#x91CF;">&#x521D;&#x59CB;&#x5316;&#x53D8;&#x91CF;</h3>
<p>&#x53D8;&#x91CF;<code>weights</code>&#x548C;<code>biases</code>&#x5728;&#x4F18;&#x5316;&#x4E4B;&#x524D;&#x9700;&#x8981;&#x5148;&#x8FDB;&#x884C;&#x521D;&#x59CB;&#x5316;&#x3002;&#x6211;&#x4EEC;&#x5199;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x5C01;&#x88C5;&#x51FD;&#x6570;&#xFF0C;&#x540E;&#x9762;&#x4F1A;&#x518D;&#x6B21;&#x8C03;&#x7528;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_variables</span><span class="hljs-params">()</span>:</span>
    session.run(tf.initialize_all_variables())
</code></pre>
<h3 id="&#x521B;&#x5EFA;&#x968F;&#x673A;&#x8BAD;&#x7EC3;batch&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x521B;&#x5EFA;&#x968F;&#x673A;&#x8BAD;&#x7EC3;batch&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x96C6;&#x4E2D;&#x6709;&#x4E0A;&#x5343;&#x5F20;&#x56FE;&#x3002;&#x7528;&#x8FD9;&#x4E9B;&#x56FE;&#x50CF;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#x7684;&#x68AF;&#x5EA6;&#x4F1A;&#x82B1;&#x5F88;&#x591A;&#x65F6;&#x95F4;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5B83;&#x5728;&#x4F18;&#x5316;&#x5668;&#x7684;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x91CC;&#x53EA;&#x7528;&#x5230;&#x4E86;&#x4E00;&#x5C0F;&#x90E8;&#x5206;&#x7684;&#x56FE;&#x50CF;&#x3002;</p>
<p>&#x5982;&#x679C;&#x5185;&#x5B58;&#x8017;&#x5C3D;&#x5BFC;&#x81F4;&#x7535;&#x8111;&#x6B7B;&#x673A;&#x6216;&#x53D8;&#x5F97;&#x5F88;&#x6162;&#xFF0C;&#x4F60;&#x5E94;&#x8BE5;&#x8BD5;&#x7740;&#x51CF;&#x5C11;&#x8FD9;&#x4E9B;&#x6570;&#x91CF;&#xFF0C;&#x4F46;&#x540C;&#x65F6;&#x53EF;&#x80FD;&#x8FD8;&#x9700;&#x8981;&#x66F4;&#x4F18;&#x5316;&#x7684;&#x8FED;&#x4EE3;&#x3002;</p>
<pre><code class="lang-python">train_batch_size = <span class="hljs-number">64</span>
</code></pre>
<p>&#x51FD;&#x6570;&#x6839;&#x636E;&#x7ED9;&#x5B9A;&#x7684;&#x5927;&#x5C0F;&#x6311;&#x9009;&#x4E00;&#x4E2A;&#x968F;&#x673A;&#x7684;training-batch&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">random_batch</span><span class="hljs-params">(x_train, y_train)</span>:</span>
    <span class="hljs-comment"># Total number of images in the training-set.</span>
    num_images = len(x_train)

    <span class="hljs-comment"># Create a random index into the training-set.</span>
    idx = np.random.choice(num_images,
                           size=train_batch_size,
                           replace=<span class="hljs-keyword">False</span>)

    <span class="hljs-comment"># Use the random index to select random images and labels.</span>
    x_batch = x_train[idx, :]  <span class="hljs-comment"># Images.</span>
    y_batch = y_train[idx, :]  <span class="hljs-comment"># Labels.</span>

    <span class="hljs-comment"># Return the batch.</span>
    <span class="hljs-keyword">return</span> x_batch, y_batch
</code></pre>
<h3 id="&#x6267;&#x884C;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x6267;&#x884C;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x51FD;&#x6570;&#x7528;&#x6765;&#x6267;&#x884C;&#x4E00;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x9010;&#x6E10;&#x6539;&#x5584;&#x7F51;&#x7EDC;&#x5C42;&#x7684;&#x53D8;&#x91CF;&#x3002;&#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x4E2D;&#xFF0C;&#x4F1A;&#x4ECE;&#x8BAD;&#x7EC3;&#x96C6;&#x4E2D;&#x9009;&#x62E9;&#x65B0;&#x7684;&#x4E00;&#x6279;&#x6570;&#x636E;&#xFF0C;&#x7136;&#x540E;TensorFlow&#x5728;&#x8FD9;&#x4E9B;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x4E0A;&#x6267;&#x884C;&#x4F18;&#x5316;&#x3002;&#x6BCF;100&#x6B21;&#x8FED;&#x4EE3;&#x4F1A;&#x6253;&#x5370;&#x51FA;&#xFF08;&#x4FE1;&#x606F;&#xFF09;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">optimize</span><span class="hljs-params">(num_iterations, x_train, y_train)</span>:</span>
    <span class="hljs-comment"># Start-time used for printing time-usage below.</span>
    start_time = time.time()

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_iterations):

        <span class="hljs-comment"># Get a batch of training examples.</span>
        <span class="hljs-comment"># x_batch now holds a batch of images and</span>
        <span class="hljs-comment"># y_true_batch are the true labels for those images.</span>
        x_batch, y_true_batch = random_batch(x_train, y_train)

        <span class="hljs-comment"># Put the batch into a dict with the proper names</span>
        <span class="hljs-comment"># for placeholder variables in the TensorFlow graph.</span>
        feed_dict_train = {x: x_batch,
                           y_true: y_true_batch}

        <span class="hljs-comment"># Run the optimizer using this batch of training data.</span>
        <span class="hljs-comment"># TensorFlow assigns the variables in feed_dict_train</span>
        <span class="hljs-comment"># to the placeholder variables and then runs the optimizer.</span>
        session.run(optimizer, feed_dict=feed_dict_train)

        <span class="hljs-comment"># Print status every 100 iterations and after last iteration.</span>
        <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:

            <span class="hljs-comment"># Calculate the accuracy on the training-batch.</span>
            acc = session.run(accuracy, feed_dict=feed_dict_train)

            <span class="hljs-comment"># Status-message for printing.</span>
            msg = <span class="hljs-string">&quot;Optimization Iteration: {0:&gt;6}, Training Batch Accuracy: {1:&gt;6.1%}&quot;</span>

            <span class="hljs-comment"># Print it.</span>
            print(msg.format(i + <span class="hljs-number">1</span>, acc))

    <span class="hljs-comment"># Ending time.</span>
    end_time = time.time()

    <span class="hljs-comment"># Difference between start and end-times.</span>
    time_dif = end_time - start_time

    <span class="hljs-comment"># Print the time-usage.</span>
    print(<span class="hljs-string">&quot;Time usage: &quot;</span> + str(timedelta(seconds=int(round(time_dif)))))
</code></pre>
<h3 id="&#x521B;&#x5EFA;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#xFF08;ensemble&#xFF09;">&#x521B;&#x5EFA;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#xFF08;ensemble&#xFF09;</h3>
<p>&#x795E;&#x7ECF;&#x7F51;&#x7EDC;ensemble&#x7684;&#x6570;&#x91CF;</p>
<pre><code class="lang-python">num_networks = <span class="hljs-number">5</span>
</code></pre>
<p>&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x7684;&#x6B21;&#x6570;&#x3002;</p>
<pre><code class="lang-python">num_iterations = <span class="hljs-number">10000</span>
</code></pre>
<p>&#x521B;&#x5EFA;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;ensemble&#x3002;&#x6240;&#x6709;&#x7F51;&#x7EDC;&#x90FD;&#x4F7F;&#x7528;&#x4E0A;&#x9762;&#x5B9A;&#x4E49;&#x7684;&#x90A3;&#x4E2A;TensorFlow&#x56FE;&#x3002;&#x6BCF;&#x4E2A;&#x7F51;&#x7EDC;&#x7684;TensorFlow&#x6743;&#x91CD;&#x548C;&#x53D8;&#x91CF;&#x90FD;&#x7528;&#x968F;&#x673A;&#x503C;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x7136;&#x540E;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#x3002;&#x63A5;&#x7740;&#x5C06;&#x53D8;&#x91CF;&#x4FDD;&#x5B58;&#x5230;&#x78C1;&#x76D8;&#x4E2D;&#x4EE5;&#x4FBF;&#x4E4B;&#x540E;&#x91CD;&#x8F7D;&#x4F7F;&#x7528;&#x3002;</p>
<p>&#x5982;&#x679C;&#x4F60;&#x53EA;&#x662F;&#x60F3;&#x91CD;&#x65B0;&#x8FD0;&#x884C;Notebook&#x6765;&#x5BF9;&#x7ED3;&#x679C;&#x8FDB;&#x884C;&#x4E0D;&#x540C;&#x7684;&#x5206;&#x6790;&#xFF0C;&#x53EF;&#x4EE5;&#x8DF3;&#x8FC7;&#x8FD9;&#x4E00;&#x6B65;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">True</span>:
    <span class="hljs-comment"># For each of the neural networks.</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_networks):
        print(<span class="hljs-string">&quot;Neural network: {0}&quot;</span>.format(i))

        <span class="hljs-comment"># Create a random training-set. Ignore the validation-set.</span>
        x_train, y_train, _, _ = random_training_set()

        <span class="hljs-comment"># Initialize the variables of the TensorFlow graph.</span>
        session.run(tf.global_variables_initializer())

        <span class="hljs-comment"># Optimize the variables using this training-set.</span>
        optimize(num_iterations=num_iterations,
                 x_train=x_train,
                 y_train=y_train)

        <span class="hljs-comment"># Save the optimized variables to disk.</span>
        saver.save(sess=session, save_path=get_save_path(i))

        <span class="hljs-comment"># Print newline.</span>
        print()
</code></pre>
<pre><code>Neural network: 0
Optimization Iteration:      1, Training Batch Accuracy:   6.2%
Optimization Iteration:    101, Training Batch Accuracy:  87.5%
Optimization Iteration:    201, Training Batch Accuracy:  92.2%
Optimization Iteration:    301, Training Batch Accuracy:  92.2%
Optimization Iteration:    401, Training Batch Accuracy:  98.4%
Optimization Iteration:    501, Training Batch Accuracy:  95.3%
Optimization Iteration:    601, Training Batch Accuracy:  95.3%
Optimization Iteration:    701, Training Batch Accuracy:  96.9%
Optimization Iteration:    801, Training Batch Accuracy:  96.9%
Optimization Iteration:    901, Training Batch Accuracy:  98.4%
Optimization Iteration:   1001, Training Batch Accuracy:  95.3%
Optimization Iteration:   1101, Training Batch Accuracy:  96.9%
Optimization Iteration:   1201, Training Batch Accuracy:  95.3%
Optimization Iteration:   1301, Training Batch Accuracy: 100.0%
Optimization Iteration:   1401, Training Batch Accuracy:  98.4%
Optimization Iteration:   1501, Training Batch Accuracy: 100.0%
Optimization Iteration:   1601, Training Batch Accuracy:  98.4%
Optimization Iteration:   1701, Training Batch Accuracy:  96.9%
Optimization Iteration:   1801, Training Batch Accuracy: 100.0%
Optimization Iteration:   1901, Training Batch Accuracy:  98.4%
Optimization Iteration:   2001, Training Batch Accuracy:  95.3%
Optimization Iteration:   2101, Training Batch Accuracy:  98.4%
Optimization Iteration:   2201, Training Batch Accuracy:  96.9%
Optimization Iteration:   2301, Training Batch Accuracy:  96.9%
Optimization Iteration:   2401, Training Batch Accuracy: 100.0%
Optimization Iteration:   2501, Training Batch Accuracy:  96.9%
Optimization Iteration:   2601, Training Batch Accuracy: 100.0%
Optimization Iteration:   2701, Training Batch Accuracy:  98.4%
Optimization Iteration:   2801, Training Batch Accuracy:  98.4%
Optimization Iteration:   2901, Training Batch Accuracy:  98.4%
Optimization Iteration:   3001, Training Batch Accuracy:  95.3%
Optimization Iteration:   3101, Training Batch Accuracy: 100.0%
Optimization Iteration:   3201, Training Batch Accuracy:  98.4%
Optimization Iteration:   3301, Training Batch Accuracy:  98.4%
Optimization Iteration:   3401, Training Batch Accuracy:  96.9%
Optimization Iteration:   3501, Training Batch Accuracy:  98.4%
Optimization Iteration:   3601, Training Batch Accuracy: 100.0%
Optimization Iteration:   3701, Training Batch Accuracy:  98.4%
Optimization Iteration:   3801, Training Batch Accuracy: 100.0%
Optimization Iteration:   3901, Training Batch Accuracy: 100.0%
Optimization Iteration:   4001, Training Batch Accuracy: 100.0%
Optimization Iteration:   4101, Training Batch Accuracy: 100.0%
Optimization Iteration:   4201, Training Batch Accuracy:  96.9%
Optimization Iteration:   4301, Training Batch Accuracy:  98.4%
Optimization Iteration:   4401, Training Batch Accuracy: 100.0%
Optimization Iteration:   4501, Training Batch Accuracy:  96.9%
Optimization Iteration:   4601, Training Batch Accuracy: 100.0%
Optimization Iteration:   4701, Training Batch Accuracy:  96.9%
Optimization Iteration:   4801, Training Batch Accuracy:  96.9%
Optimization Iteration:   4901, Training Batch Accuracy: 100.0%
Optimization Iteration:   5001, Training Batch Accuracy:  95.3%
Optimization Iteration:   5101, Training Batch Accuracy: 100.0%
Optimization Iteration:   5201, Training Batch Accuracy:  98.4%
Optimization Iteration:   5301, Training Batch Accuracy: 100.0%
Optimization Iteration:   5401, Training Batch Accuracy: 100.0%
Optimization Iteration:   5501, Training Batch Accuracy: 100.0%
Optimization Iteration:   5601, Training Batch Accuracy: 100.0%
Optimization Iteration:   5701, Training Batch Accuracy: 100.0%
Optimization Iteration:   5801, Training Batch Accuracy: 100.0%
Optimization Iteration:   5901, Training Batch Accuracy: 100.0%
Optimization Iteration:   6001, Training Batch Accuracy: 100.0%
Optimization Iteration:   6101, Training Batch Accuracy: 100.0%
Optimization Iteration:   6201, Training Batch Accuracy: 100.0%
Optimization Iteration:   6301, Training Batch Accuracy:  98.4%
Optimization Iteration:   6401, Training Batch Accuracy:  98.4%
Optimization Iteration:   6501, Training Batch Accuracy: 100.0%
Optimization Iteration:   6601, Training Batch Accuracy: 100.0%
Optimization Iteration:   6701, Training Batch Accuracy: 100.0%
Optimization Iteration:   6801, Training Batch Accuracy: 100.0%
Optimization Iteration:   6901, Training Batch Accuracy:  98.4%
Optimization Iteration:   7001, Training Batch Accuracy:  98.4%
Optimization Iteration:   7101, Training Batch Accuracy: 100.0%
Optimization Iteration:   7201, Training Batch Accuracy:  98.4%
Optimization Iteration:   7301, Training Batch Accuracy: 100.0%
Optimization Iteration:   7401, Training Batch Accuracy: 100.0%
Optimization Iteration:   7501, Training Batch Accuracy: 100.0%
Optimization Iteration:   7601, Training Batch Accuracy: 100.0%
Optimization Iteration:   7701, Training Batch Accuracy:  98.4%
Optimization Iteration:   7801, Training Batch Accuracy:  96.9%
Optimization Iteration:   7901, Training Batch Accuracy: 100.0%
Optimization Iteration:   8001, Training Batch Accuracy:  98.4%
Optimization Iteration:   8101, Training Batch Accuracy:  98.4%
Optimization Iteration:   8201, Training Batch Accuracy: 100.0%
Optimization Iteration:   8301, Training Batch Accuracy: 100.0%
Optimization Iteration:   8401, Training Batch Accuracy: 100.0%
Optimization Iteration:   8501, Training Batch Accuracy: 100.0%
Optimization Iteration:   8601, Training Batch Accuracy: 100.0%
Optimization Iteration:   8701, Training Batch Accuracy: 100.0%
Optimization Iteration:   8801, Training Batch Accuracy:  96.9%
Optimization Iteration:   8901, Training Batch Accuracy: 100.0%
Optimization Iteration:   9001, Training Batch Accuracy: 100.0%
Optimization Iteration:   9101, Training Batch Accuracy:  98.4%
Optimization Iteration:   9201, Training Batch Accuracy: 100.0%
Optimization Iteration:   9301, Training Batch Accuracy: 100.0%
Optimization Iteration:   9401, Training Batch Accuracy: 100.0%
Optimization Iteration:   9501, Training Batch Accuracy:  98.4%
Optimization Iteration:   9601, Training Batch Accuracy: 100.0%
Optimization Iteration:   9701, Training Batch Accuracy: 100.0%
Optimization Iteration:   9801, Training Batch Accuracy: 100.0%
Optimization Iteration:   9901, Training Batch Accuracy: 100.0%
Time usage: 0:00:40

Neural network: 1
Optimization Iteration:      1, Training Batch Accuracy:   7.8%
Optimization Iteration:    101, Training Batch Accuracy:  85.9%
Optimization Iteration:    201, Training Batch Accuracy:  95.3%
Optimization Iteration:    301, Training Batch Accuracy:  90.6%
Optimization Iteration:    401, Training Batch Accuracy:  92.2%
Optimization Iteration:    501, Training Batch Accuracy:  95.3%
Optimization Iteration:    601, Training Batch Accuracy:  95.3%
Optimization Iteration:    701, Training Batch Accuracy:  93.8%
Optimization Iteration:    801, Training Batch Accuracy:  96.9%
Optimization Iteration:    901, Training Batch Accuracy:  95.3%
Optimization Iteration:   1001, Training Batch Accuracy:  95.3%
Optimization Iteration:   1101, Training Batch Accuracy:  96.9%
Optimization Iteration:   1201, Training Batch Accuracy:  96.9%
Optimization Iteration:   1301, Training Batch Accuracy:  98.4%
Optimization Iteration:   1401, Training Batch Accuracy: 100.0%
Optimization Iteration:   1501, Training Batch Accuracy: 100.0%
Optimization Iteration:   1601, Training Batch Accuracy:  96.9%
Optimization Iteration:   1701, Training Batch Accuracy:  95.3%
Optimization Iteration:   1801, Training Batch Accuracy:  98.4%
Optimization Iteration:   1901, Training Batch Accuracy:  98.4%
Optimization Iteration:   2001, Training Batch Accuracy:  98.4%
Optimization Iteration:   2101, Training Batch Accuracy:  98.4%
Optimization Iteration:   2201, Training Batch Accuracy: 100.0%
Optimization Iteration:   2301, Training Batch Accuracy:  98.4%
Optimization Iteration:   2401, Training Batch Accuracy:  96.9%
Optimization Iteration:   2501, Training Batch Accuracy: 100.0%
Optimization Iteration:   2601, Training Batch Accuracy:  98.4%
Optimization Iteration:   2701, Training Batch Accuracy:  95.3%
Optimization Iteration:   2801, Training Batch Accuracy:  96.9%
Optimization Iteration:   2901, Training Batch Accuracy:  96.9%
Optimization Iteration:   3001, Training Batch Accuracy:  98.4%
Optimization Iteration:   3101, Training Batch Accuracy: 100.0%
Optimization Iteration:   3201, Training Batch Accuracy: 100.0%
Optimization Iteration:   3301, Training Batch Accuracy:  96.9%
Optimization Iteration:   3401, Training Batch Accuracy:  96.9%
Optimization Iteration:   3501, Training Batch Accuracy:  98.4%
Optimization Iteration:   3601, Training Batch Accuracy:  98.4%
Optimization Iteration:   3701, Training Batch Accuracy: 100.0%
Optimization Iteration:   3801, Training Batch Accuracy:  96.9%
Optimization Iteration:   3901, Training Batch Accuracy: 100.0%
Optimization Iteration:   4001, Training Batch Accuracy: 100.0%
Optimization Iteration:   4101, Training Batch Accuracy: 100.0%
Optimization Iteration:   4201, Training Batch Accuracy: 100.0%
Optimization Iteration:   4301, Training Batch Accuracy:  98.4%
Optimization Iteration:   4401, Training Batch Accuracy: 100.0%
Optimization Iteration:   4501, Training Batch Accuracy:  98.4%
Optimization Iteration:   4601, Training Batch Accuracy:  98.4%
Optimization Iteration:   4701, Training Batch Accuracy:  98.4%
Optimization Iteration:   4801, Training Batch Accuracy:  96.9%
Optimization Iteration:   4901, Training Batch Accuracy:  98.4%
Optimization Iteration:   5001, Training Batch Accuracy:  98.4%
Optimization Iteration:   5101, Training Batch Accuracy: 100.0%
Optimization Iteration:   5201, Training Batch Accuracy: 100.0%
Optimization Iteration:   5301, Training Batch Accuracy: 100.0%
Optimization Iteration:   5401, Training Batch Accuracy: 100.0%
Optimization Iteration:   5501, Training Batch Accuracy:  98.4%
Optimization Iteration:   5601, Training Batch Accuracy: 100.0%
Optimization Iteration:   5701, Training Batch Accuracy:  96.9%
Optimization Iteration:   5801, Training Batch Accuracy:  98.4%
Optimization Iteration:   5901, Training Batch Accuracy:  96.9%
Optimization Iteration:   6001, Training Batch Accuracy: 100.0%
Optimization Iteration:   6101, Training Batch Accuracy: 100.0%
Optimization Iteration:   6201, Training Batch Accuracy: 100.0%
Optimization Iteration:   6301, Training Batch Accuracy:  98.4%
Optimization Iteration:   6401, Training Batch Accuracy:  98.4%
Optimization Iteration:   6501, Training Batch Accuracy: 100.0%
Optimization Iteration:   6601, Training Batch Accuracy: 100.0%
Optimization Iteration:   6701, Training Batch Accuracy:  98.4%
Optimization Iteration:   6801, Training Batch Accuracy: 100.0%
Optimization Iteration:   6901, Training Batch Accuracy: 100.0%
Optimization Iteration:   7001, Training Batch Accuracy: 100.0%
Optimization Iteration:   7101, Training Batch Accuracy: 100.0%
Optimization Iteration:   7201, Training Batch Accuracy:  96.9%
Optimization Iteration:   7301, Training Batch Accuracy: 100.0%
Optimization Iteration:   7401, Training Batch Accuracy: 100.0%
Optimization Iteration:   7501, Training Batch Accuracy: 100.0%
Optimization Iteration:   7601, Training Batch Accuracy: 100.0%
Optimization Iteration:   7701, Training Batch Accuracy:  98.4%
Optimization Iteration:   7801, Training Batch Accuracy: 100.0%
Optimization Iteration:   7901, Training Batch Accuracy: 100.0%
Optimization Iteration:   8001, Training Batch Accuracy:  98.4%
Optimization Iteration:   8101, Training Batch Accuracy: 100.0%
Optimization Iteration:   8201, Training Batch Accuracy: 100.0%
Optimization Iteration:   8301, Training Batch Accuracy: 100.0%
Optimization Iteration:   8401, Training Batch Accuracy:  98.4%
Optimization Iteration:   8501, Training Batch Accuracy:  98.4%
Optimization Iteration:   8601, Training Batch Accuracy: 100.0%
Optimization Iteration:   8701, Training Batch Accuracy:  98.4%
Optimization Iteration:   8801, Training Batch Accuracy: 100.0%
Optimization Iteration:   8901, Training Batch Accuracy: 100.0%
Optimization Iteration:   9001, Training Batch Accuracy: 100.0%
Optimization Iteration:   9101, Training Batch Accuracy: 100.0%
Optimization Iteration:   9201, Training Batch Accuracy: 100.0%
Optimization Iteration:   9301, Training Batch Accuracy: 100.0%
Optimization Iteration:   9401, Training Batch Accuracy: 100.0%
Optimization Iteration:   9501, Training Batch Accuracy: 100.0%
Optimization Iteration:   9601, Training Batch Accuracy: 100.0%
Optimization Iteration:   9701, Training Batch Accuracy: 100.0%
Optimization Iteration:   9801, Training Batch Accuracy:  98.4%
Optimization Iteration:   9901, Training Batch Accuracy:  98.4%
Time usage: 0:00:40

Neural network: 2
Optimization Iteration:      1, Training Batch Accuracy:   3.1%
Optimization Iteration:    101, Training Batch Accuracy:  84.4%
Optimization Iteration:    201, Training Batch Accuracy:  87.5%
Optimization Iteration:    301, Training Batch Accuracy:  87.5%
Optimization Iteration:    401, Training Batch Accuracy:  98.4%
Optimization Iteration:    501, Training Batch Accuracy:  93.8%
Optimization Iteration:    601, Training Batch Accuracy:  98.4%
Optimization Iteration:    701, Training Batch Accuracy:  93.8%
Optimization Iteration:    801, Training Batch Accuracy: 100.0%
Optimization Iteration:    901, Training Batch Accuracy: 100.0%
Optimization Iteration:   1001, Training Batch Accuracy:  96.9%
Optimization Iteration:   1101, Training Batch Accuracy:  93.8%
Optimization Iteration:   1201, Training Batch Accuracy:  96.9%
Optimization Iteration:   1301, Training Batch Accuracy:  96.9%
Optimization Iteration:   1401, Training Batch Accuracy:  95.3%
Optimization Iteration:   1501, Training Batch Accuracy:  98.4%
Optimization Iteration:   1601, Training Batch Accuracy:  96.9%
Optimization Iteration:   1701, Training Batch Accuracy:  95.3%
Optimization Iteration:   1801, Training Batch Accuracy:  98.4%
Optimization Iteration:   1901, Training Batch Accuracy: 100.0%
Optimization Iteration:   2001, Training Batch Accuracy:  98.4%
Optimization Iteration:   2101, Training Batch Accuracy:  98.4%
Optimization Iteration:   2201, Training Batch Accuracy:  98.4%
Optimization Iteration:   2301, Training Batch Accuracy:  96.9%
Optimization Iteration:   2401, Training Batch Accuracy:  95.3%
Optimization Iteration:   2501, Training Batch Accuracy:  92.2%
Optimization Iteration:   2601, Training Batch Accuracy: 100.0%
Optimization Iteration:   2701, Training Batch Accuracy: 100.0%
Optimization Iteration:   2801, Training Batch Accuracy:  95.3%
Optimization Iteration:   2901, Training Batch Accuracy: 100.0%
Optimization Iteration:   3001, Training Batch Accuracy:  98.4%
Optimization Iteration:   3101, Training Batch Accuracy:  93.8%
Optimization Iteration:   3201, Training Batch Accuracy:  98.4%
Optimization Iteration:   3301, Training Batch Accuracy:  96.9%
Optimization Iteration:   3401, Training Batch Accuracy: 100.0%
Optimization Iteration:   3501, Training Batch Accuracy:  95.3%
Optimization Iteration:   3601, Training Batch Accuracy:  98.4%
Optimization Iteration:   3701, Training Batch Accuracy:  98.4%
Optimization Iteration:   3801, Training Batch Accuracy: 100.0%
Optimization Iteration:   3901, Training Batch Accuracy:  95.3%
Optimization Iteration:   4001, Training Batch Accuracy: 100.0%
Optimization Iteration:   4101, Training Batch Accuracy: 100.0%
Optimization Iteration:   4201, Training Batch Accuracy: 100.0%
Optimization Iteration:   4301, Training Batch Accuracy:  98.4%
Optimization Iteration:   4401, Training Batch Accuracy:  98.4%
Optimization Iteration:   4501, Training Batch Accuracy: 100.0%
Optimization Iteration:   4601, Training Batch Accuracy: 100.0%
Optimization Iteration:   4701, Training Batch Accuracy:  98.4%
Optimization Iteration:   4801, Training Batch Accuracy: 100.0%
Optimization Iteration:   4901, Training Batch Accuracy: 100.0%
Optimization Iteration:   5001, Training Batch Accuracy:  98.4%
Optimization Iteration:   5101, Training Batch Accuracy:  96.9%
Optimization Iteration:   5201, Training Batch Accuracy: 100.0%
Optimization Iteration:   5301, Training Batch Accuracy: 100.0%
Optimization Iteration:   5401, Training Batch Accuracy:  98.4%
Optimization Iteration:   5501, Training Batch Accuracy:  98.4%
Optimization Iteration:   5601, Training Batch Accuracy:  98.4%
Optimization Iteration:   5701, Training Batch Accuracy: 100.0%
Optimization Iteration:   5801, Training Batch Accuracy: 100.0%
Optimization Iteration:   5901, Training Batch Accuracy:  98.4%
Optimization Iteration:   6001, Training Batch Accuracy: 100.0%
Optimization Iteration:   6101, Training Batch Accuracy: 100.0%
Optimization Iteration:   6201, Training Batch Accuracy: 100.0%
Optimization Iteration:   6301, Training Batch Accuracy:  98.4%
Optimization Iteration:   6401, Training Batch Accuracy: 100.0%
Optimization Iteration:   6501, Training Batch Accuracy:  98.4%
Optimization Iteration:   6601, Training Batch Accuracy: 100.0%
Optimization Iteration:   6701, Training Batch Accuracy: 100.0%
Optimization Iteration:   6801, Training Batch Accuracy:  98.4%
Optimization Iteration:   6901, Training Batch Accuracy: 100.0%
Optimization Iteration:   7001, Training Batch Accuracy:  98.4%
Optimization Iteration:   7101, Training Batch Accuracy: 100.0%
Optimization Iteration:   7201, Training Batch Accuracy: 100.0%
Optimization Iteration:   7301, Training Batch Accuracy:  98.4%
Optimization Iteration:   7401, Training Batch Accuracy:  96.9%
Optimization Iteration:   7501, Training Batch Accuracy: 100.0%
Optimization Iteration:   7601, Training Batch Accuracy:  98.4%
Optimization Iteration:   7701, Training Batch Accuracy:  98.4%
Optimization Iteration:   7801, Training Batch Accuracy: 100.0%
Optimization Iteration:   7901, Training Batch Accuracy:  98.4%
Optimization Iteration:   8001, Training Batch Accuracy:  98.4%
Optimization Iteration:   8101, Training Batch Accuracy:  96.9%
Optimization Iteration:   8201, Training Batch Accuracy: 100.0%
Optimization Iteration:   8301, Training Batch Accuracy:  98.4%
Optimization Iteration:   8401, Training Batch Accuracy: 100.0%
Optimization Iteration:   8501, Training Batch Accuracy: 100.0%
Optimization Iteration:   8601, Training Batch Accuracy:  98.4%
Optimization Iteration:   8701, Training Batch Accuracy: 100.0%
Optimization Iteration:   8801, Training Batch Accuracy: 100.0%
Optimization Iteration:   8901, Training Batch Accuracy: 100.0%
Optimization Iteration:   9001, Training Batch Accuracy: 100.0%
Optimization Iteration:   9101, Training Batch Accuracy:  98.4%
Optimization Iteration:   9201, Training Batch Accuracy:  98.4%
Optimization Iteration:   9301, Training Batch Accuracy: 100.0%
Optimization Iteration:   9401, Training Batch Accuracy: 100.0%
Optimization Iteration:   9501, Training Batch Accuracy: 100.0%
Optimization Iteration:   9601, Training Batch Accuracy:  98.4%
Optimization Iteration:   9701, Training Batch Accuracy:  95.3%
Optimization Iteration:   9801, Training Batch Accuracy:  96.9%
Optimization Iteration:   9901, Training Batch Accuracy: 100.0%
Time usage: 0:00:39

Neural network: 3
Optimization Iteration:      1, Training Batch Accuracy:   9.4%
Optimization Iteration:    101, Training Batch Accuracy:  89.1%
Optimization Iteration:    201, Training Batch Accuracy:  89.1%
Optimization Iteration:    301, Training Batch Accuracy:  90.6%
Optimization Iteration:    401, Training Batch Accuracy:  93.8%
Optimization Iteration:    501, Training Batch Accuracy:  93.8%
Optimization Iteration:    601, Training Batch Accuracy:  90.6%
Optimization Iteration:    701, Training Batch Accuracy:  96.9%
Optimization Iteration:    801, Training Batch Accuracy:  93.8%
Optimization Iteration:    901, Training Batch Accuracy:  96.9%
Optimization Iteration:   1001, Training Batch Accuracy:  98.4%
Optimization Iteration:   1101, Training Batch Accuracy: 100.0%
Optimization Iteration:   1201, Training Batch Accuracy: 100.0%
Optimization Iteration:   1301, Training Batch Accuracy:  98.4%
Optimization Iteration:   1401, Training Batch Accuracy:  96.9%
Optimization Iteration:   1501, Training Batch Accuracy:  96.9%
Optimization Iteration:   1601, Training Batch Accuracy:  98.4%
Optimization Iteration:   1701, Training Batch Accuracy:  92.2%
Optimization Iteration:   1801, Training Batch Accuracy:  96.9%
Optimization Iteration:   1901, Training Batch Accuracy:  98.4%
Optimization Iteration:   2001, Training Batch Accuracy:  93.8%
Optimization Iteration:   2101, Training Batch Accuracy:  98.4%
Optimization Iteration:   2201, Training Batch Accuracy: 100.0%
Optimization Iteration:   2301, Training Batch Accuracy: 100.0%
Optimization Iteration:   2401, Training Batch Accuracy: 100.0%
Optimization Iteration:   2501, Training Batch Accuracy: 100.0%
Optimization Iteration:   2601, Training Batch Accuracy: 100.0%
Optimization Iteration:   2701, Training Batch Accuracy:  96.9%
Optimization Iteration:   2801, Training Batch Accuracy: 100.0%
Optimization Iteration:   2901, Training Batch Accuracy:  95.3%
Optimization Iteration:   3001, Training Batch Accuracy: 100.0%
Optimization Iteration:   3101, Training Batch Accuracy: 100.0%
Optimization Iteration:   3201, Training Batch Accuracy: 100.0%
Optimization Iteration:   3301, Training Batch Accuracy:  98.4%
Optimization Iteration:   3401, Training Batch Accuracy:  98.4%
Optimization Iteration:   3501, Training Batch Accuracy:  98.4%
Optimization Iteration:   3601, Training Batch Accuracy: 100.0%
Optimization Iteration:   3701, Training Batch Accuracy: 100.0%
Optimization Iteration:   3801, Training Batch Accuracy:  95.3%
Optimization Iteration:   3901, Training Batch Accuracy:  98.4%
Optimization Iteration:   4001, Training Batch Accuracy: 100.0%
Optimization Iteration:   4101, Training Batch Accuracy:  98.4%
Optimization Iteration:   4201, Training Batch Accuracy: 100.0%
Optimization Iteration:   4301, Training Batch Accuracy:  95.3%
Optimization Iteration:   4401, Training Batch Accuracy: 100.0%
Optimization Iteration:   4501, Training Batch Accuracy: 100.0%
Optimization Iteration:   4601, Training Batch Accuracy: 100.0%
Optimization Iteration:   4701, Training Batch Accuracy:  95.3%
Optimization Iteration:   4801, Training Batch Accuracy:  98.4%
Optimization Iteration:   4901, Training Batch Accuracy:  98.4%
Optimization Iteration:   5001, Training Batch Accuracy:  98.4%
Optimization Iteration:   5101, Training Batch Accuracy:  98.4%
Optimization Iteration:   5201, Training Batch Accuracy: 100.0%
Optimization Iteration:   5301, Training Batch Accuracy: 100.0%
Optimization Iteration:   5401, Training Batch Accuracy: 100.0%
Optimization Iteration:   5501, Training Batch Accuracy: 100.0%
Optimization Iteration:   5601, Training Batch Accuracy: 100.0%
Optimization Iteration:   5701, Training Batch Accuracy: 100.0%
Optimization Iteration:   5801, Training Batch Accuracy: 100.0%
Optimization Iteration:   5901, Training Batch Accuracy: 100.0%
Optimization Iteration:   6001, Training Batch Accuracy: 100.0%
Optimization Iteration:   6101, Training Batch Accuracy: 100.0%
Optimization Iteration:   6201, Training Batch Accuracy:  95.3%
Optimization Iteration:   6301, Training Batch Accuracy: 100.0%
Optimization Iteration:   6401, Training Batch Accuracy:  98.4%
Optimization Iteration:   6501, Training Batch Accuracy: 100.0%
Optimization Iteration:   6601, Training Batch Accuracy:  98.4%
Optimization Iteration:   6701, Training Batch Accuracy: 100.0%
Optimization Iteration:   6801, Training Batch Accuracy: 100.0%
Optimization Iteration:   6901, Training Batch Accuracy: 100.0%
Optimization Iteration:   7001, Training Batch Accuracy: 100.0%
Optimization Iteration:   7101, Training Batch Accuracy: 100.0%
Optimization Iteration:   7201, Training Batch Accuracy: 100.0%
Optimization Iteration:   7301, Training Batch Accuracy: 100.0%
Optimization Iteration:   7401, Training Batch Accuracy: 100.0%
Optimization Iteration:   7501, Training Batch Accuracy: 100.0%
Optimization Iteration:   7601, Training Batch Accuracy: 100.0%
Optimization Iteration:   7701, Training Batch Accuracy: 100.0%
Optimization Iteration:   7801, Training Batch Accuracy:  98.4%
Optimization Iteration:   7901, Training Batch Accuracy: 100.0%
Optimization Iteration:   8001, Training Batch Accuracy:  98.4%
Optimization Iteration:   8101, Training Batch Accuracy: 100.0%
Optimization Iteration:   8201, Training Batch Accuracy: 100.0%
Optimization Iteration:   8301, Training Batch Accuracy: 100.0%
Optimization Iteration:   8401, Training Batch Accuracy: 100.0%
Optimization Iteration:   8501, Training Batch Accuracy: 100.0%
Optimization Iteration:   8601, Training Batch Accuracy: 100.0%
Optimization Iteration:   8701, Training Batch Accuracy: 100.0%
Optimization Iteration:   8801, Training Batch Accuracy: 100.0%
Optimization Iteration:   8901, Training Batch Accuracy: 100.0%
Optimization Iteration:   9001, Training Batch Accuracy: 100.0%
Optimization Iteration:   9101, Training Batch Accuracy:  98.4%
Optimization Iteration:   9201, Training Batch Accuracy: 100.0%
Optimization Iteration:   9301, Training Batch Accuracy: 100.0%
Optimization Iteration:   9401, Training Batch Accuracy: 100.0%
Optimization Iteration:   9501, Training Batch Accuracy:  96.9%
Optimization Iteration:   9601, Training Batch Accuracy:  98.4%
Optimization Iteration:   9701, Training Batch Accuracy:  98.4%
Optimization Iteration:   9801, Training Batch Accuracy:  98.4%
Optimization Iteration:   9901, Training Batch Accuracy: 100.0%
Time usage: 0:00:39

Neural network: 4
Optimization Iteration:      1, Training Batch Accuracy:   9.4%
Optimization Iteration:    101, Training Batch Accuracy:  82.8%
Optimization Iteration:    201, Training Batch Accuracy:  89.1%
Optimization Iteration:    301, Training Batch Accuracy:  89.1%
Optimization Iteration:    401, Training Batch Accuracy:  96.9%
Optimization Iteration:    501, Training Batch Accuracy:  96.9%
Optimization Iteration:    601, Training Batch Accuracy:  98.4%
Optimization Iteration:    701, Training Batch Accuracy:  96.9%
Optimization Iteration:    801, Training Batch Accuracy:  93.8%
Optimization Iteration:    901, Training Batch Accuracy:  96.9%
Optimization Iteration:   1001, Training Batch Accuracy:  98.4%
Optimization Iteration:   1101, Training Batch Accuracy:  96.9%
Optimization Iteration:   1201, Training Batch Accuracy:  93.8%
Optimization Iteration:   1301, Training Batch Accuracy:  96.9%
Optimization Iteration:   1401, Training Batch Accuracy:  98.4%
Optimization Iteration:   1501, Training Batch Accuracy:  95.3%
Optimization Iteration:   1601, Training Batch Accuracy:  96.9%
Optimization Iteration:   1701, Training Batch Accuracy:  98.4%
Optimization Iteration:   1801, Training Batch Accuracy:  93.8%
Optimization Iteration:   1901, Training Batch Accuracy:  96.9%
Optimization Iteration:   2001, Training Batch Accuracy: 100.0%
Optimization Iteration:   2101, Training Batch Accuracy:  95.3%
Optimization Iteration:   2201, Training Batch Accuracy:  96.9%
Optimization Iteration:   2301, Training Batch Accuracy:  96.9%
Optimization Iteration:   2401, Training Batch Accuracy:  93.8%
Optimization Iteration:   2501, Training Batch Accuracy:  98.4%
Optimization Iteration:   2601, Training Batch Accuracy:  96.9%
Optimization Iteration:   2701, Training Batch Accuracy:  98.4%
Optimization Iteration:   2801, Training Batch Accuracy:  98.4%
Optimization Iteration:   2901, Training Batch Accuracy:  98.4%
Optimization Iteration:   3001, Training Batch Accuracy:  96.9%
Optimization Iteration:   3101, Training Batch Accuracy:  98.4%
Optimization Iteration:   3201, Training Batch Accuracy:  98.4%
Optimization Iteration:   3301, Training Batch Accuracy: 100.0%
Optimization Iteration:   3401, Training Batch Accuracy:  98.4%
Optimization Iteration:   3501, Training Batch Accuracy:  96.9%
Optimization Iteration:   3601, Training Batch Accuracy:  98.4%
Optimization Iteration:   3701, Training Batch Accuracy:  98.4%
Optimization Iteration:   3801, Training Batch Accuracy:  98.4%
Optimization Iteration:   3901, Training Batch Accuracy: 100.0%
Optimization Iteration:   4001, Training Batch Accuracy:  98.4%
Optimization Iteration:   4101, Training Batch Accuracy: 100.0%
Optimization Iteration:   4201, Training Batch Accuracy: 100.0%
Optimization Iteration:   4301, Training Batch Accuracy: 100.0%
Optimization Iteration:   4401, Training Batch Accuracy:  98.4%
Optimization Iteration:   4501, Training Batch Accuracy:  98.4%
Optimization Iteration:   4601, Training Batch Accuracy:  98.4%
Optimization Iteration:   4701, Training Batch Accuracy: 100.0%
Optimization Iteration:   4801, Training Batch Accuracy: 100.0%
Optimization Iteration:   4901, Training Batch Accuracy:  96.9%
Optimization Iteration:   5001, Training Batch Accuracy: 100.0%
Optimization Iteration:   5101, Training Batch Accuracy:  98.4%
Optimization Iteration:   5201, Training Batch Accuracy: 100.0%
Optimization Iteration:   5301, Training Batch Accuracy: 100.0%
Optimization Iteration:   5401, Training Batch Accuracy:  98.4%
Optimization Iteration:   5501, Training Batch Accuracy: 100.0%
Optimization Iteration:   5601, Training Batch Accuracy:  98.4%
Optimization Iteration:   5701, Training Batch Accuracy:  95.3%
Optimization Iteration:   5801, Training Batch Accuracy: 100.0%
Optimization Iteration:   5901, Training Batch Accuracy: 100.0%
Optimization Iteration:   6001, Training Batch Accuracy:  98.4%
Optimization Iteration:   6101, Training Batch Accuracy: 100.0%
Optimization Iteration:   6201, Training Batch Accuracy:  96.9%
Optimization Iteration:   6301, Training Batch Accuracy:  98.4%
Optimization Iteration:   6401, Training Batch Accuracy: 100.0%
Optimization Iteration:   6501, Training Batch Accuracy: 100.0%
Optimization Iteration:   6601, Training Batch Accuracy: 100.0%
Optimization Iteration:   6701, Training Batch Accuracy: 100.0%
Optimization Iteration:   6801, Training Batch Accuracy:  96.9%
Optimization Iteration:   6901, Training Batch Accuracy:  96.9%
Optimization Iteration:   7001, Training Batch Accuracy: 100.0%
Optimization Iteration:   7101, Training Batch Accuracy: 100.0%
Optimization Iteration:   7201, Training Batch Accuracy:  96.9%
Optimization Iteration:   7301, Training Batch Accuracy: 100.0%
Optimization Iteration:   7401, Training Batch Accuracy: 100.0%
Optimization Iteration:   7501, Training Batch Accuracy: 100.0%
Optimization Iteration:   7601, Training Batch Accuracy: 100.0%
Optimization Iteration:   7701, Training Batch Accuracy: 100.0%
Optimization Iteration:   7801, Training Batch Accuracy: 100.0%
Optimization Iteration:   7901, Training Batch Accuracy:  93.8%
Optimization Iteration:   8001, Training Batch Accuracy: 100.0%
Optimization Iteration:   8101, Training Batch Accuracy:  98.4%
Optimization Iteration:   8201, Training Batch Accuracy: 100.0%
Optimization Iteration:   8301, Training Batch Accuracy: 100.0%
Optimization Iteration:   8401, Training Batch Accuracy: 100.0%
Optimization Iteration:   8501, Training Batch Accuracy:  98.4%
Optimization Iteration:   8601, Training Batch Accuracy: 100.0%
Optimization Iteration:   8701, Training Batch Accuracy:  98.4%
Optimization Iteration:   8801, Training Batch Accuracy: 100.0%
Optimization Iteration:   8901, Training Batch Accuracy:  98.4%
Optimization Iteration:   9001, Training Batch Accuracy: 100.0%
Optimization Iteration:   9101, Training Batch Accuracy: 100.0%
Optimization Iteration:   9201, Training Batch Accuracy: 100.0%
Optimization Iteration:   9301, Training Batch Accuracy: 100.0%
Optimization Iteration:   9401, Training Batch Accuracy: 100.0%
Optimization Iteration:   9501, Training Batch Accuracy: 100.0%
Optimization Iteration:   9601, Training Batch Accuracy: 100.0%
Optimization Iteration:   9701, Training Batch Accuracy: 100.0%
Optimization Iteration:   9801, Training Batch Accuracy: 100.0%
Optimization Iteration:   9901, Training Batch Accuracy:  98.4%
Time usage: 0:00:39
</code></pre><h3 id="&#x8BA1;&#x7B97;&#x5E76;&#x4E14;&#x9884;&#x6D4B;&#x5206;&#x7C7B;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x8BA1;&#x7B97;&#x5E76;&#x4E14;&#x9884;&#x6D4B;&#x5206;&#x7C7B;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x4E86;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF0C;&#x5BF9;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x6765;&#x8BF4;&#xFF0C;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x4E86;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A;10&#x7684;&#x5411;&#x91CF;&#xFF0C;&#x5411;&#x91CF;&#x663E;&#x793A;&#x4E86;&#x56FE;&#x50CF;&#x7684;&#x7C7B;&#x522B;&#x3002;</p>
<p>&#x8BA1;&#x7B97;&#x5206;&#x6279;&#x5B8C;&#x6210;&#xFF0C;&#x5426;&#x5219;&#x5C06;&#x5360;&#x7528;&#x592A;&#x591A;&#x5185;&#x5B58;&#x3002;&#x5982;&#x679C;&#x7535;&#x8111;&#x6B7B;&#x673A;&#x4E86;&#xFF0C;&#x4F60;&#x9700;&#x8981;&#x964D;&#x4F4E;batch-size&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># Split the data-set in batches of this size to limit RAM usage.</span>
batch_size = <span class="hljs-number">256</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_labels</span><span class="hljs-params">(images)</span>:</span>
    <span class="hljs-comment"># Number of images.</span>
    num_images = len(images)

    <span class="hljs-comment"># Allocate an array for the predicted labels which</span>
    <span class="hljs-comment"># will be calculated in batches and filled into this array.</span>
    pred_labels = np.zeros(shape=(num_images, num_classes),
                           dtype=np.float)

    <span class="hljs-comment"># Now calculate the predicted labels for the batches.</span>
    <span class="hljs-comment"># We will just iterate through all the batches.</span>
    <span class="hljs-comment"># There might be a more clever and Pythonic way of doing this.</span>

    <span class="hljs-comment"># The starting index for the next batch is denoted i.</span>
    i = <span class="hljs-number">0</span>

    <span class="hljs-keyword">while</span> i &lt; num_images:
        <span class="hljs-comment"># The ending index for the next batch is denoted j.</span>
        j = min(i + batch_size, num_images)

        <span class="hljs-comment"># Create a feed-dict with the images between index i and j.</span>
        feed_dict = {x: images[i:j, :]}

        <span class="hljs-comment"># Calculate the predicted labels using TensorFlow.</span>
        pred_labels[i:j] = session.run(y_pred, feed_dict=feed_dict)

        <span class="hljs-comment"># Set the start-index for the next batch to the</span>
        <span class="hljs-comment"># end-index of the current batch.</span>
        i = j

    <span class="hljs-keyword">return</span> pred_labels
</code></pre>
<p>&#x8BA1;&#x7B97;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;&#x503C;&#x5411;&#x91CF;&#xFF0C;&#x4EE3;&#x8868;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x7C7B;&#x578B;&#x662F;&#x5426;&#x6B63;&#x786E;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">correct_prediction</span><span class="hljs-params">(images, labels, cls_true)</span>:</span>
    <span class="hljs-comment"># Calculate the predicted labels.</span>
    pred_labels = predict_labels(images=images)

    <span class="hljs-comment"># Calculate the predicted class-number for each image.</span>
    cls_pred = np.argmax(pred_labels, axis=<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Create a boolean array whether each image is correctly classified.</span>
    correct = (cls_true == cls_pred)

    <span class="hljs-keyword">return</span> correct
</code></pre>
<p>&#x8BA1;&#x7B97;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#xFF0C;&#x4EE3;&#x8868;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x5206;&#x7C7B;&#x6B63;&#x786E;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_correct</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> correct_prediction(images = data.test.images,
                              labels = data.test.labels,
                              cls_true = data.test.cls)
</code></pre>
<p>&#x8BA1;&#x7B97;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#xFF0C;&#x4EE3;&#x8868;&#x9A8C;&#x8BC1;&#x96C6;&#x4E2D;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x5206;&#x7C7B;&#x6B63;&#x786E;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validation_correct</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> correct_prediction(images = data.validation.images,
                              labels = data.validation.labels,
                              cls_true = data.validation.cls)
</code></pre>
<h3 id="&#x8BA1;&#x7B97;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x8BA1;&#x7B97;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x4E86;&#x7ED9;&#x5B9A;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#xFF0C;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x8868;&#x793A;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x88AB;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x3002;&#x6BD4;&#x5982;&#xFF0C; <code>cls_accuracy([True, True, False, False, False]) = 2/5 = 0.4</code>&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">classification_accuracy</span><span class="hljs-params">(correct)</span>:</span>
    <span class="hljs-comment"># When averaging a boolean array, False means 0 and True means 1.</span>
    <span class="hljs-comment"># So we are calculating: number of True / len(correct) which is</span>
    <span class="hljs-comment"># the same as the classification accuracy.</span>
    <span class="hljs-keyword">return</span> correct.mean()
</code></pre>
<p>&#x8BA1;&#x7B97;&#x6D4B;&#x8BD5;&#x96C6;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_accuracy</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># Get the array of booleans whether the classifications are correct</span>
    <span class="hljs-comment"># for the test-set.</span>
    correct = test_correct()

    <span class="hljs-comment"># Calculate the classification accuracy and return it.</span>
    <span class="hljs-keyword">return</span> classification_accuracy(correct)
</code></pre>
<p>&#x8BA1;&#x7B97;&#x539F;&#x59CB;&#x9A8C;&#x8BC1;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validation_accuracy</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># Get the array of booleans whether the classifications are correct</span>
    <span class="hljs-comment"># for the validation-set.</span>
    correct = validation_correct()

    <span class="hljs-comment"># Calculate the classification accuracy and return it.</span>
    <span class="hljs-keyword">return</span> classification_accuracy(correct)
</code></pre>
<h2 id="&#x7ED3;&#x679C;&#x4E0E;&#x5206;&#x6790;">&#x7ED3;&#x679C;&#x4E0E;&#x5206;&#x6790;</h2>
<p>&#x51FD;&#x6570;&#x7528;&#x6765;&#x4E3A;ensemble&#x4E2D;&#x7684;&#x6240;&#x6709;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BA1;&#x7B97;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x3002;&#x540E;&#x9762;&#x4F1A;&#x5C06;&#x8FD9;&#x4E9B;&#x6807;&#x7B7E;&#x5408;&#x5E76;&#x8D77;&#x6765;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">ensemble_predictions</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-comment"># Empty list of predicted labels for each of the neural networks.</span>
    pred_labels = []

    <span class="hljs-comment"># Classification accuracy on the test-set for each network.</span>
    test_accuracies = []

    <span class="hljs-comment"># Classification accuracy on the validation-set for each network.</span>
    val_accuracies = []

    <span class="hljs-comment"># For each neural network in the ensemble.</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_networks):
        <span class="hljs-comment"># Reload the variables into the TensorFlow graph.</span>
        saver.restore(sess=session, save_path=get_save_path(i))

        <span class="hljs-comment"># Calculate the classification accuracy on the test-set.</span>
        test_acc = test_accuracy()

        <span class="hljs-comment"># Append the classification accuracy to the list.</span>
        test_accuracies.append(test_acc)

        <span class="hljs-comment"># Calculate the classification accuracy on the validation-set.</span>
        val_acc = validation_accuracy()

        <span class="hljs-comment"># Append the classification accuracy to the list.</span>
        val_accuracies.append(val_acc)

        <span class="hljs-comment"># Print status message.</span>
        msg = <span class="hljs-string">&quot;Network: {0}, Accuracy on Validation-Set: {1:.4f}, Test-Set: {2:.4f}&quot;</span>
        print(msg.format(i, val_acc, test_acc))

        <span class="hljs-comment"># Calculate the predicted labels for the images in the test-set.</span>
        <span class="hljs-comment"># This is already calculated in test_accuracy() above but</span>
        <span class="hljs-comment"># it is re-calculated here to keep the code a bit simpler.</span>
        pred = predict_labels(images=data.test.images)

        <span class="hljs-comment"># Append the predicted labels to the list.</span>
        pred_labels.append(pred)

    <span class="hljs-keyword">return</span> np.array(pred_labels), \
           np.array(test_accuracies), \
           np.array(val_accuracies)
</code></pre>
<pre><code class="lang-python">pred_labels, test_accuracies, val_accuracies = ensemble_predictions()
</code></pre>
<pre><code>Network: 0, Accuracy on Validation-Set: 0.9948, Test-Set: 0.9893
Network: 1, Accuracy on Validation-Set: 0.9936, Test-Set: 0.9880
Network: 2, Accuracy on Validation-Set: 0.9958, Test-Set: 0.9893
Network: 3, Accuracy on Validation-Set: 0.9938, Test-Set: 0.9889
Network: 4, Accuracy on Validation-Set: 0.9938, Test-Set: 0.9892
</code></pre><p>&#x603B;&#x7ED3;ensemble&#x4E2D;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;Mean test-set accuracy: {0:.4f}&quot;</span>.format(np.mean(test_accuracies)))
print(<span class="hljs-string">&quot;Min test-set accuracy:  {0:.4f}&quot;</span>.format(np.min(test_accuracies)))
print(<span class="hljs-string">&quot;Max test-set accuracy:  {0:.4f}&quot;</span>.format(np.max(test_accuracies)))
</code></pre>
<pre><code>Mean test-set accuracy: 0.9889
Min test-set accuracy:  0.9880
Max test-set accuracy:  0.9893
</code></pre><p>ensemble&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x662F;3&#x7EF4;&#x7684;&#x6570;&#x7EC4;&#xFF0C;&#x7B2C;&#x4E00;&#x7EF4;&#x662F;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6570;&#x91CF;&#xFF0C;&#x7B2C;&#x4E8C;&#x7EF4;&#x662F;&#x56FE;&#x50CF;&#x6570;&#x91CF;&#xFF0C;&#x7B2C;&#x4E09;&#x7EF4;&#x662F;&#x5206;&#x7C7B;&#x5411;&#x91CF;&#x3002;</p>
<pre><code class="lang-python">pred_labels.shape
</code></pre>
<pre><code>(5, 10000, 10)
</code></pre><h3 id="ensemble&#x9884;&#x6D4B;">ensemble&#x9884;&#x6D4B;</h3>
<p>&#x6709;&#x51E0;&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x65B9;&#x6CD5;&#x6765;&#x8BA1;&#x7B97;ensemble&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x3002;&#x4E00;&#x79CD;&#x662F;&#x8BA1;&#x7B97;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#x6570;&#x5B57;&#xFF0C;&#x7136;&#x540E;&#x9009;&#x62E9;&#x5F97;&#x7968;&#x6700;&#x591A;&#x7684;&#x90A3;&#x4E2A;&#x7C7B;&#x522B;&#x3002;&#x4F46;&#x6839;&#x636E;&#x5206;&#x7C7B;&#x7684;&#x7C7B;&#x522B;&#x6570;&#x91CF;&#xFF0C;&#x8FD9;&#x79CD;&#x65B9;&#x6CD5;&#x9700;&#x8981;&#x5927;&#x91CF;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
<p>&#x8FD9;&#x91CC;&#x7528;&#x7684;&#x65B9;&#x6CD5;&#x662F;&#x53D6;ensemble&#x4E2D;&#x6240;&#x6709;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x7684;&#x5E73;&#x5747;&#x3002;&#x8FD9;&#x4E2A;&#x8BA1;&#x7B97;&#x5F88;&#x7B80;&#x5355;&#xFF0C;&#x800C;&#x4E14;&#x96C6;&#x6210;&#x79CD;&#x4E0D;&#x9700;&#x8981;&#x5927;&#x91CF;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
<pre><code class="lang-python">ensemble_pred_labels = np.mean(pred_labels, axis=<span class="hljs-number">0</span>)
ensemble_pred_labels.shape
</code></pre>
<pre><code>(10000, 10)
</code></pre><p>&#x53D6;&#x6807;&#x7B7E;&#x4E2D;&#x6700;&#x5927;&#x6570;&#x5B57;&#x7684;&#x7D22;&#x5F15;&#x4F5C;&#x4E3A;ensemble&#x7684;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#x6570;&#x5B57;&#xFF0C;&#x8FD9;&#x901A;&#x5E38;&#x7528;argmax&#x6765;&#x8BA1;&#x7B97;&#x3002;</p>
<pre><code class="lang-python">ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=<span class="hljs-number">1</span>)
ensemble_cls_pred.shape
</code></pre>
<pre><code>(10000,)
</code></pre><p>&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x8868;&#x793A;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x7684;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x88AB;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;ensemble&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x3002;</p>
<pre><code class="lang-python">ensemble_correct = (ensemble_cls_pred == data.test.cls)
</code></pre>
<p>&#x5BF9;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x53D6;&#x53CD;&#xFF0C;&#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x7528;&#x5B83;&#x6765;&#x67E5;&#x627E;&#x8BEF;&#x5206;&#x7C7B;&#x7684;&#x56FE;&#x50CF;&#x3002;</p>
<pre><code class="lang-python">ensemble_incorrect = np.logical_not(ensemble_correct)
</code></pre>
<h3 id="&#x6700;&#x4F73;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;">&#x6700;&#x4F73;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h3>
<p>&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x627E;&#x51FA;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x8868;&#x73B0;&#x6700;&#x4F73;&#x7684;&#x5355;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
<p>&#x9996;&#x5148;&#x5217;&#x51FA;ensemble&#x4E2D;&#x6240;&#x6709;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<pre><code class="lang-python">test_accuracies
</code></pre>
<pre><code>array([ 0.9893,  0.988 ,  0.9893,  0.9889,  0.9892])
</code></pre><p>&#x51C6;&#x786E;&#x7387;&#x6700;&#x9AD8;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7D22;&#x5F15;&#x3002;</p>
<pre><code class="lang-python">best_net = np.argmax(test_accuracies)
best_net
</code></pre>
<pre><code>0
</code></pre><p>&#x6700;&#x4F73;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x3002;</p>
<pre><code class="lang-python">test_accuracies[best_net]
</code></pre>
<pre><code>0.98929999999999996
</code></pre><p>&#x6700;&#x4F73;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x3002;</p>
<pre><code class="lang-python">best_net_pred_labels = pred_labels[best_net, :, :]
</code></pre>
<p>&#x9884;&#x6D4B;&#x7684;&#x7C7B;&#x522B;&#x6570;&#x5B57;&#x3002;</p>
<pre><code class="lang-python">best_net_cls_pred = np.argmax(best_net_pred_labels, axis=<span class="hljs-number">1</span>)
</code></pre>
<p>&#x6700;&#x4F73;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x662F;&#x5426;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x56FE;&#x50CF;&#x7684;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x3002;</p>
<pre><code class="lang-python">best_net_correct = (best_net_cls_pred == data.test.cls)
</code></pre>
<p>&#x56FE;&#x50CF;&#x662F;&#x5426;&#x88AB;&#x8BEF;&#x5206;&#x7C7B;&#x7684;&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x3002;</p>
<pre><code class="lang-python">best_net_incorrect = np.logical_not(best_net_correct)
</code></pre>
<h3 id="ensemble&#x4E0E;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x7684;&#x6BD4;&#x8F83;">ensemble&#x4E0E;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x7684;&#x6BD4;&#x8F83;</h3>
<p>&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x88AB;ensemble&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x7684;&#x56FE;&#x50CF;&#x6570;&#x91CF;&#x3002;</p>
<pre><code class="lang-python">np.sum(ensemble_correct)
</code></pre>
<pre><code>9916
</code></pre><p>&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x88AB;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x7684;&#x56FE;&#x50CF;&#x6570;&#x91CF;&#x3002;</p>
<pre><code class="lang-python">np.sum(best_net_correct)
</code></pre>
<pre><code>9893
</code></pre><p>&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x8868;&#x793A;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x201C;&#x88AB;ensemble&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x4E14;&#x88AB;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x8BEF;&#x5206;&#x7C7B;&#x201D;&#x3002;</p>
<pre><code class="lang-python">ensemble_better = np.logical_and(best_net_incorrect,
                                 ensemble_correct)
</code></pre>
<p>&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;ensemble&#x6BD4;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x8868;&#x73B0;&#x66F4;&#x597D;&#x7684;&#x56FE;&#x50CF;&#x6570;&#x91CF;&#xFF1A;</p>
<pre><code class="lang-python">ensemble_better.sum()
</code></pre>
<pre><code>39
</code></pre><p>&#x5E03;&#x5C14;&#x6570;&#x7EC4;&#x8868;&#x793A;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x662F;&#x5426;&#x201C;&#x88AB;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x4E14;&#x88AB;ensemble&#x8BEF;&#x5206;&#x7C7B;&#x201D;&#x3002;</p>
<pre><code class="lang-python">best_net_better = np.logical_and(best_net_correct,
                                 ensemble_incorrect)
</code></pre>
<p>&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6BD4;ensemble&#x8868;&#x73B0;&#x66F4;&#x597D;&#x7684;&#x56FE;&#x50CF;&#x6570;&#x91CF;&#xFF1A;</p>
<pre><code class="lang-python">best_net_better.sum()
</code></pre>
<pre><code>16
</code></pre><h3 id="&#x7ED8;&#x5236;&#x4EE5;&#x53CA;&#x6253;&#x5370;&#x5BF9;&#x6BD4;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x7ED8;&#x5236;&#x4EE5;&#x53CA;&#x6253;&#x5370;&#x5BF9;&#x6BD4;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x51FD;&#x6570;&#x7528;&#x6765;&#x7ED8;&#x5236;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x7684;&#x56FE;&#x50CF;&#xFF0C;&#x4EE5;&#x53CA;&#x5B83;&#x4EEC;&#x7684;&#x771F;&#x5B9E;&#x7C7B;&#x522B;&#x4E0E;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_images_comparison</span><span class="hljs-params">(idx)</span>:</span>
    plot_images(images=data.test.images[idx, :],
                cls_true=data.test.cls[idx],
                ensemble_cls_pred=ensemble_cls_pred[idx],
                best_cls_pred=best_net_cls_pred[idx])
</code></pre>
<p>&#x6253;&#x5370;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x7684;&#x51FD;&#x6570;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_labels</span><span class="hljs-params">(labels, idx, num=<span class="hljs-number">1</span>)</span>:</span>
    <span class="hljs-comment"># Select the relevant labels based on idx.</span>
    labels = labels[idx, :]

    <span class="hljs-comment"># Select the first num labels.</span>
    labels = labels[<span class="hljs-number">0</span>:num, :]

    <span class="hljs-comment"># Round numbers to 2 decimal points so they are easier to read.</span>
    labels_rounded = np.round(labels, <span class="hljs-number">2</span>)

    <span class="hljs-comment"># Print the rounded labels.</span>
    print(labels_rounded)
</code></pre>
<p>Function for printing the predicted labels for the ensemble of neural networks.</p>
<p>&#x6253;&#x5370;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;ensemble&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x7684;&#x51FD;&#x6570;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_labels_ensemble</span><span class="hljs-params">(idx, **kwargs)</span>:</span>
    print_labels(labels=ensemble_pred_labels, idx=idx, **kwargs)
</code></pre>
<p>&#x6253;&#x5370;&#x5355;&#x4E2A;&#x7F51;&#x7EDC;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x7684;&#x51FD;&#x6570;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_labels_best_net</span><span class="hljs-params">(idx, **kwargs)</span>:</span>
    print_labels(labels=best_net_pred_labels, idx=idx, **kwargs)
</code></pre>
<p>&#x6253;&#x5370;ensemble&#x4E2D;&#x6240;&#x6709;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x7684;&#x51FD;&#x6570;&#x3002;&#x53EA;&#x6253;&#x5370;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x6807;&#x7B7E;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_labels_all_nets</span><span class="hljs-params">(idx)</span>:</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_networks):
        print_labels(labels=pred_labels[i, :, :], idx=idx, num=<span class="hljs-number">1</span>)
</code></pre>
<h2 id="&#x6837;&#x672C;&#xFF1A;ensemble&#x6BD4;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x597D;">&#x6837;&#x672C;&#xFF1A;ensemble&#x6BD4;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x597D;</h2>
<p>&#x7ED8;&#x5236;&#x51FA;&#x90A3;&#x4E9B;&#x88AB;&#x96C6;&#x6210;&#x7F51;&#x7EDC;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#xFF0C;&#x4E14;&#x88AB;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x8BEF;&#x5206;&#x7C7B;&#x7684;&#x6837;&#x672C;&#x3002;</p>
<pre><code class="lang-python">plot_images_comparison(idx=ensemble_better)
</code></pre>
<p><img src="output_160_0.png" alt="png"></p>
<p>ensemble&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#xFF08;&#x5DE6;&#x4E0A;&#xFF09;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_ensemble(idx=ensemble_better, num=<span class="hljs-number">1</span>)
</code></pre>
<pre><code>[[ 0.    0.    0.    0.76  0.    0.    0.    0.    0.23  0.  ]]
</code></pre><p>&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_best_net(idx=ensemble_better, num=<span class="hljs-number">1</span>)
</code></pre>
<pre><code>[[ 0.    0.    0.    0.21  0.    0.    0.    0.    0.79  0.  ]]
</code></pre><p>ensemble&#x4E2D;&#x6240;&#x6709;&#x7F51;&#x7EDC;&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_all_nets(idx=ensemble_better)
</code></pre>
<pre><code>[[ 0.    0.    0.    0.21  0.    0.    0.    0.    0.79  0.  ]]
[[ 0.    0.    0.    0.96  0.    0.01  0.    0.    0.03  0.  ]]
[[ 0.    0.    0.    0.99  0.    0.    0.    0.    0.01  0.  ]]
[[ 0.    0.    0.    0.88  0.    0.    0.    0.    0.12  0.  ]]
[[ 0.    0.    0.    0.76  0.    0.01  0.    0.    0.22  0.  ]]
</code></pre><h2 id="&#x6837;&#x672C;&#xFF1A;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6BD4;ensemble&#x597D;">&#x6837;&#x672C;&#xFF1A;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6BD4;ensemble&#x597D;</h2>
<p>&#x73B0;&#x5728;&#x7ED8;&#x5236;&#x90A3;&#x4E9B;&#x88AB;ensemble&#x8BEF;&#x5206;&#x7C7B;&#xFF0C;&#x4F46;&#x88AB;&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x7684;&#x6837;&#x672C;&#x3002;</p>
<pre><code class="lang-python">plot_images_comparison(idx=best_net_better)
</code></pre>
<p><img src="output_168_0.png" alt="png"></p>
<p>ensemble&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#xFF08;&#x5DE6;&#x4E0A;&#xFF09;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_ensemble(idx=best_net_better, num=<span class="hljs-number">1</span>)
</code></pre>
<pre><code>[[ 0.5   0.    0.    0.    0.    0.05  0.45  0.    0.    0.  ]]
</code></pre><p>&#x6700;&#x4F73;&#x7F51;&#x7EDC;&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_best_net(idx=best_net_better, num=<span class="hljs-number">1</span>)
</code></pre>
<pre><code>[[ 0.3   0.    0.    0.    0.    0.15  0.56  0.    0.    0.  ]]
</code></pre><p>ensemble&#x4E2D;&#x6240;&#x6709;&#x7F51;&#x7EDC;&#x5BF9;&#x7B2C;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#xFF1A;</p>
<pre><code class="lang-python">print_labels_all_nets(idx=best_net_better)
</code></pre>
<pre><code>[[ 0.3   0.    0.    0.    0.    0.15  0.56  0.    0.    0.  ]]
[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]
[[ 0.19  0.    0.    0.    0.    0.    0.81  0.    0.    0.  ]]
[[ 0.15  0.    0.    0.    0.    0.12  0.72  0.    0.    0.  ]]
[[ 0.85  0.    0.    0.    0.    0.    0.14  0.    0.    0.  ]]
</code></pre><h2 id="&#x5173;&#x95ED;tensorflow&#x4F1A;&#x8BDD;">&#x5173;&#x95ED;TensorFlow&#x4F1A;&#x8BDD;</h2>
<p>&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x7528;TensorFlow&#x5B8C;&#x6210;&#x4E86;&#x4EFB;&#x52A1;&#xFF0C;&#x5173;&#x95ED;session&#xFF0C;&#x91CA;&#x653E;&#x8D44;&#x6E90;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># This has been commented out in case you want to modify and experiment</span>
<span class="hljs-comment"># with the Notebook without having to restart it.</span>
<span class="hljs-comment"># session.close()</span>
</code></pre>
<h2 id="&#x603B;&#x7ED3;">&#x603B;&#x7ED3;</h2>
<p>&#x8FD9;&#x7BC7;&#x6559;&#x7A0B;&#x521B;&#x5EFA;&#x4E86;5&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#xFF08;ensemble&#xFF09;&#xFF0C;&#x7528;&#x6765;&#x8BC6;&#x522B;MINIST&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x7684;&#x624B;&#x5199;&#x6570;&#x5B57;&#x3002;ensemble&#x53D6;5&#x4E2A;&#x5355;&#x72EC;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x5E73;&#x5747;&#x503C;&#x3002;&#x6700;&#x7EC8;&#x7A0D;&#x5FAE;&#x63D0;&#x9AD8;&#x4E86;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#xFF0C;&#x76F8;&#x6BD4;&#x5355;&#x4E2A;&#x6700;&#x4F73;&#x7F51;&#x7EDC;98.9%&#x7684;&#x51C6;&#x786E;&#x7387;&#xFF0C;ensemble&#x662F;99.1%&#x3002;</p>
<p>&#x7136;&#x800C;&#xFF0C;ensemble&#x7684;&#x8868;&#x73B0;&#x5E76;&#x4E0D;&#x662F;&#x4E00;&#x76F4;&#x90FD;&#x6BD4;&#x5355;&#x4E2A;&#x7F51;&#x7EDC;&#x597D;&#xFF0C;&#x6709;&#x4E9B;&#x5355;&#x4E2A;&#x7F51;&#x7EDC;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x7684;&#x56FE;&#x50CF;&#x5374;&#x88AB;ensemble&#x8BEF;&#x5206;&#x7C7B;&#x3002;&#x8FD9;&#x8868;&#x660E;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;ensemble&#x7684;&#x4F5C;&#x7528;&#x6709;&#x70B9;&#x968F;&#x673A;&#xFF0C;&#x53EF;&#x80FD;&#x65E0;&#x6CD5;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;&#x63D0;&#x5347;&#x6027;&#x80FD;&#x7684;&#x53EF;&#x9760;&#x65B9;&#x5F0F;&#xFF08;&#x548C;&#x5355;&#x72EC;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6027;&#x80FD;&#x76F8;&#x6BD4;&#xFF09;&#x3002;</p>
<p>&#x8FD9;&#x91CC;&#x4F7F;&#x7528;&#x7684;&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x7684;&#x5F62;&#x5F0F;&#x53EB;<a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" target="_blank">bagging</a> (&#x6216; Bootstrap Aggregating)&#xFF0C;&#x5B83;&#x5E38;&#x7528;&#x6765;&#x907F;&#x514D;&#x8FC7;&#x62DF;&#x5408;&#xFF0C;&#x4F46;&#x5BF9;&#xFF08;&#x672C;&#x6587;&#x4E2D;&#x7684;&#xFF09;&#x8FD9;&#x4E2A;&#x7279;&#x5B9A;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x548C;&#x6570;&#x636E;&#x96C6;&#x6765;&#x8BF4;&#x4E0D;&#x662F;&#x5FC5;&#x8981;&#x7684;&#x3002;&#x5728;&#x5176;&#x4ED6;&#x60C5;&#x51B5;&#x4E0B;&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x53EF;&#x80FD;&#x4ECD;&#x7136;&#x6709;&#x6548;&#x3002;</p>
<h3 id="&#x6280;&#x672F;&#x8BF4;&#x660E;">&#x6280;&#x672F;&#x8BF4;&#x660E;</h3>
<p>&#x672C;&#x6587;&#x5728;&#x5B9E;&#x73B0;&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x65F6;&#x7528;&#x4E86;TensorFlow&#x4E2D;<code>Saver()</code>&#x5BF9;&#x8C61;&#x6765;&#x4FDD;&#x5B58;&#x548C;&#x6062;&#x590D;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x53D8;&#x91CF;&#x3002;&#x4F46;&#x8FD9;&#x4E2A;&#x529F;&#x80FD;&#x5176;&#x5B9E;&#x662F;&#x4E3A;&#x5176;&#x4ED6;&#x76EE;&#x7684;&#x8BBE;&#x8BA1;&#x7684;&#xFF0C;&#x4F7F;&#x7528;&#x5728;&#x6709;&#x591A;&#x79CD;&#x7C7B;&#x578B;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x4E2D;&#xFF0C;&#x6216;&#x8005;&#x60F3;&#x540C;&#x65F6;&#x8F7D;&#x5165;&#x591A;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x65F6;&#x5C31;&#x6709;&#x70B9;&#x7B28;&#x62D9;&#x4E86;&#x3002;&#x6709;&#x4E00;&#x4E2A;&#x53EB; <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn" target="_blank">sk-flow</a> &#x7684;TensorFlow&#x6DFB;&#x52A0;&#x5305;&#x6709;&#x66F4;&#x7B80;&#x5355;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x4F46;&#x5230;2016&#x5E74;&#x516B;&#x6708;&#x4E3A;&#x6B62;&#xFF0C;&#x5B83;&#x4ECD;&#x7136;&#x5904;&#x4E8E;&#x5F00;&#x53D1;&#x7684;&#x524D;&#x671F;&#x9636;&#x6BB5;&#x3002;</p>
<h2 id="&#x7EC3;&#x4E60;">&#x7EC3;&#x4E60;</h2>
<p>&#x4E0B;&#x9762;&#x662F;&#x4E00;&#x4E9B;&#x53EF;&#x80FD;&#x4F1A;&#x8BA9;&#x4F60;&#x63D0;&#x5347;TensorFlow&#x6280;&#x80FD;&#x7684;&#x4E00;&#x4E9B;&#x5EFA;&#x8BAE;&#x7EC3;&#x4E60;&#x3002;&#x4E3A;&#x4E86;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x66F4;&#x5408;&#x9002;&#x5730;&#x4F7F;&#x7528;TensorFlow&#xFF0C;&#x5B9E;&#x8DF5;&#x7ECF;&#x9A8C;&#x662F;&#x5F88;&#x91CD;&#x8981;&#x7684;&#x3002;</p>
<p>&#x5728;&#x4F60;&#x5BF9;&#x8FD9;&#x4E2A;Notebook&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x4E4B;&#x524D;&#xFF0C;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x5148;&#x5907;&#x4EFD;&#x4E00;&#x4E0B;&#x3002;</p>
<ul>
<li>&#x6539;&#x53D8;&#x7A0B;&#x5E8F;&#x7684;&#x51E0;&#x4E2A;&#x4E0D;&#x540C;&#x5730;&#x65B9;&#xFF0C;&#x770B;&#x770B;&#x5B83;&#x5982;&#x4F55;&#x5F71;&#x54CD;&#x6027;&#x80FD;&#xFF1A;<ul>
<li>&#x5728;&#x96C6;&#x6210;&#x4E2D;&#x4F7F;&#x7528;&#x66F4;&#x591A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</li>
<li>&#x6539;&#x53D8;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x5927;&#x5C0F;&#x3002;</li>
<li>&#x6539;&#x53D8;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x7684;&#x6B21;&#x6570;&#xFF0C;&#x8BD5;&#x7740;&#x589E;&#x52A0;&#x6216;&#x51CF;&#x5C11;&#x3002;</li>
</ul>
</li>
<li>&#x5411;&#x670B;&#x53CB;&#x89E3;&#x91CA;&#x7A0B;&#x5E8F;&#x5982;&#x4F55;&#x5DE5;&#x4F5C;&#x3002;</li>
<li>&#x4F60;&#x8BA4;&#x4E3A;&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x503C;&#x5F97;&#x66F4;&#x591A;&#x7684;&#x7814;&#x7A76;&#x5417;&#xFF0C;&#x6216;&#x8005;&#x5B81;&#x53EF;&#x4E13;&#x6CE8;&#x4E8E;&#x63D0;&#x5347;&#x5355;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x6027;&#x80FD;&#xFF1F;</li>
</ul>
<h2 id="license-mit">License (MIT)</h2>
<p>Copyright (c) 2016 by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a></p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html" class="navigation navigation-prev " aria-label="Previous page: 保存 & 恢复">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html" class="navigation navigation-next " aria-label="Next page: CIFAR-10">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"集成学习","level":"1.6","depth":1,"next":{"title":"CIFAR-10","level":"1.7","depth":1,"path":"06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.md","ref":"06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.md","articles":[]},"previous":{"title":"保存 & 恢复","level":"1.5","depth":1,"path":"04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.md","ref":"04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.md","articles":[]},"dir":"ltr"},"config":{"plugins":["comment"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"comment":{"highlightCommented":true},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"wizardforcel","pdf":{"pageNumbers":true,"fontSize":16,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"TensorFlow 教程（Hvass）","language":"zh","links":{"sidebar":{"TensorFlow 教程（Hvass）":"https://www.gitbook.com/book/wizardforcel/tf-tut-hvass"},"gitbook":true},"gitbook":"*","description":"Tensorflow 教程（Hvass）"},"file":{"path":"05_Ensemble_Learning_zh_CN/05_Ensemble_Learning_zh_CN.md","mtime":"2017-09-18T01:21:37.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2017-09-18T01:34:14.068Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-comment/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

