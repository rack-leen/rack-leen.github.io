
<!DOCTYPE HTML>
<html lang="zh" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>对抗样本 · TensorFlow 教程（Hvass）</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="wizardforcel">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-comment/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html" />
    
    
    <link rel="prev" href="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="輸入並搜尋" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://www.gitbook.com/book/wizardforcel/tf-tut-hvass" target="_blank" class="custom-link">TensorFlow 教程（Hvass）</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    TensorFlow 教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                <a href="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                    
                    简单线性模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                <a href="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                    
                    卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                <a href="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                    
                    PrettyTensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                <a href="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                    
                    保存 & 恢复
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../05_Ensemble_Learning_zh_CN/05_Ensemble_Learning_zh_CN.html">
            
                <a href="../05_Ensemble_Learning_zh_CN/05_Ensemble_Learning_zh_CN.html">
            
                    
                    集成学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                <a href="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                    
                    CIFAR-10
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                <a href="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                    
                    Inception 模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                <a href="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                    
                    迁移学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                <a href="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                    
                    视频数据
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.11" data-path="11_Adversarial_Examples_zh_CN.html">
            
                <a href="11_Adversarial_Examples_zh_CN.html">
            
                    
                    对抗样本
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                <a href="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                    
                    MNIST的对抗噪声
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                <a href="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                    
                    可视化分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                <a href="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                    
                    DeepDream
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../15_Style_Transfer_zh_CN/15_Style_Transfer_zh_CN.html">
            
                <a href="../15_Style_Transfer_zh_CN/15_Style_Transfer_zh_CN.html">
            
                    
                    风格迁移
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本書使用 GitBook 釋出
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >对抗样本</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="tensorflow-&#x6559;&#x7A0B;-11">TensorFlow &#x6559;&#x7A0B; #11</h1>
<h1 id="&#x5BF9;&#x6297;&#x6837;&#x672C;">&#x5BF9;&#x6297;&#x6837;&#x672C;</h1>
<p>by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a>
/ <a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials" target="_blank">GitHub</a> / <a href="https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ" target="_blank">Videos on YouTube</a></p>
<p>&#x4E2D;&#x6587;&#x7FFB;&#x8BD1; <a href="https://zhuanlan.zhihu.com/insight-pixel" target="_blank">thrillerist</a>/<a href="https://github.com/thrillerist/TensorFlow-Tutorials" target="_blank">Github</a></p>
<h2 id="&#x4ECB;&#x7ECD;">&#x4ECB;&#x7ECD;</h2>
<p>&#x4E4B;&#x524D;&#x7684;&#x6559;&#x7A0B;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x7528;&#x51E0;&#x79CD;&#x4E0D;&#x7528;&#x7684;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6765;&#x5206;&#x7C7B;&#x56FE;&#x50CF;&#xFF0C;&#x53D6;&#x5F97;&#x4E0D;&#x540C;&#x7A0B;&#x5EA6;&#x7684;&#x6210;&#x529F;&#x3002;&#x5728;&#x8FD9;&#x7BC7;&#x6559;&#x7A0B;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x4F1A;&#x770B;&#x5230;&#x4E00;&#x4E2A;&#x5BFB;&#x627E;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x7684;&#x7B80;&#x5355;&#x65B9;&#x6CD5;&#xFF0C;&#x5B83;&#x4F1A;&#x4F7F;&#x4E00;&#x4E2A;&#x6700;&#x5148;&#x8FDB;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BEF;&#x5206;&#x7C7B;&#x4EFB;&#x4F55;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#xFF0C;&#x4E0D;&#x7BA1;&#x9009;&#x7684;&#x662F;&#x4EC0;&#x4E48;&#x7C7B;&#x522B;&#x3002;&#x8FD9;&#x901A;&#x8FC7;&#x7B80;&#x5355;&#x5730;&#x5411;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x6DFB;&#x52A0;&#x5C0F;&#x90E8;&#x5206;&#x201C;&#x7279;&#x5B9A;&#x201D;&#x566A;&#x58F0;&#x5B8C;&#x6210;&#x3002;&#x4EBA;&#x7C7B;&#x4E0D;&#x4F1A;&#x89C9;&#x5BDF;&#x5230;&#x8FD9;&#x4E9B;&#x53D8;&#x5316;&#xFF0C;&#x4F46;&#x5B83;&#x5374;&#x80FD;&#x620F;&#x5F04;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
<p>&#x672C;&#x6587;&#x57FA;&#x4E8E;&#x4E4B;&#x524D;&#x7684;&#x6559;&#x7A0B;&#x3002;&#x4F60;&#x9700;&#x8981;&#x5927;&#x6982;&#x5730;&#x719F;&#x6089;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;&#x6559;&#x7A0B;#01&#x548C;#02&#xFF09;&#xFF0C;&#x4E86;&#x89E3;Inception&#x6A21;&#x578B;&#xFF08;&#x6559;&#x7A0B;#07&#xFF09;&#x4E5F;&#x5F88;&#x6709;&#x5E2E;&#x52A9;&#x3002;</p>
<h2 id="&#x6D41;&#x7A0B;&#x56FE;">&#x6D41;&#x7A0B;&#x56FE;</h2>
<p>&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x6559;&#x7A0B;#07&#x4E2D;&#x7684;Inception&#x6A21;&#x578B;&#xFF0C;&#x7136;&#x540E;&#x4FEE;&#x6539;/&#x9ED1;&#x6389;TensorFlow&#x56FE;&#xFF0C;&#x6765;&#x5BFB;&#x627E;&#x5F15;&#x8D77;Inception&#x6A21;&#x578B;&#x8BEF;&#x5206;&#x7C7B;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x3002;</p>
<p>&#x5728;&#x4E0B;&#x9762;&#x7684;&#x6D41;&#x7A0B;&#x56FE;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x300A;&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382;&#x300B;&#x56FE;&#x50CF;&#x4E0A;&#x6DFB;&#x52A0;&#x4E86;&#x4E00;&#x4E9B;&#x566A;&#x58F0;&#xFF0C;&#x7136;&#x540E;&#x4F5C;&#x4E3A;Inception&#x6A21;&#x578B;&#x7684;&#x8F93;&#x5165;&#x3002;&#x6700;&#x7EC8;&#x76EE;&#x6807;&#x662F;&#x627E;&#x5230;&#x4F7F;Inception&#x6A21;&#x578B;&#x5C06;&#x56FE;&#x50CF;&#x8BEF;&#x5206;&#x7C7B;&#x6210;&#x6211;&#x4EEC;&#x76EE;&#x6807;&#x7C7B;&#x578B;&#x7684;&#x566A;&#x58F0;&#xFF0C;&#x8FD9;&#x8FB9;&#x9009;&#x62E9;<code>&#x4E66;&#x67DC;</code>&#x7C7B;&#x578B;&#xFF08;&#x5206;&#x7C7B;&#x53F7;300&#xFF09;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x4E5F;&#x4E3A;&#x56FE;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x6765;&#x8BA1;&#x7B97;cross-entropy&#xFF0C;&#x5B83;&#x662F;Inception&#x6A21;&#x578B;&#x5206;&#x7C7B;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x7684;&#x6027;&#x80FD;&#x5EA6;&#x91CF;&#x3002;</p>
<p>&#x7531;&#x4E8E;Inception&#x6A21;&#x578B;&#x662F;&#x7531;&#x5F88;&#x591A;&#x76F8;&#x7ED3;&#x5408;&#x7684;&#x57FA;&#x672C;&#x6570;&#x5B66;&#x8FD0;&#x7B97;&#x6784;&#x9020;&#x7684;&#xFF0C;&#x4F7F;&#x7528;&#x5FAE;&#x5206;&#x94FE;&#x5F0F;&#x6CD5;&#x5219;&#xFF0C;TensorFlow&#x8BA9;&#x6211;&#x4EEC;&#x5F88;&#x5FEB;&#x5C31;&#x80FD;&#x627E;&#x5230;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5173;&#x4E8E;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x6765;&#x5BFB;&#x627E;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x3002;&#x8981;&#x5BFB;&#x627E;&#x7684;&#x662F;&#x90A3;&#x4E9B;&#x53EF;&#x4EE5;&#x589E;&#x52A0;&apos;&#x4E66;&#x67DC;&apos;&#x7C7B;&#x522B;&#x800C;&#x4E0D;&#x662F;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x539F;&#x59CB;&#x7C7B;&#x522B;&#x7684;&#x8BC4;&#x5206;&#xFF08;&#x5373;&#x6982;&#x7387;&#xFF09;&#x7684;&#x566A;&#x58F0;&#x3002;</p>
<p>&#x8FD9;&#x672C;&#x8D28;&#x4E0A;&#x662F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x6765;&#x6267;&#x884C;&#x4F18;&#x5316;&#x7684;&#xFF0C;&#x540E;&#x9762;&#x4F1A;&#x5B9E;&#x73B0;&#x5B83;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image, display
Image(<span class="hljs-string">&apos;images/11_adversarial_examples_flowchart.png&apos;</span>)
</code></pre>
<p><img src="output_4_0.png" alt="png"></p>
<h2 id="&#x5BFC;&#x5165;">&#x5BFC;&#x5165;</h2>
<pre><code class="lang-python">%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os

<span class="hljs-comment"># Functions and classes for loading and using the Inception model.</span>
<span class="hljs-keyword">import</span> inception
</code></pre>
<p>&#x4F7F;&#x7528;Python3.5.2&#xFF08;Anaconda&#xFF09;&#x5F00;&#x53D1;&#xFF0C;TensorFlow&#x7248;&#x672C;&#x662F;&#xFF1A;</p>
<pre><code class="lang-python">tf.__version__
</code></pre>
<pre><code>&apos;0.11.0rc0&apos;
</code></pre><h2 id="inception-&#x6A21;&#x578B;">Inception &#x6A21;&#x578B;</h2>
<h3 id="&#x4ECE;&#x7F51;&#x4E0A;&#x4E0B;&#x8F7D;inception&#x6A21;&#x578B;&#x3002;">&#x4ECE;&#x7F51;&#x4E0A;&#x4E0B;&#x8F7D;Inception&#x6A21;&#x578B;&#x3002;</h3>
<p>&#x4ECE;&#x7F51;&#x4E0A;&#x4E0B;&#x8F7D;Inception&#x6A21;&#x578B;&#x3002;&#x8FD9;&#x662F;&#x4F60;&#x4FDD;&#x5B58;&#x6570;&#x636E;&#x6587;&#x4EF6;&#x7684;&#x9ED8;&#x8BA4;&#x6587;&#x4EF6;&#x5939;&#x3002;&#x5982;&#x679C;&#x6587;&#x4EF6;&#x5939;&#x4E0D;&#x5B58;&#x5728;&#x5C31;&#x81EA;&#x52A8;&#x521B;&#x5EFA;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># inception.data_dir = &apos;inception/&apos;</span>
</code></pre>
<p>&#x5982;&#x679C;&#x6587;&#x4EF6;&#x5939;&#x4E2D;&#x4E0D;&#x5B58;&#x5728;Inception&#x6A21;&#x578B;&#xFF0C;&#x5C31;&#x81EA;&#x52A8;&#x4E0B;&#x8F7D;&#x3002; &#x5B83;&#x6709;85MB&#x3002;</p>
<pre><code class="lang-python">inception.maybe_download()
</code></pre>
<pre><code>Downloading Inception v3 Model ...
Data has apparently already been downloaded and unpacked.
</code></pre><h3 id="&#x8F7D;&#x5165;inception&#x6A21;&#x578B;">&#x8F7D;&#x5165;Inception&#x6A21;&#x578B;</h3>
<p>&#x8F7D;&#x5165;&#x6A21;&#x578B;&#xFF0C;&#x4E3A;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x505A;&#x51C6;&#x5907;&#x3002;</p>
<p>&#x6CE8;&#x610F;warning&#x4FE1;&#x606F;&#xFF0C;&#x4EE5;&#x540E;&#x53EF;&#x80FD;&#x4F1A;&#x5BFC;&#x81F4;&#x7A0B;&#x5E8F;&#x8FD0;&#x884C;&#x5931;&#x8D25;&#x3002;</p>
<pre><code class="lang-python">model = inception.Inception()
</code></pre>
<h3 id="&#x83B7;&#x53D6;inception&#x6A21;&#x578B;&#x7684;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;">&#x83B7;&#x53D6;Inception&#x6A21;&#x578B;&#x7684;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;</h3>
<p>&#x53D6;&#x5F97;Inception&#x6A21;&#x578B;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x7684;&#x5F15;&#x7528;&#x3002;&#x8FD9;&#x4E2A;&#x5F20;&#x91CF;&#x662F;&#x7528;&#x6765;&#x4FDD;&#x5B58;&#x8C03;&#x6574;&#x5927;&#x5C0F;&#x540E;&#x7684;&#x56FE;&#x50CF;&#xFF0C;&#x5373;299 x 299&#x50CF;&#x7D20;&#x5E76;&#x5E26;&#x6709;3&#x4E2A;&#x989C;&#x8272;&#x901A;&#x9053;&#x3002;&#x6211;&#x4EEC;&#x4F1A;&#x5728;&#x8C03;&#x6574;&#x5927;&#x5C0F;&#x540E;&#x7684;&#x56FE;&#x50CF;&#x4E0A;&#x6DFB;&#x52A0;&#x566A;&#x58F0;&#xFF0C;&#x7136;&#x540E;&#x8FD8;&#x662F;&#x7528;&#x8FD9;&#x4E2A;&#x5F20;&#x91CF;&#x5C06;&#x7ED3;&#x679C;&#x4F20;&#x5230;&#x56FE;&#xFF08;graph&#xFF09;&#x4E2D;&#xFF0C;&#x56E0;&#x6B64;&#x9700;&#x8981;&#x786E;&#x4FDD;&#x8C03;&#x6574;&#x5927;&#x5C0F;&#x7684;&#x7B97;&#x6CD5;&#x6CA1;&#x6709;&#x5F15;&#x5165;&#x566A;&#x58F0;&#x3002;</p>
<pre><code class="lang-python">resized_image = model.resized_image
</code></pre>
<p>&#x83B7;&#x53D6;Inception&#x6A21;&#x578B;softmax&#x5206;&#x7C7B;&#x5668;&#x8F93;&#x51FA;&#x7684;&#x5F15;&#x7528;&#x3002;</p>
<pre><code class="lang-python">y_pred = model.y_pred
</code></pre>
<p>&#x83B7;&#x53D6;Inception&#x6A21;&#x578B;softmax&#x5206;&#x7C7B;&#x5668;&#x672A;&#x7ECF;&#x5C3A;&#x5EA6;&#x53D8;&#x5316;&#x7684;&#xFF08;unscaled&#xFF09;&#x8F93;&#x51FA;&#x7684;&#x5F15;&#x7528;&#x3002;&#x8FD9;&#x901A;&#x5E38;&#x79F0;&#x4E3A;&#x201C;logits&#x201D;&#x3002;&#x7531;&#x4E8E;&#x6211;&#x4EEC;&#x4F1A;&#x5728;graph&#x4E0A;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x5176;&#x4E2D;&#x7528;&#x5230;&#x8FD9;&#x4E9B;&#x672A;&#x7ECF;&#x53D8;&#x5316;&#x7684;&#x8F93;&#x51FA;&#xFF0C;&#x56E0;&#x6B64;logits&#x662F;&#x5FC5;&#x8981;&#x7684;&#x3002;</p>
<pre><code class="lang-python">y_logits = model.y_logits
</code></pre>
<h3 id="&#x9ED1;&#x6389;inception&#x6A21;&#x578B;">&#x9ED1;&#x6389;Inception&#x6A21;&#x578B;</h3>
<p>&#x4E3A;&#x4E86;&#x627E;&#x5230;&#x5BF9;&#x6297;&#x6837;&#x672C;&#xFF0C;&#x9700;&#x8981;&#x4E3A;Inception&#x6A21;&#x578B;&#x7684;&#x56FE;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;&#x6211;&#x4EEC;&#x8FD8;&#x9700;&#x8981;&#x8FD9;&#x4E2A;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5173;&#x4E8E;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x68AF;&#x5EA6;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># Set the graph for the Inception model as the default graph,</span>
<span class="hljs-comment"># so that all changes inside this with-block are done to that graph.</span>
<span class="hljs-keyword">with</span> model.graph.as_default():
    <span class="hljs-comment"># Add a placeholder variable for the target class-number.</span>
    <span class="hljs-comment"># This will be set to e.g. 300 for the &apos;bookcase&apos; class.</span>
    pl_cls_target = tf.placeholder(dtype=tf.int32)

    <span class="hljs-comment"># Add a new loss-function. This is the cross-entropy.</span>
    <span class="hljs-comment"># See Tutorial #01 for an explanation of cross-entropy.</span>
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=[pl_cls_target])

    <span class="hljs-comment"># Get the gradient for the loss-function with regard to</span>
    <span class="hljs-comment"># the resized input image.</span>
    gradient = tf.gradients(loss, resized_image)
</code></pre>
<h2 id="tensorflow-&#x4F1A;&#x8BDD;">TensorFlow &#x4F1A;&#x8BDD;</h2>
<p>&#x6211;&#x4EEC;&#x9700;&#x8981;&#x4E00;&#x4E2A;TensorFlow&#x4F1A;&#x8BDD;&#x6765;&#x8FD0;&#x884C;&#x56FE;&#x3002;</p>
<pre><code class="lang-python">session = tf.Session(graph=model.graph)
</code></pre>
<h2 id="&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#x7528;&#x6765;&#x5BFB;&#x627E;&#x5BF9;&#x6297;&#x566A;&#x58F0;">&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#x7528;&#x6765;&#x5BFB;&#x627E;&#x5BF9;&#x6297;&#x566A;&#x58F0;</h2>
<p>&#x4E0B;&#x9762;&#x7684;&#x51FD;&#x6570;&#x627E;&#x51FA;&#x4E86;&#x8981;&#x6DFB;&#x52A0;&#x5230;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x4E0A;&#x7684;&#x566A;&#x58F0;&#xFF0C;&#x8FD9;&#x6837;&#xFF08;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#xFF09;&#x5C31;&#x4F1A;&#x88AB;&#x5206;&#x7C7B;&#x5230;&#x60F3;&#x8981;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x578B;&#x3002;</p>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x672C;&#x8D28;&#x4E0A;&#x662F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6765;&#x6267;&#x884C;&#x4F18;&#x5316;&#x3002;&#x566A;&#x58F0;&#x88AB;&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x96F6;&#xFF0C;&#x7136;&#x540E;&#x7528;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5173;&#x4E8E;&#x8F93;&#x5165;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x7684;&#x68AF;&#x5EA6;&#x6765;&#x9010;&#x6B65;&#x4F18;&#x5316;&#xFF0C;&#x8FD9;&#x6837;&#xFF0C;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x566A;&#x58F0;&#x90FD;&#x4F7F;&#x5206;&#x7C7B;&#x66F4;&#x63A5;&#x8FD1;&#x4E8E;&#x60F3;&#x8981;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x578B;&#x3002;&#x5F53;&#x5206;&#x7C7B;&#x8BC4;&#x5206;&#x8FBE;&#x5230;&#x8981;&#x6C42;&#xFF08;&#x6BD4;&#x5982;99%&#xFF09;&#x6216;&#x8005;&#x6267;&#x884C;&#x4E86;&#x6700;&#x5927;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x65F6;&#xFF0C;&#x5C31;&#x505C;&#x6B62;&#x4F18;&#x5316;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">find_adversary_noise</span><span class="hljs-params">(image_path, cls_target, noise_limit=<span class="hljs-number">3.0</span>,
                         required_score=<span class="hljs-number">0.99</span>, max_iterations=<span class="hljs-number">100</span>)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Find the noise that must be added to the given image so
    that it is classified as the target-class.

    image_path: File-path to the input-image (must be *.jpg).
    cls_target: Target class-number (integer between 1-1000).
    noise_limit: Limit for pixel-values in the noise.
    required_score: Stop when target-class score reaches this.
    max_iterations: Max number of optimization iterations to perform.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Create a feed-dict with the image.</span>
    feed_dict = model._create_feed_dict(image_path=image_path)

    <span class="hljs-comment"># Use TensorFlow to calculate the predicted class-scores</span>
    <span class="hljs-comment"># (aka. probabilities) as well as the resized image.</span>
    pred, image = session.run([y_pred, resized_image],
                              feed_dict=feed_dict)

    <span class="hljs-comment"># Convert to one-dimensional array.</span>
    pred = np.squeeze(pred)

    <span class="hljs-comment"># Predicted class-number.</span>
    cls_source = np.argmax(pred)

    <span class="hljs-comment"># Score for the predicted class (aka. probability or confidence).</span>
    score_source_org = pred.max()

    <span class="hljs-comment"># Names for the source and target classes.</span>
    name_source = model.name_lookup.cls_to_name(cls_source,
                                                only_first_name=<span class="hljs-keyword">True</span>)
    name_target = model.name_lookup.cls_to_name(cls_target,
                                                only_first_name=<span class="hljs-keyword">True</span>)

    <span class="hljs-comment"># Initialize the noise to zero.</span>
    noise = <span class="hljs-number">0</span>

    <span class="hljs-comment"># Perform a number of optimization iterations to find</span>
    <span class="hljs-comment"># the noise that causes mis-classification of the input image.</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(max_iterations):
        print(<span class="hljs-string">&quot;Iteration:&quot;</span>, i)

        <span class="hljs-comment"># The noisy image is just the sum of the input image and noise.</span>
        noisy_image = image + noise

        <span class="hljs-comment"># Ensure the pixel-values of the noisy image are between</span>
        <span class="hljs-comment"># 0 and 255 like a real image. If we allowed pixel-values</span>
        <span class="hljs-comment"># outside this range then maybe the mis-classification would</span>
        <span class="hljs-comment"># be due to this &apos;illegal&apos; input breaking the Inception model.</span>
        noisy_image = np.clip(a=noisy_image, a_min=<span class="hljs-number">0.0</span>, a_max=<span class="hljs-number">255.0</span>)

        <span class="hljs-comment"># Create a feed-dict. This feeds the noisy image to the</span>
        <span class="hljs-comment"># tensor in the graph that holds the resized image, because</span>
        <span class="hljs-comment"># this is the final stage for inputting raw image data.</span>
        <span class="hljs-comment"># This also feeds the target class-number that we desire.</span>
        feed_dict = {model.tensor_name_resized_image: noisy_image,
                     pl_cls_target: cls_target}

        <span class="hljs-comment"># Calculate the predicted class-scores as well as the gradient.</span>
        pred, grad = session.run([y_pred, gradient],
                                 feed_dict=feed_dict)

        <span class="hljs-comment"># Convert the predicted class-scores to a one-dim array.</span>
        pred = np.squeeze(pred)

        <span class="hljs-comment"># The scores (probabilities) for the source and target classes.</span>
        score_source = pred[cls_source]
        score_target = pred[cls_target]

        <span class="hljs-comment"># Squeeze the dimensionality for the gradient-array.</span>
        grad = np.array(grad).squeeze()

        <span class="hljs-comment"># The gradient now tells us how much we need to change the</span>
        <span class="hljs-comment"># noisy input image in order to move the predicted class</span>
        <span class="hljs-comment"># closer to the desired target-class.</span>

        <span class="hljs-comment"># Calculate the max of the absolute gradient values.</span>
        <span class="hljs-comment"># This is used to calculate the step-size.</span>
        grad_absmax = np.abs(grad).max()

        <span class="hljs-comment"># If the gradient is very small then use a lower limit,</span>
        <span class="hljs-comment"># because we will use it as a divisor.</span>
        <span class="hljs-keyword">if</span> grad_absmax &lt; <span class="hljs-number">1e-10</span>:
            grad_absmax = <span class="hljs-number">1e-10</span>

        <span class="hljs-comment"># Calculate the step-size for updating the image-noise.</span>
        <span class="hljs-comment"># This ensures that at least one pixel colour is changed by 7.</span>
        <span class="hljs-comment"># Recall that pixel colours can have 255 different values.</span>
        <span class="hljs-comment"># This step-size was found to give fast convergence.</span>
        step_size = <span class="hljs-number">7</span> / grad_absmax

        <span class="hljs-comment"># Print the score etc. for the source-class.</span>
        msg = <span class="hljs-string">&quot;Source score: {0:&gt;7.2%}, class-number: {1:&gt;4}, class-name: {2}&quot;</span>
        print(msg.format(score_source, cls_source, name_source))

        <span class="hljs-comment"># Print the score etc. for the target-class.</span>
        msg = <span class="hljs-string">&quot;Target score: {0:&gt;7.2%}, class-number: {1:&gt;4}, class-name: {2}&quot;</span>
        print(msg.format(score_target, cls_target, name_target))

        <span class="hljs-comment"># Print statistics for the gradient.</span>
        msg = <span class="hljs-string">&quot;Gradient min: {0:&gt;9.6f}, max: {1:&gt;9.6f}, stepsize: {2:&gt;9.2f}&quot;</span>
        print(msg.format(grad.min(), grad.max(), step_size))

        <span class="hljs-comment"># Newline.</span>
        print()

        <span class="hljs-comment"># If the score for the target-class is not high enough.</span>
        <span class="hljs-keyword">if</span> score_target &lt; required_score:
            <span class="hljs-comment"># Update the image-noise by subtracting the gradient</span>
            <span class="hljs-comment"># scaled by the step-size.</span>
            noise -= step_size * grad

            <span class="hljs-comment"># Ensure the noise is within the desired range.</span>
            <span class="hljs-comment"># This avoids distorting the image too much.</span>
            noise = np.clip(a=noise,
                            a_min=-noise_limit,
                            a_max=noise_limit)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># Abort the optimization because the score is high enough.</span>
            <span class="hljs-keyword">break</span>

    <span class="hljs-keyword">return</span> image.squeeze(), noisy_image.squeeze(), noise, \
           name_source, name_target, \
           score_source, score_source_org, score_target
</code></pre>
<h3 id="&#x7ED8;&#x5236;&#x56FE;&#x50CF;&#x548C;&#x566A;&#x58F0;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x7ED8;&#x5236;&#x56FE;&#x50CF;&#x548C;&#x566A;&#x58F0;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x51FD;&#x6570;&#x5BF9;&#x8F93;&#x5165;&#x505A;&#x5F52;&#x4E00;&#x5316;&#xFF0C;&#x5219;&#x8F93;&#x5165;&#x503C;&#x5728;0.0&#x5230;1.0&#x4E4B;&#x95F4;&#xFF0C;&#x8FD9;&#x6837;&#x624D;&#x80FD;&#x6B63;&#x786E;&#x7684;&#x663E;&#x793A;&#x51FA;&#x566A;&#x58F0;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normalize_image</span><span class="hljs-params">(x)</span>:</span>
    <span class="hljs-comment"># Get the min and max values for all pixels in the input.</span>
    x_min = x.min()
    x_max = x.max()

    <span class="hljs-comment"># Normalize so all values are between 0.0 and 1.0</span>
    x_norm = (x - x_min) / (x_max - x_min)

    <span class="hljs-keyword">return</span> x_norm
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7ED8;&#x5236;&#x4E86;&#x539F;&#x59CB;&#x56FE;&#x50CF;&#x3001;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#xFF0C;&#x4EE5;&#x53CA;&#x566A;&#x58F0;&#x3002;&#x5B83;&#x4E5F;&#x663E;&#x793A;&#x4E86;&#x7C7B;&#x522B;&#x540D;&#x548C;&#x8BC4;&#x5206;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_images</span><span class="hljs-params">(image, noise, noisy_image,
                name_source, name_target,
                score_source, score_source_org, score_target)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Plot the image, the noisy image and the noise.
    Also shows the class-names and scores.

    Note that the noise is amplified to use the full range of
    colours, otherwise if the noise is very low it would be
    hard to see.

    image: Original input image.
    noise: Noise that has been added to the image.
    noisy_image: Input image + noise.
    name_source: Name of the source-class.
    name_target: Name of the target-class.
    score_source: Score for the source-class.
    score_source_org: Original score for the source-class.
    score_target: Score for the target-class.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Create figure with sub-plots.</span>
    fig, axes = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">10</span>))

    <span class="hljs-comment"># Adjust vertical spacing.</span>
    fig.subplots_adjust(hspace=<span class="hljs-number">0.1</span>, wspace=<span class="hljs-number">0.1</span>)

    <span class="hljs-comment"># Use interpolation to smooth pixels?</span>
    smooth = <span class="hljs-keyword">True</span>

    <span class="hljs-comment"># Interpolation type.</span>
    <span class="hljs-keyword">if</span> smooth:
        interpolation = <span class="hljs-string">&apos;spline16&apos;</span>
    <span class="hljs-keyword">else</span>:
        interpolation = <span class="hljs-string">&apos;nearest&apos;</span>

    <span class="hljs-comment"># Plot the original image.</span>
    <span class="hljs-comment"># Note that the pixel-values are normalized to the [0.0, 1.0]</span>
    <span class="hljs-comment"># range by dividing with 255.</span>
    ax = axes.flat[<span class="hljs-number">0</span>]
    ax.imshow(image / <span class="hljs-number">255.0</span>, interpolation=interpolation)
    msg = <span class="hljs-string">&quot;Original Image:\n{0} ({1:.2%})&quot;</span>
    xlabel = msg.format(name_source, score_source_org)
    ax.set_xlabel(xlabel)

    <span class="hljs-comment"># Plot the noisy image.</span>
    ax = axes.flat[<span class="hljs-number">1</span>]
    ax.imshow(noisy_image / <span class="hljs-number">255.0</span>, interpolation=interpolation)
    msg = <span class="hljs-string">&quot;Image + Noise:\n{0} ({1:.2%})\n{2} ({3:.2%})&quot;</span>
    xlabel = msg.format(name_source, score_source, name_target, score_target)
    ax.set_xlabel(xlabel)

    <span class="hljs-comment"># Plot the noise.</span>
    <span class="hljs-comment"># The colours are amplified otherwise they would be hard to see.</span>
    ax = axes.flat[<span class="hljs-number">2</span>]
    ax.imshow(normalize_image(noise), interpolation=interpolation)
    xlabel = <span class="hljs-string">&quot;Amplified Noise&quot;</span>
    ax.set_xlabel(xlabel)

    <span class="hljs-comment"># Remove ticks from all the plots.</span>
    <span class="hljs-keyword">for</span> ax <span class="hljs-keyword">in</span> axes.flat:
        ax.set_xticks([])
        ax.set_yticks([])

    <span class="hljs-comment"># Ensure the plot is shown correctly with multiple plots</span>
    <span class="hljs-comment"># in a single Notebook cell.</span>
    plt.show()
</code></pre>
<h3 id="&#x5BFB;&#x627E;&#x5E76;&#x7ED8;&#x5236;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x5BFB;&#x627E;&#x5E76;&#x7ED8;&#x5236;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h3>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7ED3;&#x5408;&#x4E86;&#x4E0A;&#x9762;&#x7684;&#x4E24;&#x4E2A;&#x65B9;&#x6CD5;&#x3002;&#x5B83;&#x5148;&#x627E;&#x5230;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#xFF0C;&#x7136;&#x540E;&#x753B;&#x51FA;&#x56FE;&#x50CF;&#x548C;&#x566A;&#x58F0;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">adversary_example</span><span class="hljs-params">(image_path, cls_target,
                      noise_limit, required_score)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Find and plot adversarial noise for the given image.

    image_path: File-path to the input-image (must be *.jpg).
    cls_target: Target class-number (integer between 1-1000).
    noise_limit: Limit for pixel-values in the noise.
    required_score: Stop when target-class score reaches this.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Find the adversarial noise.</span>
    image, noisy_image, noise, \
    name_source, name_target, \
    score_source, score_source_org, score_target = \
        find_adversary_noise(image_path=image_path,
                             cls_target=cls_target,
                             noise_limit=noise_limit,
                             required_score=required_score)

    <span class="hljs-comment"># Plot the image and the noise.</span>
    plot_images(image=image, noise=noise, noisy_image=noisy_image,
                name_source=name_source, name_target=name_target,
                score_source=score_source,
                score_source_org=score_source_org,
                score_target=score_target)

    <span class="hljs-comment"># Print some statistics for the noise.</span>
    msg = <span class="hljs-string">&quot;Noise min: {0:.3f}, max: {1:.3f}, mean: {2:.3f}, std: {3:.3f}&quot;</span>
    print(msg.format(noise.min(), noise.max(),
                     noise.mean(), noise.std()))
</code></pre>
<h2 id="&#x7ED3;&#x679C;">&#x7ED3;&#x679C;</h2>
<h3 id="&#x9E66;&#x9E49;">&#x9E66;&#x9E49;</h3>
<p>&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x5C06;&#x4E00;&#x5F20;&#x9E66;&#x9E49;&#x56FE;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x7136;&#x540E;&#x627E;&#x5230;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#xFF0C;&#x4F7F;&#x5F97;Inception&#x6A21;&#x578B;&#x5C06;&#x56FE;&#x50CF;&#x8BEF;&#x5206;&#x7C7B;&#x6210;&#x4E00;&#x4E2A;&#x4E66;&#x67B6;&#xFF08;&#x7C7B;&#x522B;&#x53F7;300&#xFF09;&#x3002;</p>
<p>&#x566A;&#x58F0;&#x754C;&#x9650;&#x8BBE;&#x4E3A;3.0&#xFF0C;&#x8FD9;&#x8868;&#x793A;&#x53EA;&#x5141;&#x8BB8;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x989C;&#x8272;&#x5728;3.0&#x8303;&#x56F4;&#x5185;&#x6CE2;&#x52A8;&#x3002;&#x50CF;&#x7D20;&#x989C;&#x8272;&#x5728;0&#x5230;255&#x4E4B;&#x95F4;&#xFF0C;&#x56E0;&#x6B64;3.0&#x7684;&#x6D6E;&#x52A8;&#x5BF9;&#x5E94;&#x5927;&#x7EA6;1.2%&#x7684;&#x53EF;&#x80FD;&#x8303;&#x56F4;&#x3002;&#x8FD9;&#x6837;&#x7684;&#x5C11;&#x91CF;&#x566A;&#x58F0;&#x5BF9;&#x4EBA;&#x773C;&#x662F;&#x4E0D;&#x53EF;&#x89C1;&#x7684;&#xFF0C;&#x56E0;&#x6B64;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x548C;&#x539F;&#x59CB;&#x56FE;&#x50CF;&#x770B;&#x8D77;&#x6765;&#x57FA;&#x672C;&#x4E00;&#x81F4;&#xFF0C;&#x5982;&#x4E0B;&#x6240;&#x793A;&#x3002;</p>
<p>&#x8981;&#x6C42;&#x8BC4;&#x5206;&#x8BBE;&#x4E3A;0.99&#xFF0C;&#x8FD9;&#x8868;&#x793A;&#x5F53;&#x76EE;&#x6807;&#x5206;&#x7C7B;&#x7684;&#x8BC4;&#x5206;&#x5927;&#x4E8E;&#x7B49;&#x4E8E;0.99&#x65F6;&#xFF0C;&#x7528;&#x6765;&#x5BFB;&#x627E;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x7684;&#x4F18;&#x5316;&#x5668;&#x5C31;&#x4F1A;&#x505C;&#x6B62;&#xFF0C;&#x8FD9;&#x6837;Inception&#x6A21;&#x578B;&#x51E0;&#x4E4E;&#x786E;&#x5B9A;&#x4E86;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x5C55;&#x793A;&#x7684;&#x662F;&#x671F;&#x671B;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x522B;&#x3002;</p>
<pre><code class="lang-python">image_path = <span class="hljs-string">&quot;images/parrot_cropped1.jpg&quot;</span>

adversary_example(image_path=image_path,
                  cls_target=<span class="hljs-number">300</span>,
                  noise_limit=<span class="hljs-number">3.0</span>,
                  required_score=<span class="hljs-number">0.99</span>)
</code></pre>
<pre><code>Iteration: 0
Source score:  97.38%, class-number:  409, class-name: macaw
Target score:   0.00%, class-number:  300, class-name: bookcase
Gradient min: -0.001329, max:  0.001370, stepsize:   5110.94

Iteration: 1
Source score:  88.87%, class-number:  409, class-name: macaw
Target score:   0.01%, class-number:  300, class-name: bookcase
Gradient min: -0.001499, max:  0.001401, stepsize:   4668.28

Iteration: 2
Source score:  68.47%, class-number:  409, class-name: macaw
Target score:   0.06%, class-number:  300, class-name: bookcase
Gradient min: -0.003093, max:  0.002587, stepsize:   2262.91

Iteration: 3
Source score:  16.76%, class-number:  409, class-name: macaw
Target score:   0.22%, class-number:  300, class-name: bookcase
Gradient min: -0.001077, max:  0.001047, stepsize:   6499.39

Iteration: 4
Source score:  31.76%, class-number:  409, class-name: macaw
Target score:   0.41%, class-number:  300, class-name: bookcase
Gradient min: -0.001670, max:  0.001715, stepsize:   4081.82

Iteration: 5
Source score:  11.86%, class-number:  409, class-name: macaw
Target score:   0.72%, class-number:  300, class-name: bookcase
Gradient min: -0.001524, max:  0.002019, stepsize:   3466.85

Iteration: 6
Source score:   2.41%, class-number:  409, class-name: macaw
Target score:   3.26%, class-number:  300, class-name: bookcase
Gradient min: -0.001685, max:  0.001247, stepsize:   4154.00

Iteration: 7
Source score:   3.02%, class-number:  409, class-name: macaw
Target score:   7.07%, class-number:  300, class-name: bookcase
Gradient min: -0.001503, max:  0.001707, stepsize:   4101.29

Iteration: 8
Source score:   2.34%, class-number:  409, class-name: macaw
Target score:   6.59%, class-number:  300, class-name: bookcase
Gradient min: -0.003677, max:  0.003430, stepsize:   1903.80

Iteration: 9
Source score:   1.33%, class-number:  409, class-name: macaw
Target score:  16.10%, class-number:  300, class-name: bookcase
Gradient min: -0.001366, max:  0.001558, stepsize:   4492.61

Iteration: 10
Source score:   0.85%, class-number:  409, class-name: macaw
Target score:  14.19%, class-number:  300, class-name: bookcase
Gradient min: -0.001632, max:  0.001372, stepsize:   4288.61

Iteration: 11
Source score:   0.89%, class-number:  409, class-name: macaw
Target score:  38.05%, class-number:  300, class-name: bookcase
Gradient min: -0.001264, max:  0.000991, stepsize:   5539.81

Iteration: 12
Source score:   0.44%, class-number:  409, class-name: macaw
Target score:  35.43%, class-number:  300, class-name: bookcase
Gradient min: -0.001744, max:  0.002125, stepsize:   3293.86

Iteration: 13
Source score:   0.29%, class-number:  409, class-name: macaw
Target score:  60.42%, class-number:  300, class-name: bookcase
Gradient min: -0.000611, max:  0.000705, stepsize:   9927.19

Iteration: 14
Source score:   0.24%, class-number:  409, class-name: macaw
Target score:  40.47%, class-number:  300, class-name: bookcase
Gradient min: -0.001014, max:  0.001096, stepsize:   6385.38

Iteration: 15
Source score:   1.98%, class-number:  409, class-name: macaw
Target score:  41.95%, class-number:  300, class-name: bookcase
Gradient min: -0.001578, max:  0.001865, stepsize:   3753.93

Iteration: 16
Source score:   0.04%, class-number:  409, class-name: macaw
Target score:  78.76%, class-number:  300, class-name: bookcase
Gradient min: -0.000333, max:  0.000335, stepsize:  20888.12

Iteration: 17
Source score:   1.93%, class-number:  409, class-name: macaw
Target score:  43.73%, class-number:  300, class-name: bookcase
Gradient min: -0.001840, max:  0.002724, stepsize:   2569.94

Iteration: 18
Source score:   0.02%, class-number:  409, class-name: macaw
Target score:  91.74%, class-number:  300, class-name: bookcase
Gradient min: -0.000328, max:  0.000189, stepsize:  21342.00

Iteration: 19
Source score:   0.00%, class-number:  409, class-name: macaw
Target score:  97.37%, class-number:  300, class-name: bookcase
Gradient min: -0.000064, max:  0.000084, stepsize:  83366.77

Iteration: 20
Source score:   0.01%, class-number:  409, class-name: macaw
Target score:  97.13%, class-number:  300, class-name: bookcase
Gradient min: -0.000089, max:  0.000086, stepsize:  78565.60

Iteration: 21
Source score:   0.01%, class-number:  409, class-name: macaw
Target score:  94.92%, class-number:  300, class-name: bookcase
Gradient min: -0.000128, max:  0.000142, stepsize:  49304.41

Iteration: 22
Source score:   0.01%, class-number:  409, class-name: macaw
Target score:  97.18%, class-number:  300, class-name: bookcase
Gradient min: -0.000071, max:  0.000058, stepsize:  97917.04

Iteration: 23
Source score:   0.01%, class-number:  409, class-name: macaw
Target score:  95.90%, class-number:  300, class-name: bookcase
Gradient min: -0.000111, max:  0.000142, stepsize:  49346.70

Iteration: 24
Source score:   0.00%, class-number:  409, class-name: macaw
Target score:  98.98%, class-number:  300, class-name: bookcase
Gradient min: -0.000029, max:  0.000025, stepsize: 245266.90

Iteration: 25
Source score:   0.00%, class-number:  409, class-name: macaw
Target score:  99.12%, class-number:  300, class-name: bookcase
Gradient min: -0.000019, max:  0.000022, stepsize: 311258.06
</code></pre><p><img src="output_45_1.png" alt="png"></p>
<pre><code>Noise min: -3.000, max: 3.000, mean: 0.001, std: 1.492
</code></pre><p>&#x5982;&#x4E0A;&#x6240;&#x793A;&#xFF0C;&#x9E66;&#x9E49;&#x7684;&#x539F;&#x59CB;&#x56FE;&#x50CF;&#x4E0E;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x770B;&#x8D77;&#x6765;&#x51E0;&#x4E4E;&#x4E00;&#x81F4;&#x3002;&#x4EBA;&#x773C;&#x65E0;&#x6CD5;&#x533A;&#x5206;&#x5F00;&#x4E24;&#x5F20;&#x56FE;&#x50CF;&#x3002;&#x539F;&#x59CB;&#x56FE;&#x88AB;Inception&#x6A21;&#x578B;&#x6B63;&#x786E;&#x5730;&#x5206;&#x7C7B;&#x6210;&#x91D1;&#x521A;&#x9E66;&#x9E49;&#xFF08;&#x9E66;&#x9E49;&#xFF09;&#xFF0C;&#x8BC4;&#x5206;&#x4E3A;97.38%&#x3002;&#x4F46;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x5BF9;&#x91D1;&#x521A;&#x9E66;&#x9E49;&#x7684;&#x5206;&#x7C7B;&#x8BC4;&#x5206;&#x662F;0.00%&#xFF0C;&#x5BF9;&#x4E66;&#x67B6;&#x7684;&#x8BC4;&#x5206;&#x662F;99.12%&#x3002;</p>
<p>&#x8FD9;&#x6837;&#xFF0C;&#x6211;&#x4EEC;&#x7CCA;&#x5F04;&#x4E86;Inception&#x6A21;&#x578B;&#xFF0C;&#x8BA9;&#x5B83;&#x76F8;&#x4FE1;&#x4E00;&#x5F20;&#x9E66;&#x9E49;&#x56FE;&#x50CF;&#x5C55;&#x793A;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x4E66;&#x67B6;&#x3002;&#x53EA;&#x662F;&#x6DFB;&#x52A0;&#x4E86;&#x4E00;&#x4E9B;&#x201C;&#x7279;&#x5B9A;&#x7684;&#x201D;&#x566A;&#x58F0;&#x5C31;&#x5BFC;&#x81F4;&#x4E86;&#x8FD9;&#x4E2A;&#x8BEF;&#x5206;&#x7C7B;&#x3002;</p>
<p>&#x6CE8;&#x610F;&#xFF0C;&#x4E0A;&#x9762;&#x5C55;&#x793A;&#x7684;&#x566A;&#x58F0;&#x662F;&#x88AB;&#x653E;&#x5927;&#x6570;&#x500D;&#x7684;&#x3002;&#x5B9E;&#x9645;&#x4E0A;&#xFF0C;&#x566A;&#x58F0;&#x53EA;&#x5728;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x989C;&#x8272;&#x5F3A;&#x5EA6;&#x7684;&#x6700;&#x591A;1.2%&#x8303;&#x56F4;&#x5185;&#x8C03;&#x6574;&#x56FE;&#x50CF;&#xFF08;&#x5047;&#x5B9A;&#x566A;&#x58F0;&#x754C;&#x9650;&#x50CF;&#x4E0A;&#x9762;&#x7684;&#x51FD;&#x6570;&#x4E00;&#x6837;&#x8BBE;&#x7F6E;&#x4E3A;3.0&#xFF09;&#x3002;&#x7531;&#x4E8E;&#x566A;&#x58F0;&#x5F88;&#x5F31;&#xFF0C;&#x4EBA;&#x7C7B;&#x89C2;&#x5BDF;&#x4E0D;&#x5230;&#xFF0C;&#x4F46;&#x5B83;&#x5BFC;&#x81F4;Inception&#x6A21;&#x578B;&#x5B8C;&#x5168;&#x8BEF;&#x5206;&#x7C7B;&#x7684;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x3002;</p>
<h3 id="elon-musk">Elon Musk</h3>
<p>&#x6211;&#x4EEC;&#x4E5F;&#x627E;&#x5230;&#x4E86;Elon Mask&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x3002;&#x76EE;&#x6807;&#x7C7B;&#x522B;&#x518D;&#x6B21;&#x8BBE;&#x4E3A;&#x201C;&#x4E66;&#x67DC;&#x201D;&#xFF08;&#x7C7B;&#x522B;&#x53F7;300&#xFF09;&#xFF0C;&#x566A;&#x58F0;&#x754C;&#x9650;&#x548C;&#x8981;&#x6C42;&#x5206;&#x6570;&#x4E5F;&#x4E0E;&#x4E0A;&#x9762;&#x7684;&#x76F8;&#x540C;&#x3002;</p>
<pre><code class="lang-python">image_path = <span class="hljs-string">&quot;images/elon_musk.jpg&quot;</span>

adversary_example(image_path=image_path,
                  cls_target=<span class="hljs-number">300</span>,
                  noise_limit=<span class="hljs-number">3.0</span>,
                  required_score=<span class="hljs-number">0.99</span>)
</code></pre>
<pre><code>Iteration: 0
Source score:  19.73%, class-number:  837, class-name: sweatshirt
Target score:   0.01%, class-number:  300, class-name: bookcase
Gradient min: -0.008348, max:  0.005946, stepsize:    838.48

Iteration: 1
Source score:   1.77%, class-number:  837, class-name: sweatshirt
Target score:   0.24%, class-number:  300, class-name: bookcase
Gradient min: -0.002952, max:  0.005907, stepsize:   1185.13

Iteration: 2
Source score:   0.52%, class-number:  837, class-name: sweatshirt
Target score:  10.06%, class-number:  300, class-name: bookcase
Gradient min: -0.006741, max:  0.006555, stepsize:   1038.46

Iteration: 3
Source score:   0.24%, class-number:  837, class-name: sweatshirt
Target score:  67.35%, class-number:  300, class-name: bookcase
Gradient min: -0.001548, max:  0.001130, stepsize:   4521.39

Iteration: 4
Source score:   0.01%, class-number:  837, class-name: sweatshirt
Target score:  68.76%, class-number:  300, class-name: bookcase
Gradient min: -0.001654, max:  0.001889, stepsize:   3706.45

Iteration: 5
Source score:   0.12%, class-number:  837, class-name: sweatshirt
Target score:  84.91%, class-number:  300, class-name: bookcase
Gradient min: -0.001288, max:  0.001800, stepsize:   3889.91

Iteration: 6
Source score:   0.00%, class-number:  837, class-name: sweatshirt
Target score:  99.09%, class-number:  300, class-name: bookcase
Gradient min: -0.000029, max:  0.000021, stepsize: 244856.71
</code></pre><p><img src="output_49_1.png" alt="png"></p>
<pre><code>Noise min: -3.000, max: 3.000, mean: -0.001, std: 0.668
</code></pre><p>Inception&#x6A21;&#x578B;&#x5F04;&#x4E0D;&#x592A;&#x6E05;&#x539F;&#x59CB;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x5206;&#x7C7B;&#xFF0C;&#x8BA4;&#x4E3A;&#x5B83;&#x6709;&#x53EF;&#x80FD;&#x662F;&#x4E00;&#x4EF6;&#x8FD0;&#x52A8;&#x886B;&#xFF08;&#x8BC4;&#x5206;19.73%&#xFF09;&#x3002;&#x4F46;&#x6211;&#x4EEC;&#x8FD8;&#x662F;&#x80FD;&#x591F;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x4F7F;Inception&#x6A21;&#x578B;&#x5B8C;&#x5168;&#x8BA4;&#x4E3A;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x662F;&#x4E66;&#x67B6;&#xFF08;&#x8BC4;&#x5206;99.09%&#xFF09;&#x7684;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#xFF0C;&#x5373;&#x4F7F;&#x5728;&#x4EBA;&#x773C;&#x770B;&#x6765;&#xFF0C;&#x4E24;&#x5F20;&#x56FE;&#x50CF;&#x51E0;&#x4E4E;&#x4E00;&#x6837;&#x3002;</p>
<h3 id="&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382;-&#x65B0;&#x7248;">&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382; (&#x65B0;&#x7248;)</h3>
<pre><code class="lang-python">image_path = <span class="hljs-string">&quot;images/willy_wonka_new.jpg&quot;</span>

adversary_example(image_path=image_path,
                  cls_target=<span class="hljs-number">300</span>,
                  noise_limit=<span class="hljs-number">3.0</span>,
                  required_score=<span class="hljs-number">0.99</span>)
</code></pre>
<pre><code>Iteration: 0
Source score:  31.48%, class-number:  535, class-name: sunglasses
Target score:   0.03%, class-number:  300, class-name: bookcase
Gradient min: -0.002181, max:  0.001478, stepsize:   3210.13

Iteration: 1
Source score:   2.08%, class-number:  535, class-name: sunglasses
Target score:   0.13%, class-number:  300, class-name: bookcase
Gradient min: -0.001447, max:  0.001573, stepsize:   4449.85

Iteration: 2
Source score:   6.37%, class-number:  535, class-name: sunglasses
Target score:   0.35%, class-number:  300, class-name: bookcase
Gradient min: -0.001421, max:  0.001633, stepsize:   4286.13

Iteration: 3
Source score:   2.25%, class-number:  535, class-name: sunglasses
Target score:   1.03%, class-number:  300, class-name: bookcase
Gradient min: -0.001736, max:  0.001874, stepsize:   3734.86

Iteration: 4
Source score:  10.54%, class-number:  535, class-name: sunglasses
Target score:   1.32%, class-number:  300, class-name: bookcase
Gradient min: -0.002901, max:  0.002503, stepsize:   2413.04

Iteration: 5
Source score:   1.86%, class-number:  535, class-name: sunglasses
Target score:   3.22%, class-number:  300, class-name: bookcase
Gradient min: -0.001784, max:  0.001904, stepsize:   3675.68

Iteration: 6
Source score:   2.19%, class-number:  535, class-name: sunglasses
Target score:   5.44%, class-number:  300, class-name: bookcase
Gradient min: -0.002405, max:  0.001714, stepsize:   2911.17

Iteration: 7
Source score:   4.16%, class-number:  535, class-name: sunglasses
Target score:   3.61%, class-number:  300, class-name: bookcase
Gradient min: -0.001463, max:  0.002057, stepsize:   3402.83

Iteration: 8
Source score:   2.25%, class-number:  535, class-name: sunglasses
Target score:  19.46%, class-number:  300, class-name: bookcase
Gradient min: -0.003193, max:  0.001512, stepsize:   2192.48

Iteration: 9
Source score:   1.25%, class-number:  535, class-name: sunglasses
Target score:  50.62%, class-number:  300, class-name: bookcase
Gradient min: -0.000910, max:  0.000770, stepsize:   7693.95

Iteration: 10
Source score:   0.86%, class-number:  535, class-name: sunglasses
Target score:  37.99%, class-number:  300, class-name: bookcase
Gradient min: -0.001351, max:  0.001484, stepsize:   4718.11

Iteration: 11
Source score:   6.40%, class-number:  535, class-name: sunglasses
Target score:  27.42%, class-number:  300, class-name: bookcase
Gradient min: -0.001785, max:  0.001544, stepsize:   3920.83

Iteration: 12
Source score:   0.17%, class-number:  535, class-name: sunglasses
Target score:  73.86%, class-number:  300, class-name: bookcase
Gradient min: -0.000646, max:  0.000842, stepsize:   8315.79

Iteration: 13
Source score:   0.16%, class-number:  535, class-name: sunglasses
Target score:  89.56%, class-number:  300, class-name: bookcase
Gradient min: -0.000217, max:  0.000296, stepsize:  23618.89

Iteration: 14
Source score:   0.19%, class-number:  535, class-name: sunglasses
Target score:  89.90%, class-number:  300, class-name: bookcase
Gradient min: -0.000196, max:  0.000241, stepsize:  29075.62

Iteration: 15
Source score:   0.28%, class-number:  535, class-name: sunglasses
Target score:  87.20%, class-number:  300, class-name: bookcase
Gradient min: -0.000232, max:  0.000209, stepsize:  30222.49

Iteration: 16
Source score:   0.99%, class-number:  535, class-name: sunglasses
Target score:  75.64%, class-number:  300, class-name: bookcase
Gradient min: -0.000799, max:  0.000592, stepsize:   8761.73

Iteration: 17
Source score:   0.06%, class-number:  535, class-name: sunglasses
Target score:  96.55%, class-number:  300, class-name: bookcase
Gradient min: -0.000078, max:  0.000057, stepsize:  90126.50

Iteration: 18
Source score:   0.26%, class-number:  535, class-name: sunglasses
Target score:  85.38%, class-number:  300, class-name: bookcase
Gradient min: -0.000487, max:  0.000490, stepsize:  14284.58

Iteration: 19
Source score:   0.25%, class-number:  535, class-name: sunglasses
Target score:  93.26%, class-number:  300, class-name: bookcase
Gradient min: -0.000143, max:  0.000156, stepsize:  44844.46

Iteration: 20
Source score:   0.07%, class-number:  535, class-name: sunglasses
Target score:  93.84%, class-number:  300, class-name: bookcase
Gradient min: -0.000166, max:  0.000141, stepsize:  42205.53

Iteration: 21
Source score:   0.03%, class-number:  535, class-name: sunglasses
Target score:  98.31%, class-number:  300, class-name: bookcase
Gradient min: -0.000033, max:  0.000026, stepsize: 213124.72

Iteration: 22
Source score:   0.03%, class-number:  535, class-name: sunglasses
Target score:  98.80%, class-number:  300, class-name: bookcase
Gradient min: -0.000023, max:  0.000027, stepsize: 260036.19

Iteration: 23
Source score:   0.03%, class-number:  535, class-name: sunglasses
Target score:  99.03%, class-number:  300, class-name: bookcase
Gradient min: -0.000022, max:  0.000024, stepsize: 294094.62
</code></pre><p><img src="output_52_1.png" alt="png"></p>
<pre><code>Noise min: -3.000, max: 3.000, mean: 0.010, std: 1.534
</code></pre><p>&#x5728;&#x4E0A;&#x9762;&#x7684;&#x300A;&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382;&#x300B;&#x56FE;&#x50CF;&#x4E2D;&#xFF08;&#x65B0;&#x7248;&#x7535;&#x5F71;&#xFF09;&#xFF0C;&#x539F;&#x5148;Inception&#x6A21;&#x578B;&#x5C06;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x6210;&#x201C;&#x592A;&#x9633;&#x955C;&#x201D;&#xFF08;&#x8BC4;&#x5206;31.48%&#xFF09;&#x3002;&#x4F46;&#x518D;&#x4E00;&#x6B21;&#xFF0C;&#x6211;&#x4EEC;&#x80FD;&#x591F;&#x751F;&#x6210;&#x8BA9;&#x6A21;&#x578B;&#x5C06;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x6210;&#x201C;&#x4E66;&#x67B6;&#x201D;&#x7684;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#xFF08;&#x8BC4;&#x5206;99.03%&#xFF09;&#x3002;</p>
<p>&#x4E24;&#x5F20;&#x56FE;&#x50CF;&#x770B;&#x8D77;&#x6765;&#x4E00;&#x6837;&#x3002;&#x4F46;&#x4F60;&#x53EF;&#x4EE5;&#x503E;&#x659C;&#x7535;&#x8111;&#x5C4F;&#x5E55;&#xFF0C;&#x770B;&#x5230;&#x767D;&#x8272;&#x533A;&#x57DF;&#x4E00;&#x4E9B;&#x8F7B;&#x5FAE;&#x53D8;&#x5316;&#x7684;&#x566A;&#x58F0;&#x56FE;&#x6837;&#x3002;</p>
<h3 id="&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382;-&#x65E7;&#x7248;">&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382; (&#x65E7;&#x7248;)</h3>
<pre><code class="lang-python">image_path = <span class="hljs-string">&quot;images/willy_wonka_old.jpg&quot;</span>

adversary_example(image_path=image_path,
                  cls_target=<span class="hljs-number">300</span>,
                  noise_limit=<span class="hljs-number">3.0</span>,
                  required_score=<span class="hljs-number">0.99</span>)
</code></pre>
<pre><code>Iteration: 0
Source score:  97.22%, class-number:  817, class-name: bow tie
Target score:   0.00%, class-number:  300, class-name: bookcase
Gradient min: -0.002479, max:  0.003469, stepsize:   2017.94

Iteration: 1
Source score:  10.65%, class-number:  817, class-name: bow tie
Target score:   0.08%, class-number:  300, class-name: bookcase
Gradient min: -0.000859, max:  0.001458, stepsize:   4799.50

Iteration: 2
Source score:   2.21%, class-number:  817, class-name: bow tie
Target score:   0.25%, class-number:  300, class-name: bookcase
Gradient min: -0.000415, max:  0.000617, stepsize:  11350.70

Iteration: 3
Source score:   3.59%, class-number:  817, class-name: bow tie
Target score:   0.74%, class-number:  300, class-name: bookcase
Gradient min: -0.000643, max:  0.000752, stepsize:   9304.24

Iteration: 4
Source score:   3.05%, class-number:  817, class-name: bow tie
Target score:   1.42%, class-number:  300, class-name: bookcase
Gradient min: -0.000744, max:  0.000688, stepsize:   9407.59

Iteration: 5
Source score:   1.80%, class-number:  817, class-name: bow tie
Target score:   1.35%, class-number:  300, class-name: bookcase
Gradient min: -0.000924, max:  0.000954, stepsize:   7334.48

Iteration: 6
Source score:   9.09%, class-number:  817, class-name: bow tie
Target score:   3.70%, class-number:  300, class-name: bookcase
Gradient min: -0.002771, max:  0.003224, stepsize:   2171.03

Iteration: 7
Source score:   1.05%, class-number:  817, class-name: bow tie
Target score:  15.34%, class-number:  300, class-name: bookcase
Gradient min: -0.001409, max:  0.001925, stepsize:   3637.15

Iteration: 8
Source score:   1.58%, class-number:  817, class-name: bow tie
Target score:  32.90%, class-number:  300, class-name: bookcase
Gradient min: -0.001282, max:  0.001393, stepsize:   5023.51

Iteration: 9
Source score:   0.98%, class-number:  817, class-name: bow tie
Target score:  32.66%, class-number:  300, class-name: bookcase
Gradient min: -0.001728, max:  0.001736, stepsize:   4032.38

Iteration: 10
Source score:   0.59%, class-number:  817, class-name: bow tie
Target score:  66.56%, class-number:  300, class-name: bookcase
Gradient min: -0.000976, max:  0.000736, stepsize:   7173.06

Iteration: 11
Source score:   0.10%, class-number:  817, class-name: bow tie
Target score:  85.64%, class-number:  300, class-name: bookcase
Gradient min: -0.000260, max:  0.000254, stepsize:  26939.47

Iteration: 12
Source score:   0.15%, class-number:  817, class-name: bow tie
Target score:  89.87%, class-number:  300, class-name: bookcase
Gradient min: -0.000341, max:  0.000252, stepsize:  20529.36

Iteration: 13
Source score:   0.00%, class-number:  817, class-name: bow tie
Target score:  98.09%, class-number:  300, class-name: bookcase
Gradient min: -0.000037, max:  0.000041, stepsize: 168840.03

Iteration: 14
Source score:   0.07%, class-number:  817, class-name: bow tie
Target score:  95.18%, class-number:  300, class-name: bookcase
Gradient min: -0.000212, max:  0.000168, stepsize:  32997.19

Iteration: 15
Source score:   0.00%, class-number:  817, class-name: bow tie
Target score:  99.72%, class-number:  300, class-name: bookcase
Gradient min: -0.000004, max:  0.000004, stepsize: 1590352.60
</code></pre><p><img src="output_55_1.png" alt="png"></p>
<pre><code>Noise min: -3.000, max: 3.000, mean: -0.000, std: 1.309
</code></pre><p>&#x300A;&#x67E5;&#x7406;&#x548C;&#x5DE7;&#x514B;&#x529B;&#x5DE5;&#x5382;&#x300B;&#x56FE;&#x50CF;&#xFF08;&#x65E7;&#x7248;&#x7535;&#x5F71;&#xFF09;&#x539F;&#x5148;&#x88AB;Inception&#x6A21;&#x578B;&#x5206;&#x7C7B;&#x6210;&#x201C;&#x8774;&#x8776;&#x9886;&#x7ED3;&#x201D;&#x3002;&#x540C;&#x6837;&#xFF0C;&#x52A0;&#x4E86;&#x566A;&#x58F0;&#x4E4B;&#x540E;&#xFF0C;&#x5B83;&#x88AB;&#x5206;&#x7C7B;&#x6210;&#x201C;&#x4E66;&#x67B6;&#x201D;&#xFF08;&#x8BC4;&#x5206;99.72%&#xFF09;&#x3002;</p>
<h2 id="&#x5173;&#x95ED;tensorflow&#x4F1A;&#x8BDD;">&#x5173;&#x95ED;TensorFlow&#x4F1A;&#x8BDD;</h2>
<p>&#x73B0;&#x5728;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x7528;TensorFlow&#x5B8C;&#x6210;&#x4E86;&#x4EFB;&#x52A1;&#xFF0C;&#x5173;&#x95ED;session&#xFF0C;&#x91CA;&#x653E;&#x8D44;&#x6E90;&#x3002;&#x6CE8;&#x610F;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5173;&#x95ED;&#x4E24;&#x4E2A;TensorFlow-session&#xFF0C;&#x6BCF;&#x4E2A;&#x6A21;&#x578B;&#x5BF9;&#x8C61;&#x5404;&#x6709;&#x4E00;&#x4E2A;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># This has been commented out in case you want to modify and experiment</span>
<span class="hljs-comment"># with the Notebook without having to restart it.</span>
<span class="hljs-comment"># session.close()</span>
<span class="hljs-comment"># model.close()</span>
</code></pre>
<h2 id="&#x603B;&#x7ED3;">&#x603B;&#x7ED3;</h2>
<p>&#x6211;&#x4EEC;&#x6F14;&#x793A;&#x4E86;&#x5982;&#x4F55;&#x5BFB;&#x627E;&#x5BFC;&#x81F4;Inception&#x6A21;&#x578B;&#x8BEF;&#x5206;&#x7C7B;&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x3002;&#x901A;&#x8FC7;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x6D41;&#x7A0B;&#xFF0C;&#x6211;&#x4EEC;&#x53D1;&#x73B0;&#x5C06;&#x566A;&#x58F0;&#x6DFB;&#x52A0;&#x5230;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x4E0A;&#x4F1A;&#x4F7F;&#x6A21;&#x578B;&#x9519;&#x8BEF;&#x5730;&#x5206;&#x7C7B;&#x56FE;&#x50CF;&#xFF0C;&#x5373;&#x4F7F;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x53EA;&#x505A;&#x4E86;&#x8F7B;&#x5FAE;&#x7684;&#x6539;&#x53D8;&#xFF0C;&#x800C;&#x4E14;&#x4EBA;&#x773C;&#x65E0;&#x6CD5;&#x5BDF;&#x89C9;&#x8FD9;&#x4E9B;&#x53D8;&#x5316;&#x3002;</p>
<p>&#x66F4;&#x8FDB;&#x4E00;&#x6B65;&#xFF0C;&#x4F18;&#x5316;&#x540E;&#x7684;&#x566A;&#x58F0;&#x53EF;&#x4EE5;&#x7ED9;&#x51FA;&#x4E00;&#x4E2A;&#x63A5;&#x8FD1;100%&#x7684;&#x8BC4;&#x5206;&#xFF08;&#x6982;&#x7387;&#x6216;&#x786E;&#x4FE1;&#x5EA6;&#xFF09;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x4E0D;&#x4EC5;&#x88AB;&#x8BEF;&#x5206;&#x7C7B;&#x4E86;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8FD8;&#x5F88;&#x786E;&#x4FE1;&#x81EA;&#x5DF1;&#x6B63;&#x786E;&#x5730;&#x5206;&#x7C7B;&#x4E86;&#x56FE;&#x50CF;&#x3002;</p>
<p>&#x8FD9;&#x662F;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x4E00;&#x4E2A;&#x666E;&#x904D;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x5E76;&#x4E14;&#x662F;&#x4E00;&#x4E2A;&#x5F88;&#x4E25;&#x8083;&#x7684;&#x95EE;&#x9898;&#xFF01;&#x6211;&#x4EEC;&#x65E0;&#x6CD5;&#x5728;&#x5173;&#x952E;&#x5E94;&#x7528;&#x4E2D;&#x76F8;&#x4FE1;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x76F4;&#x5230;&#x80FD;&#x591F;&#x7406;&#x89E3;&#x4E3A;&#x4EC0;&#x4E48;&#x4F1A;&#x53D1;&#x751F;&#x4E0A;&#x8FF0;&#x95EE;&#x9898;&#x6216;&#x5982;&#x4F55;&#x89E3;&#x51B3;&#x5B83;&#x3002;&#x60F3;&#x8C61;&#x4E00;&#x4E0B;&#x81EA;&#x52A8;&#x9A7E;&#x9A76;&#x6C7D;&#x8F66;&#x7531;&#x4E8E;&#x5176;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BEF;&#x5206;&#x7C7B;&#x4E86;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x800C;&#x5FFD;&#x89C6;&#x505C;&#x6B62;&#x6807;&#x5FD7;&#x6216;&#x7A7F;&#x8FC7;&#x9A6C;&#x8DEF;&#x7684;&#x884C;&#x4EBA;&#x3002;</p>
<p>&#x5BF9;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x7684;&#x7814;&#x7A76;&#x6B63;&#x5728;&#x8FDB;&#x884C;&#x4E2D;&#xFF0C;&#x9F13;&#x52B1;&#x4F60;&#x5728;&#x7F51;&#x4E0A;&#x641C;&#x7D22;&#x4E00;&#x4E0B;&#x8FD9;&#x4E2A;&#x8BFE;&#x9898;&#x7684;&#x6700;&#x65B0;&#x8BBA;&#x6587;&#x3002;&#x4E5F;&#x8BB8;&#x4F60;&#x53EF;&#x4EE5;&#x627E;&#x5230;&#x95EE;&#x9898;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#xFF1F;</p>
<h2 id="&#x7EC3;&#x4E60;">&#x7EC3;&#x4E60;</h2>
<p>&#x4E0B;&#x9762;&#x4F7F;&#x4E00;&#x4E9B;&#x53EF;&#x80FD;&#x4F1A;&#x8BA9;&#x4F60;&#x63D0;&#x5347;TensorFlow&#x6280;&#x80FD;&#x7684;&#x4E00;&#x4E9B;&#x5EFA;&#x8BAE;&#x7EC3;&#x4E60;&#x3002;&#x4E3A;&#x4E86;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x66F4;&#x5408;&#x9002;&#x5730;&#x4F7F;&#x7528;TensorFlow&#xFF0C;&#x5B9E;&#x8DF5;&#x7ECF;&#x9A8C;&#x662F;&#x5F88;&#x91CD;&#x8981;&#x7684;&#x3002;</p>
<p>&#x5728;&#x4F60;&#x5BF9;&#x8FD9;&#x4E2A;Notebook&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x4E4B;&#x524D;&#xFF0C;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x5148;&#x5907;&#x4EFD;&#x4E00;&#x4E0B;&#x3002;</p>
<ul>
<li>&#x8BD5;&#x7740;&#x4F7F;&#x7528;&#x81EA;&#x5DF1;&#x7684;&#x56FE;&#x50CF;&#x3002;</li>
<li>&#x8BD5;&#x7740;&#x5728; <code>adversary_example()</code>&#x4E2D;&#x4F7F;&#x7528;&#x5176;&#x4ED6;&#x7684;&#x53C2;&#x6570;&#x3002;&#x8BD5;&#x8BD5;&#x5176;&#x5B83;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x522B;&#x3001;&#x566A;&#x58F0;&#x754C;&#x9650;&#x548C;&#x8BC4;&#x5206;&#x8981;&#x6C42;&#x3002;&#x7ED3;&#x679C;&#x662F;&#x600E;&#x6837;&#x7684;&#xFF1F;</li>
<li>&#x4F60;&#x8BA4;&#x4E3A;&#x5BF9;&#x4E8E;&#x6240;&#x6709;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x522B;&#x90FD;&#x80FD;&#x751F;&#x6210;&#x5B83;&#x7684;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x5417;&#xFF1F;&#x5982;&#x4F55;&#x8BC1;&#x660E;&#x4F60;&#x7684;&#x7406;&#x8BBA;&#xFF1F;</li>
<li>&#x8BD5;&#x7740;&#x5728;<code>find_adversary_noise()</code>&#x4E2D;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x516C;&#x5F0F;&#x6765;&#x8BA1;&#x7B97;step-size&#x3002;&#x4F60;&#x80FD;&#x4F7F;&#x4F18;&#x5316;&#x66F4;&#x5FEB;&#x5417;&#xFF1F;</li>
<li>&#x8BD5;&#x7740;&#x5728;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x8F93;&#x5165;&#x5230;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E4B;&#x524D;&#x5BF9;&#x5B83;&#x8FDB;&#x884C;&#x6A21;&#x7CCA;&#x5904;&#x7406;&#x3002;&#x5B83;&#x80FD;&#x53BB;&#x6389;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#xFF0C;&#x5E76;&#x4E14;&#x5BFC;&#x81F4;&#x518D;&#x4E00;&#x6B21;&#x7684;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x5417;&#xFF1F;</li>
<li>&#x8BD5;&#x7740;&#x964D;&#x4F4E;&#x566A;&#x58F0;&#x56FE;&#x50CF;&#x7684;&#x989C;&#x8272;&#x6DF1;&#x5EA6;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x5BF9;&#x5B83;&#x505A;&#x6A21;&#x7CCA;&#x3002;&#x5B83;&#x4F1A;&#x53BB;&#x9664;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x5E76;&#x5BFC;&#x81F4;&#x6B63;&#x786E;&#x5206;&#x7C7B;&#x5417;&#xFF1F;&#x6BD4;&#x5982;&#x5C06;&#x56FE;&#x50CF;&#x7684;RGB&#x9650;&#x5236;&#x5728;16&#x6216;32&#x4F4D;&#x91CC;&#xFF0C;&#x901A;&#x5E38;&#x662F;&#x6709;255&#x4F4D;&#x7684;&#x3002;</li>
<li>&#x4F60;&#x8BA4;&#x4E3A;&#x4F60;&#x7684;&#x566A;&#x58F0;&#x6D88;&#x9664;&#x5BF9;MNIST&#x6570;&#x636E;&#x96C6;&#x7684;&#x624B;&#x5199;&#x6570;&#x5B57;&#x6216;&#x5947;&#x7279;&#x7684;&#x51E0;&#x4F55;&#x5F62;&#x72B6;&#x6709;&#x6548;&#x5417;&#xFF1F;&#x6709;&#x65F6;&#x5C06;&#x8FD9;&#x4E9B;&#x79F0;&#x4E3A;&apos;fooling images&apos;&#xFF0C;&#x4E0A;&#x7F51;&#x641C;&#x7D22;&#x770B;&#x770B;&#x3002;</li>
<li>&#x4F60;&#x80FD;&#x627E;&#x5230;&#x5BF9;&#x6240;&#x6709;&#x56FE;&#x50CF;&#x90FD;&#x6709;&#x6548;&#x7684;&#x5BF9;&#x6297;&#x566A;&#x58F0;&#x5417;&#xFF1F;&#x8FD9;&#x6837;&#x5C31;&#x4E0D;&#x7528;&#x4E3A;&#x6BCF;&#x5F20;&#x56FE;&#x50CF;&#x5BFB;&#x627E;&#x7279;&#x5B9A;&#x7684;&#x566A;&#x58F0;&#x4E86;&#x3002;&#x4F60;&#x4F1A;&#x600E;&#x4E48;&#x505A;&#xFF1F;</li>
<li>&#x4F60;&#x80FD;&#x76F4;&#x63A5;&#x7528;TensorFlow&#x800C;&#x4E0D;&#x662F;Numpy&#x6765;&#x5B9E;&#x73B0;<code>find_adversary_noise()</code>&#x5417;&#xFF1F;&#x9700;&#x8981;&#x5728;TensorFlow&#x56FE;&#x4E2D;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x566A;&#x58F0;&#x53D8;&#x91CF;&#xFF0C;&#x8FD9;&#x6837;&#x5B83;&#x5C31;&#x80FD;&#x88AB;&#x4F18;&#x5316;&#x3002;</li>
<li>&#x5411;&#x670B;&#x53CB;&#x89E3;&#x91CA;&#x4EC0;&#x4E48;&#x662F;&#x5BF9;&#x6297;&#x6837;&#x672C;&#x4EE5;&#x53CA;&#x7A0B;&#x5E8F;&#x5982;&#x4F55;&#x627E;&#x5230;&#x5B83;&#x4EEC;&#x3002;</li>
</ul>
<h2 id="license-mit">License (MIT)</h2>
<p>Copyright (c) 2016 by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a></p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html" class="navigation navigation-prev " aria-label="Previous page: 视频数据">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html" class="navigation navigation-next " aria-label="Next page: MNIST的对抗噪声">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"对抗样本","level":"1.11","depth":1,"next":{"title":"MNIST的对抗噪声","level":"1.12","depth":1,"path":"12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.md","ref":"12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.md","articles":[]},"previous":{"title":"视频数据","level":"1.10","depth":1,"path":"09_Video_Data_zh_CN/09_Video_Data_zh_CN.md","ref":"09_Video_Data_zh_CN/09_Video_Data_zh_CN.md","articles":[]},"dir":"ltr"},"config":{"plugins":["comment"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"comment":{"highlightCommented":true},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"wizardforcel","pdf":{"pageNumbers":true,"fontSize":16,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"TensorFlow 教程（Hvass）","language":"zh","links":{"sidebar":{"TensorFlow 教程（Hvass）":"https://www.gitbook.com/book/wizardforcel/tf-tut-hvass"},"gitbook":true},"gitbook":"*","description":"Tensorflow 教程（Hvass）"},"file":{"path":"11_Adversarial_Examples_zh_CN/11_Adversarial_Examples_zh_CN.md","mtime":"2017-09-18T01:21:37.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2017-09-18T01:34:14.068Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-comment/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

