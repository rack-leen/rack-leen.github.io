
<!DOCTYPE HTML>
<html lang="zh" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>风格迁移 · TensorFlow 教程（Hvass）</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="wizardforcel">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-comment/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="輸入並搜尋" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://www.gitbook.com/book/wizardforcel/tf-tut-hvass" target="_blank" class="custom-link">TensorFlow 教程（Hvass）</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    TensorFlow 教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                <a href="../01_Simple_Linear_Model_zh_CN/01_Simple_Linear_Model_zh_CN.html">
            
                    
                    简单线性模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                <a href="../02_Convolutional_Neural_Network_zh_CN/02_Convolutional_Neural_Network_zh_CN.html">
            
                    
                    卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                <a href="../03_PrettyTensor_zh_CN/03_PrettyTensor_zh_CN.html">
            
                    
                    PrettyTensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                <a href="../04_Save_Restore_zh_CN/04_Save_Restore_zh_CN.html">
            
                    
                    保存 & 恢复
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../05_Ensemble_Learning_zh_CN/05_Ensemble_Learning_zh_CN.html">
            
                <a href="../05_Ensemble_Learning_zh_CN/05_Ensemble_Learning_zh_CN.html">
            
                    
                    集成学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                <a href="../06_CIFAR-10_zh_CN/06_CIFAR-10_zh_CN.html">
            
                    
                    CIFAR-10
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                <a href="../07_Inception_Model_zh_CN/07_Inception_Model_zh_CN.html">
            
                    
                    Inception 模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                <a href="../08_Transfer_Learning_zh_CN/08_Transfer_Learning_zh_CN.html">
            
                    
                    迁移学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                <a href="../09_Video_Data_zh_CN/09_Video_Data_zh_CN.html">
            
                    
                    视频数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../11_Adversarial_Examples_zh_CN/11_Adversarial_Examples_zh_CN.html">
            
                <a href="../11_Adversarial_Examples_zh_CN/11_Adversarial_Examples_zh_CN.html">
            
                    
                    对抗样本
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                <a href="../12_Adversarial_Noise_MNIST_zh_CN/12_Adversarial_Noise_MNIST_zh_CN.html">
            
                    
                    MNIST的对抗噪声
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                <a href="../13_Visual_Analysis_zh_CN/13_Visual_Analysis_zh_CN.html">
            
                    
                    可视化分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                <a href="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html">
            
                    
                    DeepDream
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.15" data-path="15_Style_Transfer_zh_CN.html">
            
                <a href="15_Style_Transfer_zh_CN.html">
            
                    
                    风格迁移
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本書使用 GitBook 釋出
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >风格迁移</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="tensorflow-&#x6559;&#x7A0B;-15">TensorFlow &#x6559;&#x7A0B; #15</h1>
<h1 id="&#x98CE;&#x683C;&#x8FC1;&#x79FB;">&#x98CE;&#x683C;&#x8FC1;&#x79FB;</h1>
<p>by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a>
/ <a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials" target="_blank">GitHub</a> / <a href="https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ" target="_blank">Videos on YouTube</a><br>&#x4E2D;&#x6587;&#x7FFB;&#x8BD1; <a href="https://zhuanlan.zhihu.com/insight-pixel" target="_blank">thrillerist</a>  / <a href="https://github.com/thrillerist/TensorFlow-Tutorials" target="_blank">Github</a></p>
<h2 id="&#x4ECB;&#x7ECD;">&#x4ECB;&#x7ECD;</h2>
<p>&#x5728;&#x4E4B;&#x524D;&#x7684;&#x6559;&#x7A0B;#14&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x770B;&#x5230;&#x4E86;&#x5982;&#x4F55;&#x6700;&#x5927;&#x5316;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5185;&#x90E8;&#x7684;&#x7279;&#x5F81;&#x6FC0;&#x6D3B;&#xFF0C;&#x4EE5;&#x4FBF;&#x653E;&#x5927;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x6A21;&#x5F0F;&#x3002;&#x8FD9;&#x4E2A;&#x79F0;&#x4E3A;DeepDream&#x3002;</p>
<p>&#x672C;&#x6587;&#x91C7;&#x7528;&#x4E86;&#x7C7B;&#x4F3C;&#x7684;&#x60F3;&#x6CD5;&#xFF0C;&#x4E0D;&#x8FC7;&#x6709;&#x4E24;&#x5F20;&#x8F93;&#x5165;&#x56FE;&#xFF1A;&#x4E00;&#x5F20;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x548C;&#x4E00;&#x5F20;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x521B;&#x5EFA;&#x4E00;&#x5F20;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#xFF0C;&#x5B83;&#x5305;&#x542B;&#x4E86;&#x5185;&#x5BB9;&#x56FE;&#x7684;&#x8F6E;&#x5ED3;&#x4EE5;&#x53CA;&#x98CE;&#x683C;&#x56FE;&#x7684;&#x7EB9;&#x7406;&#x3002;</p>
<p>&#x672C;&#x6587;&#x57FA;&#x4E8E;&#x4E4B;&#x524D;&#x7684;&#x6559;&#x7A0B;&#x3002;&#x4F60;&#x9700;&#x8981;&#x5927;&#x6982;&#x5730;&#x719F;&#x6089;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;&#x8BE6;&#x89C1;&#x6559;&#x7A0B; #01&#x548C; #02&#xFF09;&#xFF0C;&#x719F;&#x6089;&#x6559;&#x7A0B; #14&#x4E2D;&#x7684;DeepDream&#x4E5F;&#x5F88;&#x6709;&#x5E2E;&#x52A9;&#x3002;</p>
<h2 id="&#x6D41;&#x7A0B;&#x56FE;">&#x6D41;&#x7A0B;&#x56FE;</h2>
<p>&#x8FD9;&#x5F20;&#x6D41;&#x7A0B;&#x56FE;&#x663E;&#x793A;&#x4E86;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;&#x7684;&#x5927;&#x4F53;&#x60F3;&#x6CD5;&#xFF0C;&#x5C3D;&#x7BA1;&#x6BD4;&#x8D77;&#x56FE;&#x4E2D;&#x6240;&#x5C55;&#x793A;&#x51FA;&#x6765;&#x7684;&#xFF0C;&#x6211;&#x4EEC;&#x6240;&#x4F7F;&#x7528;&#x7684;VGG-16&#x6A21;&#x578B;&#x6709;&#x66F4;&#x591A;&#x7684;&#x5C42;&#x6B21;&#x3002;</p>
<p>&#x8F93;&#x5165;&#x4E24;&#x5F20;&#x56FE;&#x50CF;&#x5230;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#xFF1A;&#x4E00;&#x5F20;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x548C;&#x4E00;&#x5F20;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x3002;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x521B;&#x5EFA;&#x4E00;&#x5F20;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#xFF0C;&#x5B83;&#x5305;&#x542B;&#x4E86;&#x5185;&#x5BB9;&#x56FE;&#x7684;&#x8F6E;&#x5ED3;&#x4EE5;&#x53CA;&#x98CE;&#x683C;&#x56FE;&#x7684;&#x7EB9;&#x7406;&#x3002;
&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x521B;&#x5EFA;&#x51E0;&#x4E2A;&#x53EF;&#x4EE5;&#x88AB;&#x4F18;&#x5316;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x6765;&#x5B8C;&#x6210;&#x8FD9;&#x4E00;&#x70B9;&#x3002;</p>
<p>&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x8BD5;&#x7740;&#x5728;&#x7F51;&#x7EDC;&#x7684;&#x67D0;&#x4E00;&#x5C42;&#x6216;&#x591A;&#x5C42;&#x4E0A;&#xFF0C;&#x6700;&#x5C0F;&#x5316;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x4EE5;&#x53CA;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x6FC0;&#x6D3B;&#x7279;&#x5F81;&#x7684;&#x5DEE;&#x8DDD;&#x3002;&#x8FD9;&#x4F7F;&#x5F97;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x548C;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x7684;&#x8F6E;&#x5ED3;&#x76F8;&#x4F3C;&#x3002;</p>
<p>&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7A0D;&#x5FAE;&#x590D;&#x6742;&#x4E00;&#x4E9B;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x8BD5;&#x56FE;&#x8BA9;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x548C;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x7684;&#x683C;&#x62C9;&#x59C6;&#x77E9;&#x9635;&#xFF08;Gram-matrices&#xFF09;&#x7684;&#x5DEE;&#x5F02;&#x6700;&#x5C0F;&#x5316;&#x3002;&#x8FD9;&#x5728;&#x7F51;&#x7EDC;&#x7684;&#x4E00;&#x4E2A;&#x6216;&#x591A;&#x4E2A;&#x5C42;&#x4E2D;&#x5B8C;&#x6210;&#x3002; Gram-matrices&#x5EA6;&#x91CF;&#x4E86;&#x54EA;&#x4E2A;&#x7279;&#x5F81;&#x5728;&#x7ED9;&#x5B9A;&#x5C42;&#x4E2D;&#x540C;&#x65F6;&#x88AB;&#x6FC0;&#x6D3B;&#x3002;&#x6539;&#x53D8;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#xFF0C;&#x4F7F;&#x5176;&#x6A21;&#x4EFF;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x7684;&#x6FC0;&#x6D3B;&#x6A21;&#x5F0F;(activation patterns)&#xFF0C;&#x8FD9;&#x5C06;&#x5BFC;&#x81F4;&#x989C;&#x8272;&#x548C;&#x7EB9;&#x7406;&#x7684;&#x8FC1;&#x79FB;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x7528;TensorFlow&#x6765;&#x81EA;&#x52A8;&#x5BFC;&#x51FA;&#x8FD9;&#x4E9B;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#x3002;&#x7136;&#x540E;&#x7528;&#x68AF;&#x5EA6;&#x6765;&#x66F4;&#x65B0;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x3002;&#x91CD;&#x590D;&#x591A;&#x6B21;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#xFF0C;&#x76F4;&#x5230;&#x6211;&#x4EEC;&#x5BF9;&#x7ED3;&#x679C;&#x56FE;&#x50CF;&#x6EE1;&#x610F;&#x4E3A;&#x6B62;&#x3002;</p>
<p>&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;&#x7684;&#x4E00;&#x4E9B;&#x7EC6;&#x8282;&#x6CA1;&#x6709;&#x5728;&#x8FD9;&#x5F20;&#x6D41;&#x7A0B;&#x56FE;&#x4E2D;&#x663E;&#x793A;&#x51FA;&#x6765;&#xFF0C;&#x6BD4;&#x5982;&#xFF0C;&#x5BF9;&#x4E8E;Gram-matrices&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x8BA1;&#x7B97;&#x5E76;&#x4FDD;&#x5B58;&#x4E2D;&#x95F4;&#x503C;&#x6765;&#x63D0;&#x5347;&#x6548;&#x7387;&#xFF0C;&#x8FD8;&#x6709;&#x4E00;&#x4E2A;&#x7528;&#x6765;&#x7ED9;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x53BB;&#x566A;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x5BF9;&#x635F;&#x5931;&#x51FD;&#x6570;&#x505A;&#x5F52;&#x4E00;&#x5316;&#xFF08;normalization&#xFF09;&#xFF0C;&#x8FD9;&#x6837;&#x5B83;&#x4EEC;&#x66F4;&#x5BB9;&#x6613;&#x76F8;&#x5BF9;&#x5F7C;&#x6B64;&#x7F29;&#x653E;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image, display
Image(<span class="hljs-string">&apos;images/15_style_transfer_flowchart.png&apos;</span>)
</code></pre>
<p><img src="output_3_0.png" alt="png"></p>
<h2 id="imports">Imports</h2>
<pre><code class="lang-python">%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> PIL.Image
</code></pre>
<p>&#x4F7F;&#x7528;Python3.5.2&#xFF08;Anaconda&#xFF09;&#x5F00;&#x53D1;&#xFF0C;TensorFlow&#x7248;&#x672C;&#x662F;&#xFF1A;</p>
<pre><code class="lang-python">tf.__version__
</code></pre>
<pre><code>&apos;0.11.0rc0&apos;
</code></pre><h2 id="vgg-16-&#x6A21;&#x578B;">VGG-16 &#x6A21;&#x578B;</h2>
<p>&#x6211;&#x82B1;&#x4E86;&#x4E24;&#x5929;&#x65F6;&#x95F4;&#xFF0C;&#x60F3;&#x7528;&#x4E4B;&#x524D;&#x6559;&#x7A0B;#14&#x4E2D;&#x5728;DeepDream&#x4E0A;&#x4F7F;&#x7528;&#x7684;Inception 5h&#x6A21;&#x578B;&#x6765;&#x5B9E;&#x73B0;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;&#xFF0C;&#x4F46;&#x65E0;&#x6CD5;&#x5F97;&#x5230;&#x770B;&#x8D77;&#x6765;&#x8DB3;&#x591F;&#x597D;&#x7684;&#x56FE;&#x50CF;&#x3002;&#x8FD9;&#x6709;&#x70B9;&#x5947;&#x602A;&#xFF0C;&#x56E0;&#x4E3A;&#x6559;&#x7A0B;#14&#x4E2D;&#x751F;&#x6210;&#x7684;&#x56FE;&#x50CF;&#x770B;&#x8D77;&#x6765;&#x633A;&#x597D;&#x7684;&#x3002;&#x4F46;&#x56DE;&#x60F3;&#x8D77;&#x6765;&#xFF0C;&#x6211;&#x4EEC;&#xFF08;&#x5728;&#x6559;&#x7A0B;#14&#x91CC;&#xFF09;&#x4E5F;&#x7528;&#x4E86;&#x4E00;&#x4E9B;&#x6280;&#x5DE7;&#x6765;&#x5F97;&#x5230;&#x8FD9;&#x79CD;&#x8D28;&#x91CF;&#xFF0C;&#x6BD4;&#x5982;&#x5E73;&#x6ED1;&#x68AF;&#x5EA6;&#x4EE5;&#x53CA;&#x9012;&#x5F52;&#x7684;&#x964D;&#x91C7;&#x6837;&#x5E76;&#x5904;&#x7406;&#x56FE;&#x50CF;&#x3002;</p>
<p><a href="https://arxiv.org/abs/1508.06576" target="_blank">&#x539F;&#x59CB;&#x8BBA;&#x6587;</a> &#x4F7F;&#x7528;&#x4E86;VGG-19&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x51FA;&#x4E8E;&#x7531;&#x4E8E;&#x67D0;&#x4E9B;&#x539F;&#x56E0;&#xFF0C;&#x5BF9;&#x4E8E;TendorFlow&#x6765;&#x8BF4;&#xFF0C;&#x9884;&#x8BAD;&#x7EC3;&#x7684;VGG-19&#x6A21;&#x578B;&#x5728;&#x672C;&#x6559;&#x7A0B;&#x4E2D;&#x4E0D;&#x591F;&#x7A33;&#x5B9A;&#x3002;&#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x4F7F;&#x7528;VGG-16&#x6A21;&#x578B;&#xFF0C;&#x8FD9;&#x662F;&#x5176;&#x4ED6;&#x4EBA;&#x5236;&#x4F5C;&#x7684;&#xFF0C;&#x53EF;&#x4EE5;&#x5F88;&#x5BB9;&#x6613;&#x5730;&#x83B7;&#x53D6;&#x5E76;&#x5728;TensorFlow&#x4E2D;&#x8F7D;&#x5165;&#x3002;&#x65B9;&#x4FBF;&#x8D77;&#x89C1;&#xFF0C;&#x6211;&#x4EEC;&#x5C01;&#x88C5;&#x4E86;&#x4E00;&#x4E2A;&#x7C7B;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> vgg16
</code></pre>
<p>VGG-16&#x6A21;&#x578B;&#x662F;&#x4ECE;&#x7F51;&#x4E0A;&#x4E0B;&#x8F7D;&#x7684;&#x3002;&#x8FD9;&#x662F;&#x4F60;&#x4FDD;&#x5B58;&#x6570;&#x636E;&#x6587;&#x4EF6;&#x7684;&#x9ED8;&#x8BA4;&#x6587;&#x4EF6;&#x5939;&#x3002;&#x5982;&#x679C;&#x6587;&#x4EF6;&#x5939;&#x4E0D;&#x5B58;&#x5728;&#xFF0C;&#x5B83;&#x5C31;&#x4F1A;&#x88AB;&#x521B;&#x5EFA;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># vgg16.data_dir = &apos;vgg16/&apos;</span>
</code></pre>
<p>Download the data for the VGG-16 model if it doesn&apos;t already exist in the directory.</p>
<p><strong>WARNING: It is 550 MB!</strong></p>
<p>&#x5982;&#x679C;&#x6587;&#x4EF6;&#x5939;&#x4E2D;&#x6CA1;&#x6709;VGG-16&#x6A21;&#x578B;&#xFF0C;&#x5C31;&#x81EA;&#x52A8;&#x4E0B;&#x8F7D;&#x3002; </p>
<p><strong>&#x6CE8;&#x610F;&#xFF1A;&#x5B83;&#x6709;500MB&#xFF01;</strong></p>
<pre><code class="lang-python">vgg16.maybe_download()
</code></pre>
<pre><code>Downloading VGG16 Model ...
Data has apparently already been downloaded and unpacked.
</code></pre><h2 id="&#x64CD;&#x4F5C;&#x56FE;&#x50CF;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;">&#x64CD;&#x4F5C;&#x56FE;&#x50CF;&#x7684;&#x5E2E;&#x52A9;&#x51FD;&#x6570;</h2>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x8F7D;&#x5165;&#x4E00;&#x5F20;&#x56FE;&#x50CF;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x6D6E;&#x70B9;&#x578B;numpy&#x6570;&#x7EC4;&#x3002;&#x56FE;&#x50CF;&#x53EF;&#x4EE5;&#x88AB;&#x81EA;&#x52A8;&#x5730;&#x6539;&#x53D8;&#x5927;&#x5C0F;&#xFF0C;&#x56E0;&#x6B64;&#x6700;&#x5927;&#x7684;&#x5BBD;&#x9AD8;&#x7B49;&#x4E8E;<code>max_size</code>&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_image</span><span class="hljs-params">(filename, max_size=None)</span>:</span>
    image = PIL.Image.open(filename)

    <span class="hljs-keyword">if</span> max_size <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        <span class="hljs-comment"># Calculate the appropriate rescale-factor for</span>
        <span class="hljs-comment"># ensuring a max height and width, while keeping</span>
        <span class="hljs-comment"># the proportion between them.</span>
        factor = max_size / np.max(image.size)

        <span class="hljs-comment"># Scale the image&apos;s height and width.</span>
        size = np.array(image.size) * factor

        <span class="hljs-comment"># The size is now floating-point because it was scaled.</span>
        <span class="hljs-comment"># But PIL requires the size to be integers.</span>
        size = size.astype(int)

        <span class="hljs-comment"># Resize the image.</span>
        image = image.resize(size, PIL.Image.LANCZOS)

    <span class="hljs-comment"># Convert to numpy floating-point array.</span>
    <span class="hljs-keyword">return</span> np.float32(image)
</code></pre>
<p>&#x5C06;&#x56FE;&#x50CF;&#x4FDD;&#x5B58;&#x6210;&#x4E00;&#x4E2A;jpeg&#x6587;&#x4EF6;&#x3002;&#x7ED9;&#x5230;&#x7684;&#x56FE;&#x50CF;&#x662F;&#x4E00;&#x4E2A;&#x5305;&#x542B;0&#x5230;255&#x50CF;&#x7D20;&#x503C;&#x7684;numpy&#x6570;&#x7EC4;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_image</span><span class="hljs-params">(image, filename)</span>:</span>
    <span class="hljs-comment"># Ensure the pixel-values are between 0 and 255.</span>
    image = np.clip(image, <span class="hljs-number">0.0</span>, <span class="hljs-number">255.0</span>)

    <span class="hljs-comment"># Convert to bytes.</span>
    image = image.astype(np.uint8)

    <span class="hljs-comment"># Write the image-file in jpeg-format.</span>
    <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">&apos;wb&apos;</span>) <span class="hljs-keyword">as</span> file:
        PIL.Image.fromarray(image).save(file, <span class="hljs-string">&apos;jpeg&apos;</span>)
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7ED8;&#x5236;&#x51FA;&#x4E00;&#x5F20;&#x5927;&#x7684;&#x56FE;&#x50CF;&#x3002;&#x7ED9;&#x5230;&#x7684;&#x56FE;&#x50CF;&#x662F;&#x4E00;&#x4E2A;&#x5305;&#x542B;0&#x5230;255&#x50CF;&#x7D20;&#x503C;&#x7684;numpy&#x6570;&#x7EC4;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_image_big</span><span class="hljs-params">(image)</span>:</span>
    <span class="hljs-comment"># Ensure the pixel-values are between 0 and 255.</span>
    image = np.clip(image, <span class="hljs-number">0.0</span>, <span class="hljs-number">255.0</span>)

    <span class="hljs-comment"># Convert pixels to bytes.</span>
    image = image.astype(np.uint8)

    <span class="hljs-comment"># Convert to a PIL-image and display it.</span>
    display(PIL.Image.fromarray(image))
</code></pre>
<p> &#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x753B;&#x51FA;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#xFF0C;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x4EE5;&#x53CA;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_images</span><span class="hljs-params">(content_image, style_image, mixed_image)</span>:</span>
    <span class="hljs-comment"># Create figure with sub-plots.</span>
    fig, axes = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))

    <span class="hljs-comment"># Adjust vertical spacing.</span>
    fig.subplots_adjust(hspace=<span class="hljs-number">0.1</span>, wspace=<span class="hljs-number">0.1</span>)

    <span class="hljs-comment"># Use interpolation to smooth pixels?</span>
    smooth = <span class="hljs-keyword">True</span>

    <span class="hljs-comment"># Interpolation type.</span>
    <span class="hljs-keyword">if</span> smooth:
        interpolation = <span class="hljs-string">&apos;sinc&apos;</span>
    <span class="hljs-keyword">else</span>:
        interpolation = <span class="hljs-string">&apos;nearest&apos;</span>

    <span class="hljs-comment"># Plot the content-image.</span>
    <span class="hljs-comment"># Note that the pixel-values are normalized to</span>
    <span class="hljs-comment"># the [0.0, 1.0] range by dividing with 255.</span>
    ax = axes.flat[<span class="hljs-number">0</span>]
    ax.imshow(content_image / <span class="hljs-number">255.0</span>, interpolation=interpolation)
    ax.set_xlabel(<span class="hljs-string">&quot;Content&quot;</span>)

    <span class="hljs-comment"># Plot the mixed-image.</span>
    ax = axes.flat[<span class="hljs-number">1</span>]
    ax.imshow(mixed_image / <span class="hljs-number">255.0</span>, interpolation=interpolation)
    ax.set_xlabel(<span class="hljs-string">&quot;Mixed&quot;</span>)

    <span class="hljs-comment"># Plot the style-image</span>
    ax = axes.flat[<span class="hljs-number">2</span>]
    ax.imshow(style_image / <span class="hljs-number">255.0</span>, interpolation=interpolation)
    ax.set_xlabel(<span class="hljs-string">&quot;Style&quot;</span>)

    <span class="hljs-comment"># Remove ticks from all the plots.</span>
    <span class="hljs-keyword">for</span> ax <span class="hljs-keyword">in</span> axes.flat:
        ax.set_xticks([])
        ax.set_yticks([])

    <span class="hljs-comment"># Ensure the plot is shown correctly with multiple plots</span>
    <span class="hljs-comment"># in a single Notebook cell.</span>
    plt.show()
</code></pre>
<h2 id="&#x635F;&#x5931;&#x51FD;&#x6570;">&#x635F;&#x5931;&#x51FD;&#x6570;</h2>
<p>&#x8FD9;&#x4E9B;&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#x521B;&#x5EFA;&#x4E86;&#x5728;TensorFlow&#x4F18;&#x5316;&#x4E2D;&#x7528;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;</p>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x521B;&#x5EFA;&#x4E86;&#x4E00;&#x4E2A;TensorFlow&#x8FD0;&#x7B97;&#xFF0C;&#x7528;&#x6765;&#x8BA1;&#x7B97;&#x4E24;&#x4E2A;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x7684;&#x6700;&#x5C0F;&#x5E73;&#x5747;&#x8BEF;&#x5DEE;&#xFF08;Mean Squared Error&#xFF09;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mean_squared_error</span><span class="hljs-params">(a, b)</span>:</span>
    <span class="hljs-keyword">return</span> tf.reduce_mean(tf.square(a - b))
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x521B;&#x5EFA;&#x4E86;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;&#x5B83;&#x662F;&#x5728;&#x7ED9;&#x5B9A;&#x5C42;&#x4E2D;&#xFF0C;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x548C;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x6FC0;&#x6D3B;&#x7279;&#x5F81;&#x7684;&#x6700;&#x5C0F;&#x5E73;&#x5747;&#x8BEF;&#x5DEE;&#x3002;&#x5F53;&#x5185;&#x5BB9;&#x635F;&#x5931;&#x6700;&#x5C0F;&#x65F6;&#xFF0C;&#x610F;&#x5473;&#x7740;&#x5728;&#x7ED9;&#x5B9A;&#x5C42;&#x4E2D;&#xFF0C;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x4E0E;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x6FC0;&#x6D3B;&#x7279;&#x5F81;&#x5F88;&#x76F8;&#x4F3C;&#x3002;&#x6839;&#x636E;&#x4F60;&#x6240;&#x9009;&#x62E9;&#x7684;&#x5C42;&#x6B21;&#xFF0C;&#x8FD9;&#x4F1A;&#x5C06;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x8F6E;&#x5ED3;&#x8FC1;&#x79FB;&#x5230;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x4E2D;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_content_loss</span><span class="hljs-params">(session, model, content_image, layer_ids)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Create the loss-function for the content-image.

    Parameters:
    session: An open TensorFlow session for running the model&apos;s graph.
    model: The model, e.g. an instance of the VGG16-class.
    content_image: Numpy float array with the content-image.
    layer_ids: List of integer id&apos;s for the layers to use in the model.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Create a feed-dict with the content-image.</span>
    feed_dict = model.create_feed_dict(image=content_image)

    <span class="hljs-comment"># Get references to the tensors for the given layers.</span>
    layers = model.get_layer_tensors(layer_ids)

    <span class="hljs-comment"># Calculate the output values of those layers when</span>
    <span class="hljs-comment"># feeding the content-image to the model.</span>
    values = session.run(layers, feed_dict=feed_dict)

    <span class="hljs-comment"># Set the model&apos;s graph as the default so we can add</span>
    <span class="hljs-comment"># computational nodes to it. It is not always clear</span>
    <span class="hljs-comment"># when this is necessary in TensorFlow, but if you</span>
    <span class="hljs-comment"># want to re-use this code then it may be necessary.</span>
    <span class="hljs-keyword">with</span> model.graph.as_default():
        <span class="hljs-comment"># Initialize an empty list of loss-functions.</span>
        layer_losses = []

        <span class="hljs-comment"># For each layer and its corresponding values</span>
        <span class="hljs-comment"># for the content-image.</span>
        <span class="hljs-keyword">for</span> value, layer <span class="hljs-keyword">in</span> zip(values, layers):
            <span class="hljs-comment"># These are the values that are calculated</span>
            <span class="hljs-comment"># for this layer in the model when inputting</span>
            <span class="hljs-comment"># the content-image. Wrap it to ensure it</span>
            <span class="hljs-comment"># is a const - although this may be done</span>
            <span class="hljs-comment"># automatically by TensorFlow.</span>
            value_const = tf.constant(value)

            <span class="hljs-comment"># The loss-function for this layer is the</span>
            <span class="hljs-comment"># Mean Squared Error between the layer-values</span>
            <span class="hljs-comment"># when inputting the content- and mixed-images.</span>
            <span class="hljs-comment"># Note that the mixed-image is not calculated</span>
            <span class="hljs-comment"># yet, we are merely creating the operations</span>
            <span class="hljs-comment"># for calculating the MSE between those two.</span>
            loss = mean_squared_error(layer, value_const)

            <span class="hljs-comment"># Add the loss-function for this layer to the</span>
            <span class="hljs-comment"># list of loss-functions.</span>
            layer_losses.append(loss)

        <span class="hljs-comment"># The combined loss for all layers is just the average.</span>
        <span class="hljs-comment"># The loss-functions could be weighted differently for</span>
        <span class="hljs-comment"># each layer. You can try it and see what happens.</span>
        total_loss = tf.reduce_mean(layer_losses)

    <span class="hljs-keyword">return</span> total_loss
</code></pre>
<p>&#x6211;&#x4EEC;&#x5C06;&#x5BF9;&#x98CE;&#x683C;&#x5C42;&#x505A;&#x76F8;&#x540C;&#x7684;&#x5904;&#x7406;&#xFF0C;&#x4F46;&#x73B0;&#x5728;&#x9700;&#x8981;&#x5EA6;&#x91CF;&#x51FA;&#x54EA;&#x4E9B;&#x7279;&#x5F81;&#x5728;&#x98CE;&#x683C;&#x5C42;&#x548C;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x4E2D;&#x540C;&#x65F6;&#x88AB;&#x6FC0;&#x6D3B;&#xFF0C;&#x63A5;&#x7740;&#x5C06;&#x8FD9;&#x4E9B;&#x6FC0;&#x6D3B;&#x6A21;&#x5F0F;&#x590D;&#x5236;&#x5230;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x4E2D;&#x3002;</p>
<p> &#x4E00;&#x79CD;&#x529E;&#x6CD5;&#x662F;&#x4E3A;&#x98CE;&#x683C;&#x5C42;&#x7684;&#x8F93;&#x51FA;&#x5F20;&#x91CF;&#x8BA1;&#x7B97;&#x4E00;&#x4E2A;&#x6240;&#x8C13;&#x7684;&#x683C;&#x62C9;&#x59C6;&#x77E9;&#x9635;&#xFF08;Gram-matrix&#xFF09;&#x3002;Gram-matrix&#x672C;&#x8D28;&#x4E0A;&#x5C31;&#x662F;&#x98CE;&#x683C;&#x5C42;&#x4E2D;&#x6FC0;&#x6D3B;&#x7279;&#x5F81;&#x5411;&#x91CF;&#x7684;&#x70B9;&#x4E58;&#x77E9;&#x9635;&#x3002;</p>
<p>&#x5982;&#x679C;Gram-matrix&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x503C;&#x63A5;&#x8FD1;&#x4E8E;0&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x7ED9;&#x5B9A;&#x5C42;&#x7684;&#x4E24;&#x4E2A;&#x7279;&#x5F81;&#x5728;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x4E2D;&#x6CA1;&#x6709;&#x540C;&#x65F6;&#x6FC0;&#x6D3B;&#x3002;&#x53CD;&#x4E4B;&#x4EA6;&#x7136;&#xFF0C;&#x5982;&#x679C;Gram-matrix&#x4E2D;&#x6709;&#x5F88;&#x5927;&#x7684;&#x503C;&#xFF0C;&#x4EE3;&#x8868;&#x7740;&#x4E24;&#x4E2A;&#x7279;&#x5F81;&#x540C;&#x65F6;&#x88AB;&#x6FC0;&#x6D3B;&#x3002;&#x63A5;&#x7740;&#xFF0C;&#x6211;&#x4EEC;&#x4F1A;&#x8BD5;&#x56FE;&#x751F;&#x6210;&#x590D;&#x5236;&#x4E86;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x6FC0;&#x6D3B;&#x6A21;&#x5F0F;&#x7684;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x3002;</p>
<p>&#x8FD9;&#x4E2A;&#x5E2E;&#x52A9;&#x51FD;&#x6570;&#x7528;&#x6765;&#x8BA1;&#x7B97;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x5377;&#x79EF;&#x5C42;&#x8F93;&#x51FA;&#x5F20;&#x91CF;&#x7684;Gram-matrix&#x3002;&#x771F;&#x6B63;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5728;&#x540E;&#x9762;&#x521B;&#x5EFA;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gram_matrix</span><span class="hljs-params">(tensor)</span>:</span>
    shape = tensor.get_shape()

    <span class="hljs-comment"># Get the number of feature channels for the input tensor,</span>
    <span class="hljs-comment"># which is assumed to be from a convolutional layer with 4-dim.</span>
    num_channels = int(shape[<span class="hljs-number">3</span>])

    <span class="hljs-comment"># Reshape the tensor so it is a 2-dim matrix. This essentially</span>
    <span class="hljs-comment"># flattens the contents of each feature-channel.</span>
    matrix = tf.reshape(tensor, shape=[<span class="hljs-number">-1</span>, num_channels])

    <span class="hljs-comment"># Calculate the Gram-matrix as the matrix-product of</span>
    <span class="hljs-comment"># the 2-dim matrix with itself. This calculates the</span>
    <span class="hljs-comment"># dot-products of all combinations of the feature-channels.</span>
    gram = tf.matmul(tf.transpose(matrix), matrix)

    <span class="hljs-keyword">return</span> gram
</code></pre>
<p>&#x4E0B;&#x9762;&#x7684;&#x51FD;&#x6570;&#x521B;&#x5EFA;&#x4E86;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;&#x5B83;&#x548C;&#x4E0A;&#x9762;&#x7684;<code>create_content_loss()</code>&#x5F88;&#x50CF;&#xFF0C;&#x9664;&#x4E86;&#x6211;&#x4EEC;&#x662F;&#x8BA1;&#x7B97;Gram-matrix&#x800C;&#x975E;layer&#x8F93;&#x51FA;&#x5F20;&#x91CF;&#x7684;&#x6700;&#x5C0F;&#x5E73;&#x65B9;&#x8BEF;&#x5DEE;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_style_loss</span><span class="hljs-params">(session, model, style_image, layer_ids)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Create the loss-function for the style-image.

    Parameters:
    session: An open TensorFlow session for running the model&apos;s graph.
    model: The model, e.g. an instance of the VGG16-class.
    style_image: Numpy float array with the style-image.
    layer_ids: List of integer id&apos;s for the layers to use in the model.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Create a feed-dict with the style-image.</span>
    feed_dict = model.create_feed_dict(image=style_image)

    <span class="hljs-comment"># Get references to the tensors for the given layers.</span>
    layers = model.get_layer_tensors(layer_ids)

    <span class="hljs-comment"># Set the model&apos;s graph as the default so we can add</span>
    <span class="hljs-comment"># computational nodes to it. It is not always clear</span>
    <span class="hljs-comment"># when this is necessary in TensorFlow, but if you</span>
    <span class="hljs-comment"># want to re-use this code then it may be necessary.</span>
    <span class="hljs-keyword">with</span> model.graph.as_default():
        <span class="hljs-comment"># Construct the TensorFlow-operations for calculating</span>
        <span class="hljs-comment"># the Gram-matrices for each of the layers.</span>
        gram_layers = [gram_matrix(layer) <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers]

        <span class="hljs-comment"># Calculate the values of those Gram-matrices when</span>
        <span class="hljs-comment"># feeding the style-image to the model.</span>
        values = session.run(gram_layers, feed_dict=feed_dict)

        <span class="hljs-comment"># Initialize an empty list of loss-functions.</span>
        layer_losses = []

        <span class="hljs-comment"># For each Gram-matrix layer and its corresponding values.</span>
        <span class="hljs-keyword">for</span> value, gram_layer <span class="hljs-keyword">in</span> zip(values, gram_layers):
            <span class="hljs-comment"># These are the Gram-matrix values that are calculated</span>
            <span class="hljs-comment"># for this layer in the model when inputting the</span>
            <span class="hljs-comment"># style-image. Wrap it to ensure it is a const,</span>
            <span class="hljs-comment"># although this may be done automatically by TensorFlow.</span>
            value_const = tf.constant(value)

            <span class="hljs-comment"># The loss-function for this layer is the</span>
            <span class="hljs-comment"># Mean Squared Error between the Gram-matrix values</span>
            <span class="hljs-comment"># for the content- and mixed-images.</span>
            <span class="hljs-comment"># Note that the mixed-image is not calculated</span>
            <span class="hljs-comment"># yet, we are merely creating the operations</span>
            <span class="hljs-comment"># for calculating the MSE between those two.</span>
            loss = mean_squared_error(gram_layer, value_const)

            <span class="hljs-comment"># Add the loss-function for this layer to the</span>
            <span class="hljs-comment"># list of loss-functions.</span>
            layer_losses.append(loss)

        <span class="hljs-comment"># The combined loss for all layers is just the average.</span>
        <span class="hljs-comment"># The loss-functions could be weighted differently for</span>
        <span class="hljs-comment"># each layer. You can try it and see what happens.</span>
        total_loss = tf.reduce_mean(layer_losses)

    <span class="hljs-keyword">return</span> total_loss
</code></pre>
<p>&#x4E0B;&#x9762;&#x521B;&#x5EFA;&#x4E86;&#x7528;&#x6765;&#x7ED9;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x53BB;&#x566A;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;&#x8FD9;&#x4E2A;&#x7B97;&#x6CD5;&#x79F0;&#x4E3A;<a href="https://en.wikipedia.org/wiki/Total_variation_denoising" target="_blank">Total Variation Denoising</a>&#xFF0C;&#x672C;&#x8D28;&#x4E0A;&#x5C31;&#x662F;&#x5728;x&#x548C;y&#x8F74;&#x4E0A;&#x5C06;&#x56FE;&#x50CF;&#x504F;&#x79FB;&#x4E00;&#x4E2A;&#x50CF;&#x7D20;&#xFF0C;&#x8BA1;&#x7B97;&#x5B83;&#x4E0E;&#x539F;&#x59CB;&#x56FE;&#x50CF;&#x7684;&#x5DEE;&#x5F02;&#xFF0C;&#x53D6;&#x7EDD;&#x5BF9;&#x503C;&#x4FDD;&#x8BC1;&#x5DEE;&#x5F02;&#x662F;&#x6B63;&#x503C;&#xFF0C;&#x7136;&#x540E;&#x5BF9;&#x6574;&#x4E2A;&#x56FE;&#x50CF;&#x6240;&#x6709;&#x50CF;&#x7D20;&#x6C42;&#x548C;&#x3002;&#x8FD9;&#x4E2A;&#x6B65;&#x9AA4;&#x521B;&#x5EFA;&#x4E86;&#x4E00;&#x4E2A;&#x53EF;&#x4EE5;&#x6700;&#x5C0F;&#x5316;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x7528;&#x6765;&#x6291;&#x5236;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x566A;&#x58F0;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_denoise_loss</span><span class="hljs-params">(model)</span>:</span>
    loss = tf.reduce_sum(tf.abs(model.input[:,<span class="hljs-number">1</span>:,:,:] - model.input[:,:<span class="hljs-number">-1</span>,:,:])) + \
           tf.reduce_sum(tf.abs(model.input[:,:,<span class="hljs-number">1</span>:,:] - model.input[:,:,:<span class="hljs-number">-1</span>,:]))

    <span class="hljs-keyword">return</span> loss
</code></pre>
<h2 id="&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;">&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;</h2>
<p>&#x8FD9;&#x662F;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x4E3B;&#x8981;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x3002;&#x5B83;&#x57FA;&#x672C;&#x4E0A;&#x5C31;&#x662F;&#x5728;&#x4E0A;&#x9762;&#x5B9A;&#x4E49;&#x7684;&#x90A3;&#x4E9B;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4E0A;&#x505A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x3002;</p>
<p>&#x7B97;&#x6CD5;&#x4E5F;&#x4F7F;&#x7528;&#x4E86;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7684;&#x5F52;&#x4E00;&#x5316;&#x3002;&#x8FD9;&#x4F3C;&#x4E4E;&#x662F;&#x4E00;&#x4E2A;&#x4E4B;&#x524D;&#x672A;&#x53D1;&#x8868;&#x8FC7;&#x7684;&#x65B0;&#x9896;&#x60F3;&#x6CD5;&#x3002;&#x5728;&#x6BCF;&#x6B21;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x4E2D;&#xFF0C;&#x8C03;&#x6574;&#x635F;&#x5931;&#x503C;&#xFF0C;&#x4F7F;&#x5B83;&#x4EEC;&#x7B49;&#x4E8E;&#x4E00;&#x3002;&#x8FD9;&#x8BA9;&#x7528;&#x6237;&#x53EF;&#x4EE5;&#x72EC;&#x7ACB;&#x5730;&#x8BBE;&#x7F6E;&#x6240;&#x9009;&#x98CE;&#x683C;&#x5C42;&#x4EE5;&#x53CA;&#x5185;&#x5BB9;&#x5C42;&#x7684;&#x635F;&#x5931;&#x6743;&#x91CD;&#x3002;&#x540C;&#x65F6;&#xFF0C;&#x5728;&#x4F18;&#x5316;&#x8FC7;&#x7A0B;&#x4E2D;&#x4E5F;&#x4FEE;&#x6539;&#x6743;&#x91CD;&#xFF0C;&#x6765;&#x786E;&#x4FDD;&#x4FDD;&#x7559;&#x98CE;&#x683C;&#x3001;&#x5185;&#x5BB9;&#x3001;&#x53BB;&#x566A;&#x4E4B;&#x95F4;&#x6240;&#x9700;&#x7684;&#x6BD4;&#x91CD;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">style_transfer</span><span class="hljs-params">(content_image, style_image,
                   content_layer_ids, style_layer_ids,
                   weight_content=<span class="hljs-number">1.5</span>, weight_style=<span class="hljs-number">10.0</span>,
                   weight_denoise=<span class="hljs-number">0.3</span>,
                   num_iterations=<span class="hljs-number">120</span>, step_size=<span class="hljs-number">10.0</span>)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Use gradient descent to find an image that minimizes the
    loss-functions of the content-layers and style-layers. This
    should result in a mixed-image that resembles the contours
    of the content-image, and resembles the colours and textures
    of the style-image.

    Parameters:
    content_image: Numpy 3-dim float-array with the content-image.
    style_image: Numpy 3-dim float-array with the style-image.
    content_layer_ids: List of integers identifying the content-layers.
    style_layer_ids: List of integers identifying the style-layers.
    weight_content: Weight for the content-loss-function.
    weight_style: Weight for the style-loss-function.
    weight_denoise: Weight for the denoising-loss-function.
    num_iterations: Number of optimization iterations to perform.
    step_size: Step-size for the gradient in each iteration.
    &quot;&quot;&quot;</span>

    <span class="hljs-comment"># Create an instance of the VGG16-model. This is done</span>
    <span class="hljs-comment"># in each call of this function, because we will add</span>
    <span class="hljs-comment"># operations to the graph so it can grow very large</span>
    <span class="hljs-comment"># and run out of RAM if we keep using the same instance.</span>
    model = vgg16.VGG16()

    <span class="hljs-comment"># Create a TensorFlow-session.</span>
    session = tf.InteractiveSession(graph=model.graph)

    <span class="hljs-comment"># Print the names of the content-layers.</span>
    print(<span class="hljs-string">&quot;Content layers:&quot;</span>)
    print(model.get_layer_names(content_layer_ids))
    print()

    <span class="hljs-comment"># Print the names of the style-layers.</span>
    print(<span class="hljs-string">&quot;Style layers:&quot;</span>)
    print(model.get_layer_names(style_layer_ids))
    print()

    <span class="hljs-comment"># Create the loss-function for the content-layers and -image.</span>
    loss_content = create_content_loss(session=session,
                                       model=model,
                                       content_image=content_image,
                                       layer_ids=content_layer_ids)

    <span class="hljs-comment"># Create the loss-function for the style-layers and -image.</span>
    loss_style = create_style_loss(session=session,
                                   model=model,
                                   style_image=style_image,
                                   layer_ids=style_layer_ids)    

    <span class="hljs-comment"># Create the loss-function for the denoising of the mixed-image.</span>
    loss_denoise = create_denoise_loss(model)

    <span class="hljs-comment"># Create TensorFlow variables for adjusting the values of</span>
    <span class="hljs-comment"># the loss-functions. This is explained below.</span>
    adj_content = tf.Variable(<span class="hljs-number">1e-10</span>, name=<span class="hljs-string">&apos;adj_content&apos;</span>)
    adj_style = tf.Variable(<span class="hljs-number">1e-10</span>, name=<span class="hljs-string">&apos;adj_style&apos;</span>)
    adj_denoise = tf.Variable(<span class="hljs-number">1e-10</span>, name=<span class="hljs-string">&apos;adj_denoise&apos;</span>)

    <span class="hljs-comment"># Initialize the adjustment values for the loss-functions.</span>
    session.run([adj_content.initializer,
                 adj_style.initializer,
                 adj_denoise.initializer])

    <span class="hljs-comment"># Create TensorFlow operations for updating the adjustment values.</span>
    <span class="hljs-comment"># These are basically just the reciprocal values of the</span>
    <span class="hljs-comment"># loss-functions, with a small value 1e-10 added to avoid the</span>
    <span class="hljs-comment"># possibility of division by zero.</span>
    update_adj_content = adj_content.assign(<span class="hljs-number">1.0</span> / (loss_content + <span class="hljs-number">1e-10</span>))
    update_adj_style = adj_style.assign(<span class="hljs-number">1.0</span> / (loss_style + <span class="hljs-number">1e-10</span>))
    update_adj_denoise = adj_denoise.assign(<span class="hljs-number">1.0</span> / (loss_denoise + <span class="hljs-number">1e-10</span>))

    <span class="hljs-comment"># This is the weighted loss-function that we will minimize</span>
    <span class="hljs-comment"># below in order to generate the mixed-image.</span>
    <span class="hljs-comment"># Because we multiply the loss-values with their reciprocal</span>
    <span class="hljs-comment"># adjustment values, we can use relative weights for the</span>
    <span class="hljs-comment"># loss-functions that are easier to select, as they are</span>
    <span class="hljs-comment"># independent of the exact choice of style- and content-layers.</span>
    loss_combined = weight_content * adj_content * loss_content + \
                    weight_style * adj_style * loss_style + \
                    weight_denoise * adj_denoise * loss_denoise

    <span class="hljs-comment"># Use TensorFlow to get the mathematical function for the</span>
    <span class="hljs-comment"># gradient of the combined loss-function with regard to</span>
    <span class="hljs-comment"># the input image.</span>
    gradient = tf.gradients(loss_combined, model.input)

    <span class="hljs-comment"># List of tensors that we will run in each optimization iteration.</span>
    run_list = [gradient, update_adj_content, update_adj_style, \
                update_adj_denoise]

    <span class="hljs-comment"># The mixed-image is initialized with random noise.</span>
    <span class="hljs-comment"># It is the same size as the content-image.</span>
    mixed_image = np.random.rand(*content_image.shape) + <span class="hljs-number">128</span>

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_iterations):
        <span class="hljs-comment"># Create a feed-dict with the mixed-image.</span>
        feed_dict = model.create_feed_dict(image=mixed_image)

        <span class="hljs-comment"># Use TensorFlow to calculate the value of the</span>
        <span class="hljs-comment"># gradient, as well as updating the adjustment values.</span>
        grad, adj_content_val, adj_style_val, adj_denoise_val \
        = session.run(run_list, feed_dict=feed_dict)

        <span class="hljs-comment"># Reduce the dimensionality of the gradient.</span>
        grad = np.squeeze(grad)

        <span class="hljs-comment"># Scale the step-size according to the gradient-values.</span>
        step_size_scaled = step_size / (np.std(grad) + <span class="hljs-number">1e-8</span>)

        <span class="hljs-comment"># Update the image by following the gradient.</span>
        mixed_image -= grad * step_size_scaled

        <span class="hljs-comment"># Ensure the image has valid pixel-values between 0 and 255.</span>
        mixed_image = np.clip(mixed_image, <span class="hljs-number">0.0</span>, <span class="hljs-number">255.0</span>)

        <span class="hljs-comment"># Print a little progress-indicator.</span>
        print(<span class="hljs-string">&quot;. &quot;</span>, end=<span class="hljs-string">&quot;&quot;</span>)

        <span class="hljs-comment"># Display status once every 10 iterations, and the last.</span>
        <span class="hljs-keyword">if</span> (i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (i == num_iterations - <span class="hljs-number">1</span>):
            print()
            print(<span class="hljs-string">&quot;Iteration:&quot;</span>, i)

            <span class="hljs-comment"># Print adjustment weights for loss-functions.</span>
            msg = <span class="hljs-string">&quot;Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}&quot;</span>
            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))

            <span class="hljs-comment"># Plot the content-, style- and mixed-images.</span>
            plot_images(content_image=content_image,
                        style_image=style_image,
                        mixed_image=mixed_image)

    print()
    print(<span class="hljs-string">&quot;Final image:&quot;</span>)
    plot_image_big(mixed_image)

    <span class="hljs-comment"># Close the TensorFlow session to release its resources.</span>
    session.close()

    <span class="hljs-comment"># Return the mixed-image.</span>
    <span class="hljs-keyword">return</span> mixed_image
</code></pre>
<h2 id="&#x4F8B;&#x5B50;">&#x4F8B;&#x5B50;</h2>
<p>&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x5C55;&#x793A;&#x4E86;&#x5982;&#x4F55;&#x5C06;&#x591A;&#x5F20;&#x56FE;&#x50CF;&#x7684;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x5230;&#x4E00;&#x5F20;&#x8096;&#x50CF;&#x4E0A;&#x3002;</p>
<p>&#x9996;&#x5148;&#xFF0C;&#x6211;&#x4EEC;&#x8F7D;&#x5165;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#xFF0C;&#x5B83;&#x6709;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x60F3;&#x8981;&#x7684;&#x5927;&#x4F53;&#x8F6E;&#x5ED3;&#x3002;</p>
<pre><code class="lang-python">content_filename = <span class="hljs-string">&apos;images/willy_wonka_old.jpg&apos;</span>
content_image = load_image(content_filename, max_size=<span class="hljs-keyword">None</span>)
</code></pre>
<p>&#x7136;&#x540E;&#x6211;&#x4EEC;&#x8F7D;&#x5165;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#xFF0C;&#x5B83;&#x62E5;&#x6709;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#x60F3;&#x8981;&#x7684;&#x989C;&#x8272;&#x548C;&#x7EB9;&#x7406;&#x3002;</p>
<pre><code class="lang-python">style_filename = <span class="hljs-string">&apos;images/style7.jpg&apos;</span>
style_image = load_image(style_filename, max_size=<span class="hljs-number">300</span>)
</code></pre>
<p>&#x63A5;&#x7740;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x6574;&#x6570;&#x5217;&#x8868;&#xFF0C;&#x5B83;&#x4EE3;&#x8868;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x6211;&#x4EEC;&#x7528;&#x6765;&#x5339;&#x914D;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x5C42;&#x6B21;&#x3002;&#x8FD9;&#x4E9B;&#x662F;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x6B21;&#x7684;&#x7D22;&#x5F15;&#x3002;&#x5BF9;&#x4E8E;VGG16&#x6A21;&#x578B;&#xFF0C;&#x7B2C;5&#x5C42;&#xFF08;&#x7D22;&#x5F15;4&#xFF09;&#x4F3C;&#x4E4E;&#x662F;&#x552F;&#x4E00;&#x6709;&#x6548;&#x7684;&#x5185;&#x5BB9;&#x5C42;&#x3002;</p>
<pre><code class="lang-python">content_layer_ids = [<span class="hljs-number">4</span>]
</code></pre>
<p>&#x7136;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x4E3A;&#x98CE;&#x683C;&#x5C42;&#x5B9A;&#x4E49;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x6574;&#x578B;&#x6570;&#x7EC4;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># The VGG16-model has 13 convolutional layers.</span>
<span class="hljs-comment"># This selects all those layers as the style-layers.</span>
<span class="hljs-comment"># This is somewhat slow to optimize.</span>
style_layer_ids = list(range(<span class="hljs-number">13</span>))

<span class="hljs-comment"># You can also select a sub-set of the layers, e.g. like this:</span>
<span class="hljs-comment"># style_layer_ids = [1, 2, 3, 4]</span>
</code></pre>
<p>&#x73B0;&#x5728;&#x6267;&#x884C;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x3002;&#x5B83;&#x81EA;&#x52A8;&#x5730;&#x4E3A;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x3001;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x521B;&#x5EFA;&#x5408;&#x9002;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x7136;&#x540E;&#x8FDB;&#x884C;&#x591A;&#x6B21;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x3002;&#x8FD9;&#x5C06;&#x9010;&#x6B65;&#x5730;&#x751F;&#x6210;&#x4E00;&#x5F20;&#x6DF7;&#x5408;&#x56FE;&#x50CF;&#xFF0C;&#x5176;&#x62E5;&#x6709;&#x5185;&#x5BB9;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x4F53;&#x8F6E;&#x5ED3;&#xFF0C;&#x5E76;&#x4E14;&#x5B83;&#x7684;&#x7EB9;&#x7406;&#x3001;&#x989C;&#x8272;&#x548C;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x7C7B;&#x4F3C;&#x3002;</p>
<p>&#x5728;CPU&#x4E0A;&#x8FD9;&#x4E2A;&#x8FD0;&#x7B97;&#x4F1A;&#x5F88;&#x6162;&#xFF01;</p>
<pre><code class="lang-python">%%time
img = style_transfer(content_image=content_image,
                     style_image=style_image,
                     content_layer_ids=content_layer_ids,
                     style_layer_ids=style_layer_ids,
                     weight_content=<span class="hljs-number">1.5</span>,
                     weight_style=<span class="hljs-number">10.0</span>,
                     weight_denoise=<span class="hljs-number">0.3</span>,
                     num_iterations=<span class="hljs-number">60</span>,
                     step_size=<span class="hljs-number">10.0</span>)
</code></pre>
<pre><code>Content layers:
[&apos;conv3_1/conv3_1&apos;]

Style layers:
[&apos;conv1_1/conv1_1&apos;, &apos;conv1_2/conv1_2&apos;, &apos;conv2_1/conv2_1&apos;, &apos;conv2_2/conv2_2&apos;, &apos;conv3_1/conv3_1&apos;, &apos;conv3_2/conv3_2&apos;, &apos;conv3_3/conv3_3&apos;, &apos;conv4_1/conv4_1&apos;, &apos;conv4_2/conv4_2&apos;, &apos;conv4_3/conv4_3&apos;, &apos;conv5_1/conv5_1&apos;, &apos;conv5_2/conv5_2&apos;, &apos;conv5_3/conv5_3&apos;]

. 
Iteration: 0
Weight Adj. for Content: 5.18e-11, Style: 2.14e-29, Denoise: 5.61e-06
</code></pre><p><img src="output_44_1.png" alt="png"></p>
<pre><code>. . . . . . . . . . 
Iteration: 10
Weight Adj. for Content: 2.79e-11, Style: 4.13e-28, Denoise: 1.25e-07
</code></pre><p><img src="output_44_3.png" alt="png"></p>
<pre><code>. . . . . . . . . . 
Iteration: 20
Weight Adj. for Content: 2.63e-11, Style: 1.09e-27, Denoise: 1.30e-07
</code></pre><p><img src="output_44_5.png" alt="png"></p>
<pre><code>. . . . . . . . . . 
Iteration: 30
Weight Adj. for Content: 2.66e-11, Style: 1.27e-27, Denoise: 1.27e-07
</code></pre><p><img src="output_44_7.png" alt="png"></p>
<pre><code>. . . . . . . . . . 
Iteration: 40
Weight Adj. for Content: 2.73e-11, Style: 1.16e-27, Denoise: 1.26e-07
</code></pre><p><img src="output_44_9.png" alt="png"></p>
<pre><code>. . . . . . . . . . 
Iteration: 50
Weight Adj. for Content: 2.75e-11, Style: 1.12e-27, Denoise: 1.24e-07
</code></pre><p><img src="output_44_11.png" alt="png"></p>
<pre><code>. . . . . . . . . 
Iteration: 59
Weight Adj. for Content: 1.85e-11, Style: 3.86e-28, Denoise: 1.01e-07
</code></pre><p><img src="output_44_13.png" alt="png"></p>
<pre><code>Final image:
</code></pre><p><img src="output_44_15.png" alt="png"></p>
<pre><code>CPU times: user 20min 1s, sys: 45.5 s, total: 20min 46s
Wall time: 3min 4s
</code></pre><h2 id="&#x603B;&#x7ED3;">&#x603B;&#x7ED3;</h2>
<p>&#x8FD9;&#x7BC7;&#x6559;&#x7A0B;&#x8BF4;&#x660E;&#x4E86;&#x7528;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6765;&#x7ED3;&#x5408;&#x4E24;&#x5F20;&#x56FE;&#x50CF;&#x5185;&#x5BB9;&#x548C;&#x98CE;&#x683C;&#x7684;&#x57FA;&#x672C;&#x60F3;&#x6CD5;&#x3002;&#x4E0D;&#x5E78;&#x7684;&#x662F;&#xFF0C;&#x7ED3;&#x679C;&#x5E76;&#x4E0D;&#x50CF;&#x4E00;&#x4E9B;&#x5546;&#x4E1A;&#x7CFB;&#x7EDF;&#x90A3;&#x4E48;&#x597D;&#xFF0C;&#x6BD4;&#x5982; <a href="http://www.deepart.io" target="_blank">DeepArt</a>&#xFF0C;&#x5B83;&#x662F;&#x7531;&#x8FD9;&#x79CD;&#x6280;&#x672F;&#x7684;&#x4E00;&#x4E9B;&#x5148;&#x9A71;&#x8005;&#x5F00;&#x53D1;&#x7684;&#x3002;&#xFF08;&#x7ED3;&#x679C;&#x4E0D;&#x597D;&#x7684;&#xFF09;&#x539F;&#x56E0;&#x6682;&#x4E0D;&#x660E;&#x786E;&#x3002;&#x4E5F;&#x8BB8;&#x6211;&#x4EEC;&#x53EA;&#x662F;&#x9700;&#x8981;&#x66F4;&#x5F3A;&#x7684;&#x8BA1;&#x7B97;&#x529B;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x9AD8;&#x5206;&#x8FA8;&#x7387;&#x56FE;&#x50CF;&#x4E0A;&#x4EE5;&#x66F4;&#x5C0F;&#x7684;&#x6B65;&#x957F;&#xFF0C;&#x8FD0;&#x884C;&#x66F4;&#x591A;&#x7684;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x3002;&#x6216;&#x8BB8;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x66F4;&#x590D;&#x6742;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x6CD5;&#x3002;&#x4E0B;&#x9762;&#x7684;&#x7EC3;&#x4E60;&#x7ED9;&#x51FA;&#x4E86;&#x4E00;&#x4E9B;&#x53EF;&#x80FD;&#x4F1A;&#x63D0;&#x5347;&#x8D28;&#x91CF;&#x7684;&#x5EFA;&#x8BAE;&#xFF0C;&#x9F13;&#x52B1;&#x4F60;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#x3002;</p>
<h2 id="&#x7EC3;&#x4E60;">&#x7EC3;&#x4E60;</h2>
<p>&#x4E0B;&#x9762;&#x4F7F;&#x4E00;&#x4E9B;&#x53EF;&#x80FD;&#x4F1A;&#x8BA9;&#x4F60;&#x63D0;&#x5347;TensorFlow&#x6280;&#x80FD;&#x7684;&#x4E00;&#x4E9B;&#x5EFA;&#x8BAE;&#x7EC3;&#x4E60;&#x3002;&#x4E3A;&#x4E86;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x66F4;&#x5408;&#x9002;&#x5730;&#x4F7F;&#x7528;TensorFlow&#xFF0C;&#x5B9E;&#x8DF5;&#x7ECF;&#x9A8C;&#x662F;&#x5F88;&#x91CD;&#x8981;&#x7684;&#x3002;</p>
<p>&#x5728;&#x4F60;&#x5BF9;&#x8FD9;&#x4E2A;Notebook&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x4E4B;&#x524D;&#xFF0C;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x5148;&#x5907;&#x4EFD;&#x4E00;&#x4E0B;&#x3002;</p>
<ul>
<li>&#x8BD5;&#x7740;&#x4F7F;&#x7528;&#x5176;&#x4ED6;&#x56FE;&#x50CF;&#x3002;&#x672C;&#x6587;&#x4E2D;&#x5305;&#x542B;&#x4E86;&#x4E00;&#x4E9B;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x3002;&#x4F60;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x81EA;&#x5DF1;&#x7684;&#x56FE;&#x50CF;&#x3002;</li>
<li>&#x8BD5;&#x7740;&#x66F4;&#x591A;&#x7684;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#xFF08;&#x6BD4;&#x5982;1000-5000&#xFF09;&#xFF0C;&#x4EE5;&#x53CA;&#x66F4;&#x5C0F;&#x7684;&#x6B65;&#x957F;&#xFF08;&#x6BD4;&#x5982;1.0-3.0&#xFF09;&#x3002;&#x5B83;&#x4F1A;&#x63D0;&#x5347;&#x8D28;&#x91CF;&#x5417;&#xFF1F;
*&#x3000;&#x6539;&#x53D8;&#x98CE;&#x683C;&#x5C42;&#x3001;&#x5185;&#x5BB9;&#x5C42;&#x4EE5;&#x53CA;&#x53BB;&#x566A;&#x65F6;&#x7684;&#x6743;&#x91CD;&#x3002;</li>
<li>&#x8BD5;&#x7740;&#x4ECE;&#x5185;&#x5BB9;&#x6216;&#x98CE;&#x683C;&#x56FE;&#x50CF;&#x5F00;&#x59CB;&#x4F18;&#x5316;&#xFF0C;&#x6216;&#x8BB8;&#x4E8C;&#x8005;&#x7684;&#x5E73;&#x5747;&#x3002;&#x4F60;&#x53EF;&#x4EE5;&#x52A0;&#x5165;&#x4E00;&#x4E9B;&#x566A;&#x58F0;&#x3002;</li>
<li>&#x8BD5;&#x7740;&#x6539;&#x53D8;&#x98CE;&#x683C;&#x56FE;&#x548C;&#x5185;&#x5BB9;&#x56FE;&#x7684;&#x5206;&#x8FA8;&#x7387;&#x3002;&#x5728;<code>load_image()</code>&#x51FD;&#x6570;&#x4E2D;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x7528;<code>max_size</code>&#x53C2;&#x6570;&#x6765;&#x6539;&#x53D8;&#x56FE;&#x50CF;&#x5927;&#x5C0F;&#x3002;&#x5B83;&#x5BF9;&#x7ED3;&#x679C;&#x6709;&#x4EC0;&#x4E48;&#x5F71;&#x54CD;&#xFF1F;</li>
<li>&#x8BD5;&#x7740;&#x4F7F;&#x7528;VGG-16&#x6A21;&#x578B;&#x7684;&#x5176;&#x4ED6;&#x5C42;&#x3002;</li>
<li>&#x6539;&#x53D8;&#x4EE3;&#x7801;&#xFF0C;&#x4F7F;&#x5176;&#x6BCF;10&#x6B21;&#x4F18;&#x5316;&#x8FED;&#x4EE3;&#x5C31;&#x4FDD;&#x5B58;&#x56FE;&#x50CF;&#x3002;</li>
<li>&#x5728;&#x4F18;&#x5316;&#x8FC7;&#x7A0B;&#x4E2D;&#x4F7F;&#x7528;&#x5E38;&#x6570;&#x6743;&#x91CD;&#x3002;&#x5B83;&#x5BF9;&#x7ED3;&#x679C;&#x6709;&#x4F55;&#x5F71;&#x54CD;&#xFF1F;</li>
<li>&#x5728;&#x98CE;&#x683C;&#x5C42;&#x4E2D;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x6743;&#x91CD;&#x3002;&#x540C;&#x6837;&#xFF0C;&#x8BD5;&#x7740;&#x50CF;&#x5176;&#x4ED6;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4E00;&#x6837;&#x81EA;&#x52A8;&#x8C03;&#x6574;&#x6743;&#x91CD;&#x3002;</li>
<li>&#x7528;TensorFlow&#x7684;ADAM&#x4F18;&#x5316;&#x5668;&#x6765;&#x4EE3;&#x66FF;&#x57FA;&#x672C;&#x7684;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x3002;</li>
<li>&#x4F7F;&#x7528;L-BFGS&#x4F18;&#x5316;&#x5668;&#x3002;&#x76EE;&#x524D;&#x5728;TensorFlow&#x4E2D;&#x6CA1;&#x6709;&#x5B9E;&#x73B0;&#x8FD9;&#x4E2A;&#x3002;&#x4F60;&#x80FD;&#x5728;&#x98CE;&#x683C;&#x8FC1;&#x79FB;&#x7B97;&#x6CD5;&#x4E2D;&#x4F7F;&#x7528;SciPy&#x4E2D;&#x5B9E;&#x73B0;&#x7684;&#x4F18;&#x5316;&#x5668;&#x4E48;&#xFF1F;&#x5B83;&#x6709;&#x63D0;&#x5347;&#x7ED3;&#x679C;&#x5417;&#xFF1F;</li>
<li>&#x7528;&#x53E6;&#x5916;&#x7684;&#x9884;&#x8BAD;&#x7EC3;&#x7F51;&#x7EDC;&#xFF0C;&#x6BD4;&#x5982;&#x6211;&#x4EEC;&#x5728;&#x6559;&#x7A0B; #14&#x4E2D;&#x4F7F;&#x7528;&#x7684;Inception 5h&#x6A21;&#x578B;&#xFF0C;&#x6216;&#x8005;&#x7528;&#x4F60;&#x4ECE;&#x7F51;&#x4E0A;&#x627E;&#x5230;&#x7684;VGG-19&#x6A21;&#x578B;&#x3002;</li>
<li>&#x5411;&#x670B;&#x53CB;&#x89E3;&#x91CA;&#x7A0B;&#x5E8F;&#x5982;&#x4F55;&#x5DE5;&#x4F5C;&#x3002;</li>
</ul>
<h2 id="license-mit">License (MIT)</h2>
<p>Copyright (c) 2016 by <a href="http://www.hvass-labs.org/" target="_blank">Magnus Erik Hvass Pedersen</a></p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../14_DeepDream_zh_CN/14_DeepDream_zh_CN.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: DeepDream">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"风格迁移","level":"1.15","depth":1,"previous":{"title":"DeepDream","level":"1.14","depth":1,"path":"14_DeepDream_zh_CN/14_DeepDream_zh_CN.md","ref":"14_DeepDream_zh_CN/14_DeepDream_zh_CN.md","articles":[]},"dir":"ltr"},"config":{"plugins":["comment"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"comment":{"highlightCommented":true},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"wizardforcel","pdf":{"pageNumbers":true,"fontSize":16,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"TensorFlow 教程（Hvass）","language":"zh","links":{"sidebar":{"TensorFlow 教程（Hvass）":"https://www.gitbook.com/book/wizardforcel/tf-tut-hvass"},"gitbook":true},"gitbook":"*","description":"Tensorflow 教程（Hvass）"},"file":{"path":"15_Style_Transfer_zh_CN/15_Style_Transfer_zh_CN.md","mtime":"2017-09-18T01:21:37.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2017-09-18T01:34:14.068Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-comment/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

